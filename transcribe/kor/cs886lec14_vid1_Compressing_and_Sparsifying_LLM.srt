1
00:00:00,000 --> 00:00:04,080
안녕하세요 여러분. 나는 하람이고 나와 함께 있어요

2
00:00:04,080 --> 00:00:06,880
마리앤 스미스.

3
00:00:06,880 --> 00:00:09,760
우리는 압축과

4
00:00:09,760 --> 00:00:12,240
대규모 언어 모델을 희소화합니다.

5
00:00:12,240 --> 00:00:15,680
우리의 프레젠테이션은 두 부분으로 나누어져 있습니다.

6
00:00:15,680 --> 00:00:17,320
나는 ~에 대해 이야기하겠다

7
00:00:17,320 --> 00:00:19,520
대규모 언어 모델의 희소화 및

8
00:00:19,520 --> 00:00:22,920
Marie-Anne은 대규모 언어 모델의 수량화에 대해 논의합니다.

9
00:00:22,920 --> 00:00:24,640
오늘의 개요는 다음과 같습니다.

10
00:00:24,640 --> 00:00:26,320
소개부터 시작하겠습니다.

11
00:00:26,320 --> 00:00:28,560
희소성이 무엇인지 이야기하겠습니다.

12
00:00:28,640 --> 00:00:32,400
그런 다음 전문가 원칙의 혼합을 확장하겠습니다.

13
00:00:32,400 --> 00:00:34,480
G샤드에 대해 이야기해 보세요.

14
00:00:34,480 --> 00:00:38,880
그리고 G-shard에 이어 세 번째 논문인 Colt T5에 대해 논의하겠습니다.

15
00:00:38,880 --> 00:00:41,200
Long T5의 버전입니다.

16
00:00:41,200 --> 00:00:44,960
아키텍처, 일부 평가 및 결과에 대해 이야기하겠습니다.

17
00:00:44,960 --> 00:00:49,760
그런 다음 Marie-Anne에게 넘겨서 정량화에 대해 이야기하겠습니다.

18
00:00:49,760 --> 00:00:51,760
그렇다면 희소성이란 무엇입니까?

19
00:00:51,760 --> 00:00:55,520
희소성은 조건부 계산이라는 아이디어를 사용합니다.

20
00:00:55,520 --> 00:00:59,360
밀집 모델에서는 모든 매개변수가 모든 입력에 사용됩니다.

21
00:00:59,360 --> 00:01:04,160
그리고 희소성으로 인해 전체 시스템의 일부만 실행할 수 있습니다.

22
00:01:04,160 --> 00:01:05,600
그러면 우리는 왜 그렇게 할까요?

23
00:01:05,600 --> 00:01:08,400
우리가 그렇게 하는 이유는 그것이 효율성에 도움이 되기 때문입니다.

24
00:01:08,400 --> 00:01:09,840
속도에 도움이 됩니다.

25
00:01:09,840 --> 00:01:11,760
에너지 소모에 좋습니다.

26
00:01:11,760 --> 00:01:15,600
그리고 용량 생성에도 좋습니다.

27
00:01:15,600 --> 00:01:21,280
그럼 전통적인 변압기 모델이 어떻게 생겼는지 이야기해 봅시다.

28
00:01:21,280 --> 00:01:24,080
그래서 우리는 이 입력 레이어를 갖게 되었습니다.

29
00:01:24,080 --> 00:01:26,480
그리고 주목 레이어가 있습니다.

30
00:01:26,480 --> 00:01:30,800
그런 다음 이러한 출력 토큰이 있습니다.

31
00:01:32,000 --> 00:01:35,120
그런 다음 이러한 출력 토큰은 피드포워드 계층으로 공급됩니다.

32
00:01:35,120 --> 00:01:38,720
그런 다음 우리는 다음 레이어에 공급되는 일부 출력을 얻습니다.

33
00:01:38,720 --> 00:01:41,360
여기 변압기의 핵심 혁신은

34
00:01:41,360 --> 00:01:44,160
그것을 가능하게 하는 주의 메커니즘이 있었습니다.

35
00:01:44,160 --> 00:01:46,880
입력 데이터의 전체 컨텍스트를 고려합니다.

36
00:01:47,760 --> 00:01:51,520
그리고 이는 이전 시퀀스 모델에 비해 상당한 도약이었습니다.

37
00:01:51,520 --> 00:01:55,120
한 번에 데이터 요소를 처리합니다.

38
00:01:56,720 --> 00:01:59,200
그래서 여기에 병목 현상이 발생합니다.

39
00:01:59,200 --> 00:02:03,120
그리고 병목 현상이 여기에 있습니다.

40
00:02:03,120 --> 00:02:08,720
따라서 규모에 따라 변환기는 더 많은 데이터와 복잡한 문제를 해결해야 합니다.

41
00:02:08,720 --> 00:02:12,240
그리고 엄청난 수의 매개변수와 작업이 필요하기 때문에

42
00:02:12,240 --> 00:02:14,960
리소스를 매우 많이 사용하게 됩니다.

43
00:02:14,960 --> 00:02:18,560
비효율성을 초래하고 확장성을 제한합니다.

44
00:02:18,560 --> 00:02:20,400
그렇다면 그에 대한 해결책은 무엇입니까?

45
00:02:20,400 --> 00:02:24,080
해결책은 조건부 컴퓨팅 또는 희소 모델입니다.

46
00:02:24,960 --> 00:02:26,880
그럼 그것에 대해 이야기 해 봅시다.

47
00:02:26,880 --> 00:02:30,160
그래서 우리는 이 전통적인 아키텍처를 없애려고 합니다.

48
00:02:30,160 --> 00:02:32,160
몇 가지 사항을 변경해 보겠습니다.

49
00:02:32,160 --> 00:02:35,280
따라서 이 다이어그램을 자세히 살펴보면

50
00:02:35,280 --> 00:02:38,640
우리가 변경한 사항이 여기에 있다는 것을 알 수 있습니다.

51
00:02:38,640 --> 00:02:42,160
그래서 우리는 이 피드포워드 네트워크를 변경했습니다.

52
00:02:42,160 --> 00:02:45,360
더 작은 하위 네트워크로 나누어 MOE라고 부릅니다.

53
00:02:46,000 --> 00:02:48,080
그리고 우리는 이 게이팅 메커니즘을 가지고 있습니다.

54
00:02:48,080 --> 00:02:51,600
어떤 입력 토큰이 어떤 전문가에게 전달되는지 결정합니다.

55
00:02:52,240 --> 00:02:53,840
그리고 나머지 모델은 동일합니다.

56
00:02:53,840 --> 00:02:56,800
입력 레이어, 장력 레이어, 출력 토큰이 있습니다.

57
00:02:57,840 --> 00:03:03,520
네, 우리가 한 일은 이 조밀한 네트워크 전체를 교체한 것입니다.

58
00:03:03,520 --> 00:03:05,440
더 작은 하위 네트워크 포함

59
00:03:05,440 --> 00:03:09,120
본질적으로 우리는 이를 분할 정복 문제로 만들고 있습니다.

60
00:03:09,120 --> 00:03:13,840
복잡성 측면에서 아주 좋을 것입니다.

61
00:03:13,840 --> 00:03:16,320
그리고 계산 자원.

62
00:03:19,040 --> 00:03:20,880
그렇다면 우리는 왜 그런 일을 하는 걸까요?

63
00:03:21,520 --> 00:03:26,480
우리가 그렇게 하는 이유는 앞서 말한 것처럼

64
00:03:26,480 --> 00:03:27,840
효율성이 좋습니다.

65
00:03:27,840 --> 00:03:30,880
따라서 전통적인 GPT는 모든 뉴런을 사용합니다.

66
00:03:30,880 --> 00:03:33,280
전진 패스를 위한 모든 매트릭스에서.

67
00:03:33,280 --> 00:03:35,600
여기 보이는 전체 네트워크는

68
00:03:35,600 --> 00:03:38,960
이 모든 뉴런은 모든 계산에 관여합니다.

69
00:03:38,960 --> 00:03:40,960
그것은 매우 비쌉니다.

70
00:03:41,760 --> 00:03:45,200
모든 뉴런이 필요하지 않다면 어떻게 될까요?

71
00:03:45,200 --> 00:03:47,520
그런데 이 오렌지색 것만 필요하다고요?

72
00:03:47,600 --> 00:03:50,720
우리는 기본적으로 Triple Quadrupled를 수행하고 있습니다.

73
00:03:50,720 --> 00:03:52,640
필수적인 컴퓨팅 양.

74
00:03:53,840 --> 00:03:58,640
이 네트워크를 더 작은 하위 네트워크로 분할하면 어떻게 될까요?

75
00:03:58,640 --> 00:04:00,960
그리고 각각은 전문적인 작업을 수행합니까?

76
00:04:01,920 --> 00:04:04,320
언어 번역의 경우,

77
00:04:04,320 --> 00:04:06,960
예를 들면, 이 숫자 1은

78
00:04:06,960 --> 00:04:11,840
이 전문가는 구두점을 다룰 것입니다. 예를 들어,

79
00:04:11,840 --> 00:04:14,000
두 번째는 기사를 다룰 것입니다.

80
00:04:14,000 --> 00:04:17,840
그래서 우리는 이 거대한 문제를 더 작은 문제로 나누고 있습니다.

81
00:04:20,240 --> 00:04:23,760
복잡성 측면에서 매우 좋습니다.

82
00:04:25,120 --> 00:04:28,400
그래서 우리는 이러한 라우팅 메커니즘이 있다는 것을 알았습니다.

83
00:04:29,280 --> 00:04:33,280
어떤 입력 토큰이 어떤 전문가에게 전달되는지 결정했습니다.

84
00:04:33,280 --> 00:04:35,520
그럼 자세히 이야기해 보겠습니다.

85
00:04:36,080 --> 00:04:41,520
따라서 라우팅 메커니즘은 본질적으로 네트워크입니다.

86
00:04:41,520 --> 00:04:45,200
어떤 토큰이 어떤 전문가에게 전달되는지 결정합니다.

87
00:04:45,840 --> 00:04:47,520
실제로 학습된 과정입니다.

88
00:04:47,520 --> 00:04:48,880
정적이 아닙니다.

89
00:04:48,880 --> 00:04:50,960
훈련을 통해 학습하고 적응합니다.

90
00:04:50,960 --> 00:04:54,960
그래서 전문가 모델의 혼합이 더 많은 데이터에 노출될수록,

91
00:04:54,960 --> 00:04:58,640
라우팅 메커니즘은 기준을 정의하고 개선합니다.

92
00:04:58,640 --> 00:05:02,400
다양한 유형의 입력 토큰에 대한 전문가를 선택합니다.

93
00:05:03,680 --> 00:05:07,360
따라서 시간이 지남에 따라 이러한 학습 과정은 전문화로 이어집니다.

94
00:05:07,360 --> 00:05:10,640
각 전문가는 더욱 능숙해집니다.

95
00:05:10,640 --> 00:05:13,200
특정 유형의 입력 토큰을 처리할 때

96
00:05:13,760 --> 00:05:15,760
이는 전반적인 효율성을 향상시킵니다.

97
00:05:15,760 --> 00:05:17,280
그리고 모델의 효율성.

98
00:05:17,840 --> 00:05:21,840
따라서 추론 시 라우팅 메커니즘은 동작을 학습했습니다.

99
00:05:21,840 --> 00:05:26,400
모델이 전문가 계산의 일부만 사용하도록 허용합니다.

100
00:05:26,400 --> 00:05:27,200
훌륭해요.

101
00:05:27,920 --> 00:05:31,600
따라서 우리는 본질적으로 이 정도의 계산을 수행하고 있습니다.

102
00:05:31,600 --> 00:05:34,000
전체 네트워크를 사용하는 대신.

103
00:05:35,360 --> 00:05:36,960
그럼 논문에 대해 이야기해 볼까요?

104
00:05:36,960 --> 00:05:40,000
논문은 효율적인 대규모 언어 모델링이라고 합니다.

105
00:05:40,000 --> 00:05:41,360
전문가들이 섞여있습니다.

106
00:05:42,080 --> 00:05:46,560
그래서 그들이 여기서 하는 일은 실제로 이 혼합물을 사용하는 것입니다.

107
00:05:46,560 --> 00:05:52,000
전문가 모델을 대규모로 활용하고 이 모델의 성능을 확인합니다.

108
00:05:52,000 --> 00:05:54,480
밀도가 높은 모델에 비해 규모가 큽니다.

109
00:05:55,360 --> 00:05:59,600
그래서 우리는 여기 x축에 있는 이 그래프를 볼 수 있습니다.

110
00:05:59,600 --> 00:06:02,560
우리는 조밀한 트레이닝 제타 플롭을 가지고 있습니다.

111
00:06:02,560 --> 00:06:05,840
그리고 y축에는 MOE 속도 향상 요소가 있습니다.

112
00:06:06,720 --> 00:06:10,160
다음 슬라이드에서는 이것이 어떻게 계산되는지 설명하겠습니다.

113
00:06:10,160 --> 00:06:15,760
하지만 지금 당장은 그것이 훨씬 더 효율적이라고 생각할 수 있습니다.

114
00:06:15,760 --> 00:06:19,600
MOE 모델은 밀집 모델에 상대적입니다.

115
00:06:21,040 --> 00:06:25,280
그리고 속도 향상 요소 9는 다음을 나타냅니다.

116
00:06:25,280 --> 00:06:28,960
MOE 모델은 해당 모델의 성능과 일치할 수 있습니다.

117
00:06:28,960 --> 00:06:32,720
9배 적은 컴퓨팅을 사용하는 밀도 모델.

118
00:06:32,720 --> 00:06:34,960
그럼 여기서 결과에 대해 이야기해 보겠습니다.

119
00:06:34,960 --> 00:06:38,960
우리는 그들이 세 가지 영역에서 모델을 테스트했음을 알 수 있습니다.

120
00:06:38,960 --> 00:06:42,160
그래서 그들은 도메인 언어 모델링을 테스트했습니다.

121
00:06:42,160 --> 00:06:46,960
훈련된 데이터로 모델을 테스트하는 것입니다.

122
00:06:46,960 --> 00:06:50,800
그런 다음 빨간색 선인 도메인 외부에서 테스트를 거쳤습니다.

123
00:06:51,600 --> 00:06:55,280
훈련되지 않은 데이터로 모델을 테스트하는 것입니다.

124
00:06:55,280 --> 00:06:56,880
그리고 우리는 짧은 프라이밍이 없습니다.

125
00:06:57,520 --> 00:07:02,560
따라서 우리는 도메인 언어 모델링에서 가장 높은 이득을 얻을 수 있음을 알 수 있습니다.

126
00:07:02,560 --> 00:07:06,400
따라서 MOE는 도메인에서 평가할 때 가장 효율적입니다.

127
00:07:06,400 --> 00:07:13,040
그리고 우리는 이득이 18이고 여기서는 약 16 또는 18임을 알 수 있습니다.

128
00:07:13,040 --> 00:07:20,560
따라서 밀도가 높은 모델은 해당 모델보다 18~16배 더 나은 성능을 발휘합니다.

129
00:07:21,600 --> 00:07:24,640
MOE 모델은 밀집 모델보다 성능이 좋습니다.

130
00:07:25,360 --> 00:07:29,920
따라서 가장 낮은 이득은 제로 쇼트 프라이밍에 대한 것이지만 여전히 더 좋습니다.

131
00:07:30,880 --> 00:07:34,560
밀도가 높은 모델보다 약 4배 더 좋습니다.

132
00:07:36,080 --> 00:07:39,680
그럼 속도 향상 요소를 계산하는 방법에 대해 이야기해 보겠습니다.

133
00:07:40,880 --> 00:07:48,160
따라서 여기서 t의 C는 주어진 성능 수준 t에서 계산된 비용 함수입니다.

134
00:07:48,160 --> 00:07:54,080
그래서 그들은 불연속적인 값만 가지기 때문에 여기서 보간법을 사용합니다.

135
00:07:54,080 --> 00:07:59,200
연속적인 값을 알기 위해서는 보간법을 사용해야 합니다.

136
00:07:59,200 --> 00:08:02,480
따라서 그들은 알려진 가장 높은 값과 가장 낮은 알려진 값을 사용합니다.

137
00:08:02,480 --> 00:08:07,680
그런 다음 성능 수준이 어느 정도인지 비율을 사용합니다.

138
00:08:07,680 --> 00:08:10,560
낮은 참조 성능과 높은 참조 성능 사이에 있습니다.

139
00:08:11,280 --> 00:08:16,240
그리고 이것이 계산된 비용 함수입니다.

140
00:08:17,360 --> 00:08:23,920
그리고 속도 향상 요소는 계산된 밀도 비용과 MOE의 비율일 뿐입니다.

141
00:08:25,760 --> 00:08:28,240
그들이 수행한 실험에 대해 이야기해 봅시다.

142
00:08:28,960 --> 00:08:34,400
그래서 그들은 크기와 크기가 대략 일치하는 자기회귀 변환기 모델을 훈련시켰습니다.

143
00:08:34,400 --> 00:08:35,920
GPT-3의 아키텍처.

144
00:08:36,640 --> 00:08:41,440
사전 정규화 변환기 블록과 GLU 활성화를 사용합니다.

145
00:08:42,080 --> 00:08:46,400
그리고 Dense 모델의 경우 GPT-3와 달리 Dense attention만 사용합니다.

146
00:08:46,400 --> 00:08:49,760
이는 희소 및 조밀을 번갈아 사용합니다.

147
00:08:49,760 --> 00:08:52,240
그리고 그들은 상위 2개 전문가 모델을 사용합니다.

148
00:08:52,960 --> 00:08:57,520
그리고 상위 2개는 게이팅 메커니즘이 입력에 점수를 매길 때

149
00:08:57,520 --> 00:09:03,680
관련성과 전문성을 기반으로 여기에서 상위 2개의 점수 입력을 사용합니다.

150
00:09:04,400 --> 00:09:10,320
그래서 저는 신문에서 이 테이블에 대해 이야기하고 싶습니다.

151
00:09:10,320 --> 00:09:14,000
그래서 자세히 보면 GPT-3의 훈련 비용이 있는데,

152
00:09:14,000 --> 00:09:15,040
밀도가 높은 GPT-3.

153
00:09:15,040 --> 00:09:19,120
그런 다음 이를 밀도 모델 및 MOE 모델과 비교합니다.

154
00:09:19,120 --> 00:09:26,160
따라서 130억 개의 GPT-3 모델의 훈련 비용은 32.67임을 알 수 있습니다.

155
00:09:27,120 --> 00:09:28,560
Zeta는 실패합니다.

156
00:09:29,200 --> 00:09:36,800
그리고 150억 크기의 MOE 모델은 0.3에 불과하며 이는 큰 격차입니다.

157
00:09:36,800 --> 00:09:43,280
그리고 우리는 이러한 전문가 모델이 밀집 모델에 비해 훨씬 더 나은 성능을 발휘한다는 것을 알 수 있습니다.

158
00:09:45,360 --> 00:09:51,200
그래서 그들은 6개의 영어 데이터세트를 통합하여 데이터와 모델을 사전 훈련했습니다.

159
00:09:51,200 --> 00:09:55,600
여기에 나열했으며 더 자세히 살펴보고 싶다면 링크가 첨부되어 있습니다.

160
00:09:56,160 --> 00:09:59,600
그러나 나는 이것에 대해 너무 깊이 다루지는 않을 것입니다.

161
00:10:01,280 --> 00:10:03,600
그럼 결과에 대해 이야기해보겠습니다.

162
00:10:03,600 --> 00:10:08,080
따라서 그들은 두 가지 측정항목을 기반으로 모델을 평가합니다.

163
00:10:08,080 --> 00:10:11,120
그들은 성능뿐만 아니라 당혹감을 확인합니다.

164
00:10:11,120 --> 00:10:17,840
그리고 그들이 선택한 이유는 당혹감이 후속 성능을 나타내는 훌륭한 지표가 아니기 때문입니다.

165
00:10:18,480 --> 00:10:19,360
작업 성과.

166
00:10:19,360 --> 00:10:26,400
그래서 그들은 모델이 예측에 대해 갖고 있는 신뢰도인 당혹성을 선택합니다.

167
00:10:26,400 --> 00:10:30,000
당혹감이 높으면 좋지 않습니다.

168
00:10:30,000 --> 00:10:31,520
모델이 자신감이 없어요.

169
00:10:32,400 --> 00:10:40,000
그리고 구체적인 데이터의 경우 도메인 내 데이터의 경우 학습 데이터의 예약된 부분을 사용합니다.

170
00:10:40,000 --> 00:10:42,800
모델의 성능을 테스트하기 위해 따로 보관해 두세요.

171
00:10:42,800 --> 00:10:45,360
그리고 도메인 외부의 경우 파일 데이터 세트를 사용합니다.

172
00:10:45,360 --> 00:10:50,160
다시 말하지만, 이는 논문의 일부 결과입니다.

173
00:10:50,160 --> 00:10:54,400
왼쪽에는 도메인 내 데이터가 있습니다.

174
00:10:55,040 --> 00:10:59,840
따라서 이 노란색 선은 MOE 모델을 위한 것이고 이 빨간색 선은 밀집 모델을 위한 것입니다.

175
00:10:59,840 --> 00:11:03,600
우리는 노란색 선이 지속적으로 덜 혼란스러운 것을 볼 수 있습니다.

176
00:11:03,600 --> 00:11:06,480
따라서 MOE는 도메인 내에서 더 나은 성능을 발휘합니다.

177
00:11:07,120 --> 00:11:13,680
그리고 도메인 외부 데이터의 경우에도 노란색 선이 덜 혼란스러운 것을 알 수 있습니다.

178
00:11:14,240 --> 00:11:17,200
실제로 이 격차는 실제로 규모가 커집니다.

179
00:11:18,160 --> 00:11:23,840
그들은 이유에 대해 이야기하지 않지만 그 이유는 과적합일 수 있습니다.

180
00:11:23,840 --> 00:11:29,760
그러나 여전히 밀도가 높은 모델보다 더 나은 성능을 발휘하며 지속적으로 덜 혼란스럽습니다.

181
00:11:32,560 --> 00:11:35,680
네, 이것은 다른 결과 중 일부입니다.

182
00:11:35,680 --> 00:11:41,520
우리는 그것을 알 수 있습니다. 이것이 앞서 이야기한 속도 향상 요소입니다.

183
00:11:41,520 --> 00:11:44,720
따라서 가장 좋은 결과는 일반적인 크롤링에 대한 것입니다.

184
00:11:44,720 --> 00:11:50,880
그 이유는 모델의 학습 데이터와 밀접한 관련이 있기 때문입니다.

185
00:11:50,880 --> 00:11:56,000
그리고 우리는 해당 모델이 도메인 내 설정에서 어떻게 가장 잘 작동하는지에 대해 이야기했습니다.

186
00:11:56,880 --> 00:12:02,560
그리고 다시 오른쪽을 보면 이 노란색 선이 가장 정확도가 높은 것을 볼 수 있습니다.

187
00:12:03,360 --> 00:12:10,640
이는 특히 GPT-3와 비교할 때 MOE가 매우 우수하다는 것을 의미합니다.

188
00:12:10,640 --> 00:12:12,240
및 기타 밀도가 높은 모델.

189
00:12:12,240 --> 00:12:15,840
따라서 정확도는 MOE의 정확도보다 낮습니다.

190
00:12:19,520 --> 00:12:21,520
그렇다면 우리는 왜 스케일링을 하는 걸까요?

191
00:12:22,240 --> 00:12:27,520
이전 결과에서 본 것처럼 극적인 품질 향상을 가져오기 때문에 규모를 조정하고 있습니다.

192
00:12:28,480 --> 00:12:31,440
특히 컴퓨터 비전 및 언어 처리 작업의 경우,

193
00:12:31,440 --> 00:12:36,640
이는 일관된 이득을 제공하고 더 나은 분류로 이어졌습니다.

194
00:12:37,120 --> 00:12:40,720
이것은 Gshard라는 두 번째 논문으로 이어집니다.

195
00:12:42,000 --> 00:12:48,640
프레임워크에 대해 이야기하기 때문에 실제로는 ML 문서가 아니며 엔지니어링 문서에 가깝습니다.

196
00:12:49,760 --> 00:12:55,360
이것은 실제로 Gshard라는 Google의 프레임워크입니다.

197
00:12:55,360 --> 00:13:01,840
그들은 1조 개의 매개변수 모델을 구축하려고 시도하지만 제대로 구축하지 못합니다.

198
00:13:02,160 --> 00:13:08,000
그래서 그들은 훈련하고 창조할 수 있었던 차선책을 선택했습니다.

199
00:13:08,000 --> 00:13:10,560
이는 6000억 개의 매개변수 모델이었습니다.

200
00:13:12,240 --> 00:13:19,520
그래서 여기서 그들이 하는 일은 거대한 MOE 모델, 즉 6천억 개의 매개변수를 구축하는 것입니다.

201
00:13:20,160 --> 00:13:29,920
그런 다음 병렬화를 사용하여 데이터를 여러 시스템으로 분할합니다.

202
00:13:29,920 --> 00:13:35,680
따라서 앞서 논의한 것과 동일한 개념이지만 파티션과 결합됩니다.

203
00:13:36,400 --> 00:13:42,400
그래서 여기서 나는 큰 모델 규모가 깊이를 증가시키는 데서 오는 것이 아니라고 썼습니다.

204
00:13:42,400 --> 00:13:47,840
트랜스포머는 레이어 수이지만 트랜스포머의 폭을 늘리는 것이며,

205
00:13:47,840 --> 00:13:51,200
이는 본질적으로 MOE 모델입니다.

206
00:13:52,000 --> 00:13:57,520
그래서 그들은 이를 하드 라우팅과 결합하여 248개의 TPU로 병렬화합니다.

207
00:13:58,240 --> 00:14:00,880
그리고 그들은 단 4일 만에 그것을 훈련시킬 수 있었습니다.

208
00:14:02,640 --> 00:14:08,240
그리고 이는 단일 프로그램 다중 데이터를 의미하는 SPMD라는 것을 기반으로 합니다.

209
00:14:08,240 --> 00:14:14,160
단일 프로그램이 프로세서에 의해 실행되는 병렬 컴퓨팅에 사용되는 개념입니다.

210
00:14:15,200 --> 00:14:19,200
병렬이지만 각 프로세서는 서로 다른 데이터 세트에서 작동합니다.

211
00:14:19,840 --> 00:14:27,840
이제 Gshard의 아키텍처에 대해 이야기해 보겠습니다. 이것이 바로 전통적인 건축입니다. 우리는

212
00:14:27,840 --> 00:14:34,160
그거 봤어. 그리고 이것이 MOE 아키텍처입니다. 우리는 이 피드포워드 레이어를 볼 수 있습니다.

213
00:14:34,160 --> 00:14:39,920
이를 여러 네트워크, 하위 네트워크로 분할한 다음 게이팅 메커니즘을 갖게 됩니다.

214
00:14:41,120 --> 00:14:46,720
따라서 Gshard는 피드포워드 레이어와 함께 대체 MOE 레이어를 사용합니다. 그래서 우리는 이 MOE 레이어를 가지고 있습니다.

215
00:14:46,720 --> 00:14:51,920
그런 다음 피드포워드 레이어가 있고, 또 다른 MOE 레이어가 있고, 또 다른 피드포워드가 있습니다.

216
00:14:51,920 --> 00:14:59,920
등등. 샤딩이 실제로 무엇인지 살펴보겠습니다. 그래서 그들은 실제로 이 전체를 분할했습니다.

217
00:14:59,920 --> 00:15:07,920
다른 컴퓨터에 네트워크를 연결합니다. 그리고 이 모든 작업은 실제로 Gshard 프레임워크에 의해 수행됩니다.

218
00:15:07,920 --> 00:15:12,800
사용자는 하드웨어 세부 사항에 대해 걱정할 필요가 없습니다.

219
00:15:12,800 --> 00:15:21,200
이 논문에 관한 것입니다. 따라서 모든 기계에는 전문가가 한 명 있습니다. 여기 전문가 한 분이 계십니다.

220
00:15:21,200 --> 00:15:28,960
그리고 이 숫자는 이 기계에 대한 전문가입니다. 그리고 본질적으로 E개의 다른 기계가 있습니다.

221
00:15:30,400 --> 00:15:39,680
그럼 여기서 게이팅 메커니즘에 대해 이야기해 보겠습니다. 따라서 이 방정식은 다음의 게이팅 점수를 보여줍니다.

222
00:15:39,680 --> 00:15:46,640
각 전문가. 이것이 입력입니다. 이를 게이트 함수에 입력하고 다음에 대한 점수를 얻습니다.

223
00:15:46,640 --> 00:15:53,920
각 전문가. 그리고 이것이 각 전문가 내부에서 일어나는 일입니다. 그래서 우리는 입력 투영을 곱합니다

224
00:15:54,560 --> 00:15:58,880
가중치를 사용하여 활성화 함수를 적용하고 이를 곱합니다.

225
00:15:59,520 --> 00:16:06,320
출력 가중치. 그런 다음 각 전문가의 결과는 본질적으로 가중 합계입니다.

226
00:16:07,040 --> 00:16:15,600
게이팅 점수를 기준으로 합니다. 따라서 전문가의 게이팅 점수가 0인 경우 어떤 입력도 라우팅하지 않습니다.

227
00:16:15,600 --> 00:16:23,520
직관적으로 이해가 됩니다. 그리고 그들은 그동안 가졌던 고려 사항에 대해 이야기합니다.

228
00:16:23,520 --> 00:16:30,160
이 게이팅 기능을 생성합니다. 그래서 그들은 로드 밸런싱에 대해 이야기하고 게이팅 기능을 만듭니다.

229
00:16:30,240 --> 00:16:38,960
그들의 의견이 각 전문가에게 균일하게 분배되는 방식입니다. 그래서 전문가가 단 한 명도 없습니다.

230
00:16:38,960 --> 00:16:47,600
부담이 없으며 모든 전문가는 본질적으로 동일한 수의 입력 토큰을 얻습니다. 그리고 그들은 또한 소개합니다

231
00:16:47,600 --> 00:16:56,160
손실 함수가 지속적으로 입력을 하나에 보내는 경우 페널티를 적용하는 보조 손실

232
00:16:56,160 --> 00:17:04,640
전문가. 따라서 분포가 균일한지 실제로 감사하게 생각합니다. 그리고 그들은

233
00:17:04,640 --> 00:17:14,480
무작위 라우팅. 따라서 무작위 라우팅은 입력 토큰을 상위 두 명의 전문가에게 보내는 곳입니다.

234
00:17:14,480 --> 00:17:22,880
하지만 때로는 두 전문가의 점수 차이가 클 경우 한 사람의 점수가 매우 높습니다.

235
00:17:22,880 --> 00:17:28,080
점수가 매우 낮고 다른 사람의 점수가 매우 낮으면 점수가 낮은 전문가를 무시할 것입니다.

236
00:17:29,440 --> 00:17:38,160
각 전문가의 역량을 확보하십시오. 그렇다면 Gshard를 어떻게 구현하나요? 앞서 논의했듯이,

237
00:17:38,160 --> 00:17:44,400
매우 효율적이고 사용하기 쉽습니다. 우리는 사용자가 본질적으로 아무것도 할 필요가 없습니다.

238
00:17:44,400 --> 00:17:50,480
그리고 모든 것이 처리되었습니다. 사용자는 주석 API를 사용해서만 주석을 추가합니다. 그래서 그샤드는

239
00:17:50,560 --> 00:17:58,640
프레임워크에는 두 가지 주요 사항이 있습니다. 사용자가 결정할 수 있는 주석 API가 함께 제공됩니다.

240
00:17:58,640 --> 00:18:04,960
그들이 무언가를 복제하거나 배포하기를 원하는지 여부. 그래서 프레임워크는

241
00:18:04,960 --> 00:18:12,720
본질적으로 스스로 결정할 것입니다. 80%의 시간 동안 프레임워크는 자체적으로 다음 사항을 결정합니다.

242
00:18:12,720 --> 00:18:20,160
특정 입력은 복제되거나 배포되어야 합니다. 그러나 이를 통해 사용자는 어느 정도 제어할 수도 있습니다.

243
00:18:20,160 --> 00:18:24,640
따라서 사용자는 배포 또는 복제를 원하는지 결정할 수 있습니다.

244
00:18:25,280 --> 00:18:31,040
그리고 가속 선형 대수 컴파일러인 XLA 컴파일러가 함께 제공됩니다.

245
00:18:31,040 --> 00:18:40,880
실제로 주석 API를 기반으로 컴파일된 프로그램을 생성하며

246
00:18:41,600 --> 00:18:50,000
이를 기반으로 입력을 분할합니다. 이것이 XLA 컴파일러의 몇 가지 특징입니다.

247
00:18:50,400 --> 00:18:58,080
프레임워크 전반에 걸쳐 통합된 컴파일을 제공합니다. 따라서 TensorFlow는 물론 PyTorch에서도 작동할 수 있습니다.

248
00:18:58,080 --> 00:19:04,560
파티셔닝 자체를 처리합니다. 그래서 큰 계산을 더 작은 단위로 나눕니다.

249
00:19:04,560 --> 00:19:10,560
운영. 그리고 데이터 통신도 처리합니다. 그래서 파티셔닝에 관해 이야기할 때,

250
00:19:10,560 --> 00:19:15,520
파티션 간에도 많은 계산과 통신이 이루어져야 합니다.

251
00:19:16,320 --> 00:19:22,240
그리고 XLA 컴파일러가 스스로 이를 수행하므로 사용자는 이에 대해 걱정할 필요가 없습니다.

252
00:19:22,240 --> 00:19:30,880
그리고 우리는 여기서 그것에 대해 이야기할 것입니다. 따라서 파티셔닝 시 고려해야 할 사항은 다음과 같습니다.

253
00:19:30,880 --> 00:19:38,480
XLA 컴파일러가 처리하는 것입니다. 그들이 논문에서 이야기하는 두 가지 주요 내용은 패딩입니다.

254
00:19:38,480 --> 00:19:48,880
그리고 후광 교환. 예를 들어 특정 텐서의 차원이 균일하지 않은 경우

255
00:19:48,880 --> 00:19:54,160
그래서 균일하게 분포되지 않습니다. 따라서 특정 파티션에는 다음보다 더 많은 데이터가 있습니다.

256
00:19:54,160 --> 00:20:01,200
다른 파티션. 따라서 이러한 경우 XLA 컴파일러는 다음 중 하나를 사용하여 텐서를 채우는 것입니다.

257
00:20:01,200 --> 00:20:07,120
단위 행렬 또는 0. 그런 다음 해당 텐서를 균일하게 배포합니다.

258
00:20:08,720 --> 00:20:14,160
그리고 컨볼루션 작업과 같은 일부 조건에서는 커널이 있다는 것을 알고 있습니다.

259
00:20:14,160 --> 00:20:20,080
슬라이딩 창은 여기 입력 위로 이동해야 합니다. 그래서 이 애니메이션에서 이 슬라이딩은

260
00:20:20,080 --> 00:20:28,160
창이 입력 위로 이동하고 있습니다. 하지만 여기 이 가장자리에 도달하면 데이터의 절반이

261
00:20:28,160 --> 00:20:35,600
다른 파티션에 상주합니다. 그렇다면 우리는 어떻게 해야 할까요? 이 문서에서는 이 영역을

262
00:20:35,600 --> 00:20:42,320
할로 지역. 그리고 컴파일러가 하는 일은 후광 영역에 도달하면 다른 파티션을 요청하는 것입니다.

263
00:20:42,320 --> 00:20:49,680
후광 영역을 보내고 각 파티션이 전체 영역을 갖도록 후광 교환을 수행합니다.

264
00:20:49,680 --> 00:20:56,560
완전한 창을 통해 정확한 결과를 얻을 수 있습니다. 그리고 이 역시 XLA에 의해 처리됩니다.

265
00:20:56,560 --> 00:21:00,880
컴파일러와 우리는 그것에 대해 걱정할 필요가 없습니다. 이것이 그것에 대한 좋은 점입니다.

266
00:21:02,800 --> 00:21:09,200
그들이 수행한 실험과 그들이 사용한 데이터 세트에 대해 이야기해 봅시다. 따라서 데이터 세트가 채굴됩니다.

267
00:21:09,200 --> 00:21:15,120
웹에서는 제공되지 않으며 우리는 이를 사용할 수 없습니다. 100개 이상의 언어로 된 문서가 있습니다.

268
00:21:15,760 --> 00:21:22,880
영어로 그리고 영어로. 그래서 그들이 훈련하는 모델은 대규모 다국어 기계 번역을 위한 것입니다.

269
00:21:22,880 --> 00:21:28,400
기계 번역 모델이고 다국어입니다. 그래서 그것은 다른 말로 번역됩니다

270
00:21:28,400 --> 00:21:36,080
언어를 영어로. 볼륨이 엄청납니다. 총 250억 개의 훈련 예시입니다.

271
00:21:37,120 --> 00:21:43,040
그리고 언어 쌍에 불균형이 있습니다. 그러니 그들이 다음과 같은 언어를 가지고 있다고 가정해 보세요.

272
00:21:43,040 --> 00:21:47,760
수백만 개의 학습 예제가 있지만 일부 언어의 경우 예제가 많지 않습니다.

273
00:21:47,760 --> 00:21:55,600
이를 위해 그들은 자원이 적은 언어라고 부릅니다. 기본적으로 그들은 실제로 훈련을 합니다.

274
00:21:55,600 --> 00:22:00,560
각 언어 쌍에 대한 이중 언어 신경 기계 번역 모델을 만든 다음

275
00:22:00,560 --> 00:22:07,840
그 결과. 그래서 이것은 몇 가지 모델 변형입니다. 그래서 그들은 두 가지 변수를 변화시킵니다. 그들

276
00:22:07,840 --> 00:22:14,800
모델의 레이어 수를 변경한 다음 사용되는 전문가의 수를 변경합니다.

277
00:22:14,800 --> 00:22:21,600
여기 이 표에서는 2000으로 시작해야 한다는 것을 알 수 있습니다. 실제로는 128로 시작합니다.

278
00:22:21,600 --> 00:22:27,440
그런 다음 512로 이동한 다음 가장 큰 모델인 2048로 이동합니다.

279
00:22:28,320 --> 00:22:35,200
그리고 그들은 12개의 레이어로 시작합니다. 36개의 레이어와 60개의 레이어가 가장 큰 모델입니다.

280
00:22:35,600 --> 00:22:50,160
그럼 몇 가지 결과에 대해 이야기해 보겠습니다. 그래서 우리는 이 파란색 선을 볼 수 있습니다. 그래서 이것은 실제로

281
00:22:50,160 --> 00:22:59,600
블루 스코어, 델타 블루 스코어. 여기 이 파란색 선은 성능 또는 델타 파란색 점수입니다.

282
00:22:59,600 --> 00:23:09,600
이는 36개 레이어로 구성된 MOE 모델의 품질 향상입니다. 그래서 우리는 그것이 최고의 성능을 발휘한다는 것을 알 수 있으며 그 이유는

283
00:23:09,600 --> 00:23:17,040
그 이유는 레이어 수 때문입니다. 따라서 레이어 수가 증가할수록 모델은

284
00:23:17,680 --> 00:23:27,280
과도한 매개변수화로 인해 많은 것을 배울 수 있습니다. 그리고 이 갈색 선이 12단 모델인데,

285
00:23:27,280 --> 00:23:33,360
이는 또한 직관적으로 의미가 있습니다. 왜냐하면 우리는 그것이 a보다 더 나은 성능을 기대하지 않기 때문입니다.

286
00:23:33,360 --> 00:23:41,680
더 깊은 모델. 그리고 우리는 규모가 증가함에 따라 품질 향상도 증가한다는 것을 알 수 있습니다.

287
00:23:41,680 --> 00:23:51,680
이는 모델이 규모에 따라 더 나은 성능을 발휘한다는 가설에 기여합니다. 그럼 그렇지, 이건

288
00:23:51,680 --> 00:23:57,120
우리가 방금 얘기한 그래프에서요. 더 심층적인 모델을 사용하면 일관된 품질 향상을 볼 수 있습니다.

289
00:23:57,120 --> 00:24:07,040
그래서 우리는 36개의 레이어로 구성된 모델이 12개의 레이어로 구성된 모델보다 더 나은 성능을 발휘한다는 것을 확인했습니다. 그런 다음

290
00:24:07,040 --> 00:24:13,840
우리는 더 많은 전문가와 함께 리소스가 많은 작업이 개선되는 것을 확인했습니다. 그래서 전문가의 수만큼

291
00:24:13,840 --> 00:24:22,960
증가하면 개선이 보입니다. 이 그래프가 위쪽으로 올라가는 것을 볼 수 있습니다. 이것은 또 다른 그래프입니다.

292
00:24:22,960 --> 00:24:30,240
모델이 이야기합니다. 그럼 먼저 여기의 빨간색 선을 살펴보겠습니다. 이는 품질 향상입니다.

293
00:24:30,240 --> 00:24:37,200
기계의 정확도를 평가하기 위한 표준 지표인 델타 블루 점수로 측정됩니다.

294
00:24:37,200 --> 00:24:46,160
번역 작업. 모델 크기를 늘리면 370억 개의 가중치로 시작하는 것을 알 수 있습니다.

295
00:24:46,160 --> 00:24:55,840
그리고 6000억을 향해 나아갑니다. 크기를 늘리면 바로 여기 파란색 선이 나타납니다.

296
00:24:55,840 --> 00:25:02,560
이는 훈련 벽 시간입니다. 모델 크기가 증가하더라도 이 파란색 선은 그렇지 않습니다.

297
00:25:02,560 --> 00:25:08,880
기하급수적으로 증가합니다. 이는 우리 모델이 정말 잘 학습하고 있지만 그렇지 않다는 것을 의미합니다.

298
00:25:09,680 --> 00:25:15,440
밀집 모델에 비해 계산 비용이 많이 듭니다. 그러니 주의를 집중시킨다면

299
00:25:15,440 --> 00:25:23,760
여기서 점선은 TPU v3 코어 연도를 기준으로 계산 비용을 나타냅니다. 당신은 알아 차릴 것입니다

300
00:25:23,760 --> 00:25:30,800
375억 개의 가중치를 갖는 모델에서 6,000억 개의 가중치를 갖는 모델로 이동하면

301
00:25:30,800 --> 00:25:37,920
계산 비용은 핵심 연도 6년에서 22년으로만 증가합니다. 이것은 단지 준선형적 증가일 뿐입니다.

302
00:25:37,920 --> 00:25:48,960
모델 크기가 16배 증가한 것을 고려할 때. 따라서 이는 MOE 모델이 다음을 수행할 수 있음을 의미합니다.

303
00:25:48,960 --> 00:25:57,360
밀도가 높은 모델에 비해 짧은 시간 내에 뛰어난 번역 품질을 달성할 수 있습니다. 그들은 실제로

304
00:25:57,360 --> 00:26:04,640
밀도가 높은 모델에 걸린 시간은 TPU 코어 연수 235년이었고 이는 단지 22년에 불과합니다.

305
00:26:06,480 --> 00:26:11,920
이제 훈련 효율성에 대해 이야기합시다. 따라서 더 깊은 모델은 샘플 효율성이 더 높고

306
00:26:11,920 --> 00:26:18,560
더 적은 예제로 더 빠르게 수렴하는데, 이는 과의 가속 효과 때문입니다.

307
00:26:18,560 --> 00:26:26,960
더 깊은 모델에는 더 많은 매개변수가 있으므로 매개변수화. 여기 12개의 모델이 있습니다.

308
00:26:26,960 --> 00:26:36,880
레이어는 0.7의 교차 엔트로피 손실에 도달하는 데 9,950억 개의 토큰이 필요합니다.

309
00:26:36,880 --> 00:26:46,160
36개 레이어에는 3,210억 개의 토큰이 필요하며 이는 그보다 3배 적은 수치입니다. 에 대해 논의해보자

310
00:26:46,160 --> 00:26:52,400
지금 성능. 그래서 6000억 크기의 가장 큰 모델을 4일 만에 학습시킬 수 있습니다.

311
00:26:53,360 --> 00:27:02,080
96레이어, 2048코어의 경우 10배인 42일이 소요된 반면 최고의 품질을 달성하기 위해

312
00:27:02,080 --> 00:27:10,000
훈련할 시간이 더 많습니다. 그들은 또한 실제로 메모리 소비에 대해서도 이야기합니다. 그래서 기억은

313
00:27:10,000 --> 00:27:16,080
Gshard의 소비는 세 가지에서 비롯됩니다. 이는 복제된 가중치입니다.

314
00:27:16,080 --> 00:27:20,560
변환기 피드포워드 레이어에는 가중치가 분산되어 있고 활성화가 있습니다.

315
00:27:20,560 --> 00:27:27,360
이는 순방향 및 역방향 경로에 사용되는 각 레이어의 출력입니다. 그래서 여기를 보면,

316
00:27:27,360 --> 00:27:36,080
전문가 수를 늘리면 128명의 전문가로 시작해서 나중에는

317
00:27:36,080 --> 00:27:43,280
2048명의 전문가로 이동했으며 전문가 규모, 활성화 가중치 및

318
00:27:44,720 --> 00:27:49,440
실제로 가중치가 증가합니다. 이는 직관적으로 이해가 되지만 정말 흥미로운 점입니다.

319
00:27:49,440 --> 00:27:58,000
마지막에 발생합니다. 여기서는 활성화 가중치가 증가하는 대신 다음을 볼 수 있습니다.

320
00:27:58,000 --> 00:28:06,400
약간의 감소. 그 이유는 활성화 메모리 크기가 커질수록

321
00:28:06,400 --> 00:28:14,560
하나의 파티션에 간격을 둘 수 없습니다. 따라서 XLA 컴파일러는 실제로 이를 다시 구체화하고

322
00:28:15,520 --> 00:28:22,960
단지 메모리의 활성화 중 일부를 사용한 다음 나머지는 다시 계산되는 동안 계산됩니다.

323
00:28:22,960 --> 00:28:32,640
pass는 XLA 컴파일러의 또 다른 뛰어난 기능입니다. 그렇다면 여기서 핵심 내용은 무엇입니까?

324
00:28:33,360 --> 00:28:40,240
따라서 Gshard는 대규모 확장을 위해 SPMD 프레임워크를 사용하고 다음 주석을 제공합니다.

325
00:28:40,320 --> 00:28:46,400
모든 머신에서 어떤 텐서를 원하는지, 어떤 텐서가 되고 싶은지 결정할 수 있게 해주는 API

326
00:28:46,400 --> 00:28:52,160
모든 기계에 분할한 다음 대규모 다국어 기계 번역을 훈련할 수 있습니다.

327
00:28:52,160 --> 00:29:01,200
단 4개로 6000억 개의 매개변수 크기를 갖는 모델입니다. 마지막 논문으로 가보겠습니다.

328
00:29:01,200 --> 00:29:10,000
조건부 긴 T5. 조건부 계산을 사용하는 Long T5 버전입니다.

329
00:29:10,000 --> 00:29:17,200
다른 방법. 그래서 지난 두 논문에서는 동일한 개념에 대해 이야기하고 있었습니다.

330
00:29:17,200 --> 00:29:26,240
전문가 모델이지만 여기에는 다른 개념이 있습니다. 그들은 실제로 매우 다른 방식으로 희소성을 사용합니다.

331
00:29:26,240 --> 00:29:33,040
이에 대해서는 다음 슬라이드에서 논의하겠습니다. 그래서 우리는 많은 자연적인 처리 작업이

332
00:29:33,120 --> 00:29:40,480
긴 입력을 사용하면 이점이 있지만 긴 입력을 처리하는 데 비용이 많이 듭니다. 왜? 이차식 때문에

333
00:29:40,480 --> 00:29:45,200
주의 복잡성. 따라서 모든 입력은 다른 모든 입력에 주의를 기울여야 합니다. 이는 2차입니다.

334
00:29:45,200 --> 00:29:55,120
입력이 너무 길면 입력을 그대로 유지하는 것이 불가능합니다. 그래서 입력으로

335
00:29:55,120 --> 00:30:04,560
증가하지만 모든 토큰이 실제로 중요한 것은 아닙니다. 이것이 바로 단어주머니 이론이다. 그래서 가방에

336
00:30:04,560 --> 00:30:10,160
단어 중 몇 단어만 중요하잖아요? 이것이 조건부 뒤에 있는 직관입니다.

337
00:30:10,160 --> 00:30:16,640
긴 T5. 이 논문은 조건부 계산을 사용한 더 빠른 장거리 변환기(Faster Long Range Transformers with Conditional Computation)라고 합니다. 그리고

338
00:30:16,640 --> 00:30:22,160
앞서 논의한 것처럼 직관은 일부 토큰이 다른 토큰보다 더 중요하다는 것입니다.

339
00:30:22,160 --> 00:30:27,920
중요한 작업에 더 많은 계산을 할애함으로써 더 낮은 비용으로 더 나은 품질을 달성할 수 있습니다.

340
00:30:27,920 --> 00:30:35,600
토큰. 그리고 이것이 그들이 하는 방법입니다. 그래서 그들은 가벼운 가지를 가지고 있고 무거운 가지를 가지고 있습니다. 그래서

341
00:30:35,600 --> 00:30:42,080
그들은 모든 토큰을 light 브랜치를 통해 라우팅합니다. 그리고 중요한 사람만이 힘든 일을 겪는다

342
00:30:42,080 --> 00:30:46,720
나뭇가지. 그리고 이 가지들 사이의 차이점은 가벼운 가지가 가벼운 주의력을 가지고 있다는 것이고,

343
00:30:46,720 --> 00:30:53,520
이는 Local Attention과 Light MLP 레이어입니다. 그리고 무거운 가지에는 완전한 주의가 있고

344
00:30:53,520 --> 00:31:00,960
무거운 MLP. 이것이 품질 5의 세 가지 주요 구성 요소입니다. 그들은 라우팅 모듈을 가지고 있습니다.

345
00:31:00,960 --> 00:31:06,320
어떤 입력 토큰이 헤비 브랜치를 통과할지 결정합니다. 그런 다음 조건부 피드 포워드가 있습니다.

346
00:31:06,320 --> 00:31:10,640
Heavy Branch에도 있고 조건부 주의 레이어도 Heavy Branch에 있습니다.

347
00:31:11,440 --> 00:31:16,640
여기서도 품질 5의 라우팅 메커니즘을 학습할 수 있습니다. 그들은 단지 입력에 다음을 곱합니다.

348
00:31:16,640 --> 00:31:22,080
라우팅 점수를 얻고 이를 정규화하기 위한 학습된 임베딩입니다. 그런 다음 상단을 선택합니다.

349
00:31:22,080 --> 00:31:27,840
K개의 가장 높은 점수를 받은 입력이며 해당 입력을 헤비 분기를 통해 라우팅합니다.

350
00:31:30,240 --> 00:31:38,080
그리고 여기서도 조건부 피드포워드는 다음과 같습니다. 우리는 가벼운 가지를 가지고 있습니다

351
00:31:38,080 --> 00:31:44,960
모든 토큰이지만 특정 양의 토큰만 헤비 브랜치에 공급됩니다.

352
00:31:44,960 --> 00:31:50,880
그들의 점수. 이것이 지난 슬라이드에서 계산한 점수입니다. 그리고 조건부로

353
00:31:50,880 --> 00:31:56,720
주의하세요, 우리는 대부분의 토큰이 간단한 상호 작용을 가지고 있다는 것을 알고 있지만 일부 토큰은 더 무거운 상호 작용을 통해 이점을 얻습니다.

354
00:31:56,720 --> 00:32:01,760
처리. 따라서 조건부 관심은 가벼운 가지와 무거운 가지로 구성됩니다. 그리고 이것이 바로 그것입니다

355
00:32:01,840 --> 00:32:09,840
처럼 보입니다. 따라서 일부 행에는 파란색 상자만 있고 일부 행에는 추가 보라색 상자가 있음을 알 수 있습니다.

356
00:32:09,840 --> 00:32:16,000
또한. 여기서 중요한 입력 토큰에 대해 많은 추가 토큰을 추가합니다. 하지만

357
00:32:16,000 --> 00:32:21,040
지역적인 관심을 끌기 위해 우리는 단지 창문의 지역적인 범위를 취하고 있습니다.

358
00:32:23,200 --> 00:32:28,960
훈련에 대해 이야기 해 봅시다. 배치 크기가 있는 C4 데이터 세트에 대해 사전 학습했습니다.

359
00:32:28,960 --> 00:32:36,800
of 256. 그리고 0.001의 일정한 학습률을 사용하여 미세 조정했습니다. 그리고 이들은 모델입니다

360
00:32:36,800 --> 00:32:41,520
그들은 사용했다. 그래서 그들은 기본 모델, 대형, 특대형의 세 가지 변형을 사용합니다.

361
00:32:42,640 --> 00:32:51,360
기본 모델의 경우 2억 4,800만 달러였습니다. 그리고 초대형의 경우 520만 달러였습니다.

362
00:32:51,440 --> 00:33:00,640
이것이 데이터 세트입니다. 이것들 중 일부는 다르지만 대부분은 다음 중 하나에 속합니다.

363
00:33:00,640 --> 00:33:09,280
Coal T5가 실제로 최첨단 기술을 달성한 벤치마크를 스크롤합니다. 결과는 다음과 같습니다. 그래서

364
00:33:10,800 --> 00:33:17,520
파란색 라인의 평균 성능은 분홍색 라인보다 훨씬 더 좋습니다. 그래서 파란색 선은

365
00:33:17,520 --> 00:33:24,880
Coal T5가 훨씬 더 나은 성능을 발휘한다는 것을 알 수 있습니다. 그리고 시간을 살펴보면,

366
00:33:24,880 --> 00:33:31,600
추론과 정밀한 작업을 위해 긴 T5에 비해 훨씬 더 적은 시간이 필요하다는 것을 알 수 있습니다.

367
00:33:31,600 --> 00:33:42,160
동조. 그래서 앞서 말씀드렸던 것처럼 스크롤 벤치마크에서는 SOTA를 달성합니다. 우리는

368
00:33:42,160 --> 00:33:50,800
석탄 T5 초대형 모델은 속도가 느리고 F1 점수가 더 높습니다.

369
00:33:52,320 --> 00:34:00,800
긴 T5와 더 높은 정확한 일치 정확도도 있습니다. 실제로 규모를 확장하는 방식은

370
00:34:00,800 --> 00:34:07,200
모델 크기이지만 실제로는 입력 크기입니다. 그리고 우리는 그것이 매우 오랫동안 효과적으로 확장된다는 것을 알 수 있습니다.

371
00:34:07,200 --> 00:34:12,000
입력하고 더 강력한 성능을 달성합니다. 따라서 파란색 선의 F1 점수가 더 높다는 것을 알 수 있습니다.

372
00:34:12,800 --> 00:34:19,520
그리고 입력 길이는 8K로 시작하여 64K로 이동합니다. 그리고 이 모든 시간 동안,

373
00:34:19,520 --> 00:34:24,320
Long T5에 비해 시간이 덜 걸리고 성능도 더 좋습니다.

374
00:34:26,080 --> 00:34:34,640
그들은 절제 연구도 수행합니다. 그리고 우리는 실제로 한 가지 흥미로운 점을 발견했습니다.

375
00:34:34,640 --> 00:34:41,360
그들은 라우팅을 정적으로 만드는 것입니다. 그리고 라우팅을 정적으로 만들면서 우리는

376
00:34:41,360 --> 00:34:49,120
성능이 저하됩니다. 점수, 점수를 보면 실제로 기준선보다 훨씬 낮습니다.

377
00:34:50,080 --> 00:34:57,200
이는 실제로 토큰을 동적으로 라우팅함으로써 이점을 얻을 수 있는 요인에 기여합니다.

378
00:34:57,200 --> 00:35:04,000
중요한 토큰을 식별하고 더 중요하게 여기는 방법을 배우게 됩니다. 그리고 이것은

379
00:35:04,000 --> 00:35:08,160
모델이 더 많은 매개변수를 갖는다고 해서 성능이 더 좋아지는 것은 아닙니다.

380
00:35:10,640 --> 00:35:16,800
그들은 또한 논문에서 Colt T5의 몇 가지 제한 사항에 대해 논의했습니다. 콜트 T5가 적용된다고 하네요

381
00:35:16,800 --> 00:35:23,120
조건부 계산은 인코더에서만 가능합니다. 그리고 조건부 계산을 적용하지 않습니다.

382
00:35:23,120 --> 00:35:30,640
디코더는 복잡하기 때문입니다. 그리고 그들은 미래의 작업을 위해 그것을 남겨 둡니다. 그리고 그들은 또한 이야기합니다

383
00:35:30,720 --> 00:35:36,800
긴 시퀀스에 대한 전문화입니다. 따라서 다른 유형에 대해서는 처음부터 훈련해야 합니다.

384
00:35:36,800 --> 00:35:44,560
시퀀스의. 제가 세 모델을 비교해본 작은 비교입니다. 그래서 전문가의 혼합

385
00:35:44,560 --> 00:35:51,920
1조 1천억 개의 모델 매개변수 모델을 사용하고 Gshard는 6천억 개를 사용하는 반면 Colt T5는 5.3개를 사용합니다.

386
00:35:51,920 --> 00:36:00,480
10억. 희소화를 위해 Mixture of Expert는 피드포워드 레이어를 분할하는 반면 Gshard는

387
00:36:00,640 --> 00:36:08,400
Colt T5는 분기를 통해 분할하는 반면 피드 포워드 레이어를 분할하고 분할도 수행합니다.

388
00:36:08,960 --> 00:36:13,760
전문가 혼합에 대한 희소화는 피드포워드 계층에 있습니다. Gshard의 경우

389
00:36:13,760 --> 00:36:22,240
피드 포워드 레이어도 마찬가지입니다. 하지만 Colt T5의 경우 세 가지 레이어가 모두 포함되어 있습니다. 전문가의 혼합은 최고를 사용합니다

390
00:36:22,240 --> 00:36:29,680
전문가 두 명. Gshard는 무작위 라우팅에서 상위 2개를 사용하고 Colt T5는 아무것도 사용하지 않습니다. 관심을 끌기 위해,

391
00:36:29,680 --> 00:36:35,280
전문가의 혼합은 집중적인 관심을 사용합니다. Gshard도 Dense attention을 사용하지만 Colt T5는

392
00:36:35,280 --> 00:36:44,000
둘 다의 혼합. 그리고 전문화를 위해 Mixture of Expert는 대규모 데이터에 특화되어 있습니다. 그샤드

393
00:36:44,000 --> 00:36:51,760
병렬화를 전문으로 하고 Colt T5는 긴 입력을 전문으로 합니다. 이제 넘겨줄게

394
00:36:51,760 --> 00:37:09,840
희소화에 대해 이야기하기 위해 마리암에게. 안녕하세요. LLM의 양자화에 대해 논의하겠습니다.

395
00:37:14,800 --> 00:37:16,640
측면을 조금 수정하겠습니다.

396
00:37:21,760 --> 00:37:32,480
슬라이드 몇 개가 빠진 것 같아요.

397
00:37:34,880 --> 00:37:43,200
앞으로 나올 슬라이드를 살펴보겠습니다. 이제 혼합 정밀도 양자화를 살펴보겠습니다. 그래서

398
00:37:44,320 --> 00:37:51,600
모든 기능은 크기에 따라 양자화됩니다. 그럼 이 입력 텐서가 있다고 가정해 봅시다.

399
00:37:51,680 --> 00:38:00,240
그리고 우리는 가중치 행렬을 가지고 있습니다. 이제 입력 텐서는 벡터로 분할됩니다. 그리고

400
00:38:00,240 --> 00:38:05,760
높은 크기의 벡터가 식별됩니다. 그리고 그들은 부동에서 정상적으로 곱해질 것입니다

401
00:38:05,760 --> 00:38:13,760
point 16. 크기가 작은 것은 int 8로 곱해집니다. 그래서 곱해집니다

402
00:38:13,760 --> 00:38:20,400
부동 소수점 16을 int 8로 변환하는 양자화 상수를 사용합니다. 그리고 나서

403
00:38:20,400 --> 00:38:26,240
행렬 곱셈이 수행됩니다. 그런 다음 최종 fp16에서 출력을 얻기 위해 비정합화됩니다.

404
00:38:27,600 --> 00:38:34,400
따라서 기본적으로 이 병목 행렬 곱셈 부분은 int 8에서 수행됩니다.

405
00:38:36,720 --> 00:38:43,040
이것은 이것의 수학적 형식입니다. 여기서 부동 소수점, 총 출력은 실제로

406
00:38:43,040 --> 00:38:49,760
부동 소수점 행렬 곱셈 연산과 int 8 행렬 곱셈의 합

407
00:38:49,760 --> 00:38:57,280
운영. 이 sf16은 int 8 행렬 곱셈을 조정하는 데 사용되는 배율 인수입니다.

408
00:38:57,280 --> 00:39:01,520
부동소수점 16으로 돌아갑니다. 이것은 기본적으로 탈원화(decontization)가 일어나는 것입니다.

409
00:39:03,680 --> 00:39:08,640
이제 벡터 방식 양자화에 대해 논의하면 이는 블록 방식 양자화의 한 형태입니다.

410
00:39:08,640 --> 00:39:17,440
그러나 텐서의 각 행이나 텐서의 열은 단일 벡터로 사용됩니다.

411
00:39:17,440 --> 00:39:23,440
그리고 그것은 독립적으로 양자화됩니다. 이제 이는 대부분의 양자화 정밀도를 향상시킵니다.

412
00:39:23,440 --> 00:39:29,520
기능 중. 예를 들어, 이것이 입력 행렬이고 이것이 가중치 행렬이라면,

413
00:39:30,240 --> 00:39:37,120
a1, a2, a3 및 b1, b4 및 b7은 다음과 같습니다. 이것은 행렬이며 다음의 단일 연산입니다.

414
00:39:37,120 --> 00:39:43,200
출력 행렬을 형성할 곱셈입니다. 따라서 이들 벡터는 독립적으로 양자화됩니다.

415
00:39:44,160 --> 00:39:51,920
자체 스케일링 상수가 있으며 출력이 계산됩니다. 모든 벡터가 다음과 같으면

416
00:39:51,920 --> 00:39:58,400
매트릭스에 함께 배치하고 합산한 다음 분리합니다. 이는 수학적 형태이며,

417
00:39:59,280 --> 00:40:07,760
여기서 출력은 실제로 비콘타이제이션 스케일링 인자와

418
00:40:08,720 --> 00:40:16,000
최신 출력. 최신 출력은 벡터 a와 벡터 b를 독립적으로 양자화하여 계산됩니다.

419
00:40:16,800 --> 00:40:23,120
기본적으로 입력 벡터는 입력 텐서가 이 두 벡터 a와 b로 구성되어 있다고 가정해 보겠습니다.

420
00:40:23,120 --> 00:40:27,760
따라서 a와 b는 독립적으로 양자화되고 스케일링 계수가 곱해집니다.

421
00:40:27,760 --> 00:40:32,640
최종 출력을 얻으려면. 여기에 양자화 기능이 있습니다.

422
00:40:33,360 --> 00:40:39,520
이제 스케일링 상수에 대해 더 자세히 살펴보겠습니다. 기본적으로 양자화란 무엇입니까?

423
00:40:39,520 --> 00:40:45,040
그들이 사용하고 있는 절차는 무엇입니까? 그래서 그들은 다음을 사용하여 실험을 보여주었습니다.

424
00:40:45,040 --> 00:40:51,200
AvSmax 양자화 및 영점 양자화. AvSmax는 대칭입니다. 그것은

425
00:40:51,200 --> 00:40:55,760
텐서의 가장 큰 절대값에서 파생된 상수를 통해 값을 입력합니다. 그래서 기본적으로,

426
00:40:55,760 --> 00:41:04,320
127입니다. int8은 기본적으로 2의 8에서 1을 뺀 값이므로 총 숫자입니다.

427
00:41:04,320 --> 00:41:12,480
날짜 내 표현으로 표현할 수 있는 최대 수이며, 나누어집니다.

428
00:41:12,480 --> 00:41:21,040
해당 벡터의 최대값으로 계산됩니다. 따라서 이렇게 하면 극단값이 캡처될 수 있지만

429
00:41:21,040 --> 00:41:26,480
사용 가능한 비트 범위를 덜 효율적으로 사용하게 됩니다. 보다 효율적인 영점 양자화

430
00:41:26,480 --> 00:41:31,600
가장 효율적입니다. 더 효율적인 양자화 기술은 영점입니다.

431
00:41:31,600 --> 00:41:37,680
양자화. 비대칭입니다. 여기에는 입력 값의 분포가 이동하는 것이 포함됩니다.

432
00:41:37,680 --> 00:41:42,880
그래서 이런 식으로 표현의 전체 범위가 효과적으로 사용되며,

433
00:41:42,880 --> 00:41:51,440
비대칭 데이터도 수용합니다. 따라서 이 절차에서는

434
00:41:53,600 --> 00:42:00,720
최대 비트 표현의 최대 수를 나누어서 최대 - 최소로 나누어 보겠습니다.

435
00:42:00,720 --> 00:42:07,920
그런 다음 마지막에 벡터에 최소값을 곱한 값도 추가합니다.

436
00:42:08,800 --> 00:42:16,080
따라서 이는 비트 표현의 전체 범위를 수용하고 양자화도 감소시킵니다.

437
00:42:16,080 --> 00:42:24,400
전반적으로 오류가 발생했습니다. 자, 이것들은 그들의 논문에서 나온 몇 가지 결과입니다. 그들은 C4를 계산했습니다

438
00:42:24,400 --> 00:42:33,520
이 표에서 볼 수 있듯이 실례합니다.

439
00:42:37,440 --> 00:42:43,840
이 논문에서 볼 수 있듯이, 절대 최대값과 영점, 절대값 최대값, 행 방향 및 벡터

440
00:42:44,800 --> 00:42:56,240
영점 벡터 방식으로 규모를 조정하면 악화가 줄어들고 27억 개의 매개변수 이후에는

441
00:42:56,240 --> 00:43:03,360
그들은 더 나쁜 성과를 냅니다. 따라서 27억 개의 매개변수 이후에는 메서드의 성능이 실제로 더 나쁩니다.

442
00:43:03,360 --> 00:43:13,040
작은 모델보다 영점 벡터 방식 양자화는 67억 이후 성능이 저하됩니다.

443
00:43:13,040 --> 00:43:22,960
매개변수. 따라서 영점 양자화가 절대 최대치에 비해 이점이 있다는 것을 알 수 있습니다.

444
00:43:22,960 --> 00:43:28,640
그러나 혼합 정밀도 분해와 함께 사용하면 더 이상 유리하지 않습니다.

445
00:43:32,880 --> 00:43:38,080
보시다시피, 그들의 최신 LLM 방법은 기존의 모든 방법보다 성능이 뛰어납니다.

446
00:43:38,080 --> 00:43:47,360
그리고 그것은 우리가 확장함에 따라 당혹감을 유지하고 있으며 정확히 비교할 수 있습니다.

447
00:43:47,360 --> 00:43:52,400
이는 32비트 흐름 변환기 모델과 매우 유사합니다.

448
00:43:59,200 --> 00:44:06,480
따라서 이것이 주요 초점의 일부는 아니었지만 몇 가지 결과도 제공했습니다.

449
00:44:06,480 --> 00:44:13,360
시간 복잡도와 관련되어 있기 때문에 양자화 오버헤드가

450
00:44:13,360 --> 00:44:19,120
부동 모델에 비해 매개변수가 67억 개 미만인 모델의 추론 속도가 느림

451
00:44:19,120 --> 00:44:30,880
포인트 16 기준선. 그러나 67억 개의 매개변수 이후에는 LLM in-date가 약 2배로 실행됩니다.

452
00:44:30,880 --> 00:44:38,080
1,750억 개의 모델에 해당하는 대규모 측정항목 곱셈의 속도가 빠릅니다.

453
00:44:39,520 --> 00:44:46,160
LLM in-date는 두 배 빠르며, LLM in-date가 일부

454
00:44:47,440 --> 00:44:55,040
67억 개의 매개변수보다 작은 모델에 더 많은 오버헤드가 발생하므로 이러한 작은 모델은 일반적으로

455
00:44:55,040 --> 00:45:03,200
대부분의 GPU와 양자화는 실제로 필요하지 않습니다. 이제 계속해서 보면 우리는

456
00:45:03,200 --> 00:45:07,680
피드포워드 및 주의 투영 레이어의 매개변수를 양자화할 수 있지만

457
00:45:07,680 --> 00:45:12,480
추론. 하지만 훈련은 어떻고 주의 함수 계산은 어떻습니까?

458
00:45:13,440 --> 00:45:20,960
따라서 이것은 블록 단위 양자화를 사용하는 8비트 최적화 프로그램인 다음 문서로 이동합니다.

459
00:45:21,200 --> 00:45:29,360
이제 이들은 8비트 통계를 사용하여 신경망에서 최적화를 수행하여

460
00:45:30,000 --> 00:45:35,040
훈련 중 32비트 최적화 상태의 성능 수준입니다. 그래서 이 논문에서는 다음 사항에 중점을 두고 있습니다.

461
00:45:35,040 --> 00:45:41,200
훈련 중 최적화가 이루어지며 가중치에도 초점을 맞추지 않습니다. 대신에,

462
00:45:41,200 --> 00:45:49,120
옵티마이저 상태는 약 33~75%의 정보를 사용하기 때문에 옵티마이저 상태에 중점을 둘 것입니다.

463
00:45:49,120 --> 00:45:55,600
훈련 중 총 메모리 공간. 그렇다면 이러한 옵티마이저 그래디언트 통계는 무엇입니까?

464
00:45:55,600 --> 00:46:00,080
따라서 기본적으로 기계 학습의 일반 최적화 프로그램은 모델 매개변수를 업데이트합니다.

465
00:46:01,280 --> 00:46:05,840
순전히 현재 데이터 배치에서 계산된 기울기를 기반으로 합니다. 그러나 주립 분야

466
00:46:05,840 --> 00:46:11,360
SGD 및 Adam과 같은 최적화 프로그램은 과거 기울기를 추적하고 이 정보를 사용하여

467
00:46:11,360 --> 00:46:18,400
업데이트를 알립니다. 예를 들어 SGD는 업데이트를 원활하게 하기 위해 모멘텀을 사용하고 Adam은 계속 추적합니다.

468
00:46:18,400 --> 00:46:22,640
각 매개변수의 학습률을 조정하기 위해 과거 기울기의 제곱합을 사용합니다.

469
00:46:23,520 --> 00:46:30,000
따라서 이 문서에서는 이러한 최적화 프로그램 상태의 메모리 공간을 최적화하는 데 중점을 둡니다.

470
00:46:30,640 --> 00:46:37,040
이제 그들은 블록 단위 양자화를 사용하며 이 접근 방식은 메모리 사용량을 줄입니다.

471
00:46:37,040 --> 00:46:42,480
최적화 상태를 통해 동일한 메모리 제약 내에서 더 큰 모델을 훈련할 수 있습니다.

472
00:46:42,480 --> 00:46:47,520
상태 저장 최적화 프로그램 사용으로 인한 성능 이점을 잃습니다.

473
00:46:48,160 --> 00:46:51,920
이 문서의 주요 혁신은 블록 단위 동적 양자화입니다.

474
00:46:52,800 --> 00:47:00,480
안정적인 임베딩 레이어. 이제 이 블록별 양자화는 이상값을 격리합니다.

475
00:47:00,480 --> 00:47:07,600
모든 비트에 대해 더 균등하게 오류에 대해 이의를 제기합니다. 기본적으로 여기에서는 텐서를 분해합니다.

476
00:47:07,600 --> 00:47:11,840
더 작은 블록이나 덩어리로 나눈 다음 각 블록을 독립적으로 정규화합니다.

477
00:47:12,560 --> 00:47:15,520
효율적인 계산과 병렬 처리를 위해.

478
00:47:18,480 --> 00:47:25,360
그리고 이것은 그것의 수학적 형태이며 그들은 블록 B에 대해 정규화 상수를 사용합니다.

479
00:47:25,360 --> 00:47:31,920
이는 해당 블록 내의 최대 절대값입니다. 따라서 벡터의 양자화된 값은 다음과 같습니다.

480
00:47:31,920 --> 00:47:37,520
정규화 상수로 나눈 값에서 이 분수를 뺍니다.

481
00:47:40,080 --> 00:47:43,360
j번째 요소를 양자화된 형태로 매핑하는 함수입니다.

482
00:47:49,200 --> 00:47:53,360
이는 기본적으로 고유한 절대 최대 양자화이며 나중에 살펴보게 됩니다.

483
00:47:54,320 --> 00:48:00,640
이제 이 방법이 왜 좋은가요? 이상값에 강하기 때문입니다. 이는 인터코어와는 독립적입니다.

484
00:48:01,440 --> 00:48:06,640
인터코어 동기화는 블록과 블록을 분할하기 때문입니다.

485
00:48:10,080 --> 00:48:15,360
계산은 병렬로 이루어지므로 코어 간 동기화를 수행할 필요가 없습니다.

486
00:48:15,360 --> 00:48:20,720
따라서 이는 계산 효율성을 향상시키며, 이 방법은 또한 가장 큰

487
00:48:20,720 --> 00:48:26,640
값은 오류 없이 양자화됩니다. 따라서 이는 양자화 과정의 정밀도를 유지합니다.

488
00:48:26,720 --> 00:48:36,400
이제 그들은 이러한 동적 양자화 절차도 도입했습니다. 그래서

489
00:48:38,240 --> 00:48:43,280
여기, 이것은 기본적으로 작은 것과 큰 것 모두를 위한 일종의 양자화입니다.

490
00:48:43,280 --> 00:48:49,120
높은 정밀도로 크기 값을 제공하며 실제로 동적 트리 양자화를 향상시킵니다.

491
00:48:49,120 --> 00:48:56,160
부호 비트가 필요하지 않은 텐서의 경우 더 나은 정밀도를 위해 용도를 변경하여

492
00:48:56,160 --> 00:49:01,600
긍정적인 가치를 제시합니다. 이것이 의미하는 바는 양자화 기술을 조정하는 것입니다.

493
00:49:01,600 --> 00:49:06,800
일반적으로 두 번째 상태를 추적하는 것과 관련된 Adam과 같은 최적화 프로그램에서 사용됩니다.

494
00:49:06,800 --> 00:49:12,800
그라디언트의 실행 평균. 이 값은 항상 양수이므로 일반적으로 부호 비트는

495
00:49:12,800 --> 00:49:18,080
이진 표현에서 음수를 나타내는 데 사용되며 필요하지 않습니다. 그래서 저자들은

496
00:49:18,080 --> 00:49:23,840
이 중복 부호 비트를 활용하여 양자화의 정밀도를 높여서

497
00:49:23,840 --> 00:49:28,800
두 번째 상태에서 발생할 수 있는 더 넓은 범위의 값을 처리하는 최적화 프로그램

498
00:49:28,800 --> 00:49:33,920
훈련 중. 이 수정은 최적화 프로그램 상태의 충실도를 유지해야 합니다.

499
00:49:33,920 --> 00:49:38,160
대표. 따라서 이는 대규모 언어 모델에 특히 중요합니다.

500
00:49:38,160 --> 00:49:44,160
그라디언트 정보의 규모에 상당한 변화가 있습니다. 따라서 이는 광범위한 계정을 허용합니다.

501
00:49:44,160 --> 00:49:57,360
이 Adam 최적화 프로그램의 크기 범위. 따라서 또 다른 주요 혁신은 안정성입니다.

502
00:49:57,360 --> 00:50:03,040
임베딩 레이어. 따라서 기본적으로 기존 임베딩 레이어는 낮은 수준에서는 불안정해질 수 있습니다.

503
00:50:03,040 --> 00:50:08,240
8비트 정수와 같은 정밀도 형식(정밀도가 감소하면 큰 오류가 발생할 수 있음)

504
00:50:08,240 --> 00:50:14,080
또는 훈련 과정의 불안정성. 그러나 그들이 도입한 안정적인 임베딩 레이어는

505
00:50:14,880 --> 00:50:20,880
임베딩이 8비트로 양자화되는 경우에도 32비트 최적화 상태를 사용할 수 있습니다.

506
00:50:20,880 --> 00:50:24,640
하지만 이는 훈련 중에 가중치를 업데이트하기 위한 계산이

507
00:50:24,640 --> 00:50:30,320
임베딩 자체가 더 낮은 정밀도를 사용하더라도 여전히 더 높은 정밀도를 사용할 수 있습니다.

508
00:50:31,440 --> 00:50:38,560
따라서 그들이 사용하는 방법은 일관성을 위해 더 무겁고 균일한 초기화로 초기화된 레이어입니다.

509
00:50:38,560 --> 00:50:44,080
변형을 적용한 다음 위치 임베딩을 추가하기 전에 레이어 표준을 적용합니다. 그래서 이거

510
00:50:44,080 --> 00:50:49,680
변형이 1 주위에 유지되도록 보장하고 불안정해질 수 있는 큰 기울기를 방지합니다.

511
00:50:50,560 --> 00:50:56,560
훈련. 따라서 이는 원래 최적화 프로그램을 변경하지 않고도 상당한 메모리 절약 효과를 제공합니다.

512
00:50:56,560 --> 00:51:01,840
하이퍼파라미터. 더욱 공격적인 상황에서도 안정적인 훈련이 가능합니다.

513
00:51:01,840 --> 00:51:09,840
양자화 기술이 사용됩니다. 다음은 결과 중 일부입니다. 보시다시피,

514
00:51:12,320 --> 00:51:19,360
이 표는 기본적으로 많은 NLP 및 컴퓨터 비전 작업의 평균 성능을 설명합니다.

515
00:51:20,080 --> 00:51:27,920
우리는 이 언어 모델과 변환기 작업에 중점을 둘 것입니다. 그래서 참고용입니다.

516
00:51:28,000 --> 00:51:38,000
보시다시피 이 8비트 아톰, 8비트 옵티마이저의 8비트 아톰은 시간을 줄이고 주로 메모리를 줄여줍니다.

517
00:51:38,000 --> 00:51:50,320
저장된 것은 엄청납니다. 따라서 일반 변압기에서는 8.5GB가 절약됩니다. 따라서 8비트가 성능이 뛰어납니다.

518
00:51:50,320 --> 00:52:04,000
모든 방법에서 메모리와 속도 측면에서. 그래서 이것은 꽤 좋은 논문이라고 말할 수 있습니다.

519
00:52:04,000 --> 00:52:12,320
하지만 미세 조정을 수행하는 다음 문서로 넘어가겠습니다. 그래서 대부분의 경우,

520
00:52:12,320 --> 00:52:18,720
대부분의 논문에서는 전체 교육을 수행할 시간이나 자원이 없습니다.

521
00:52:18,720 --> 00:52:24,640
대부분의 산업 사용 사례에서는 기존 LLM을 미세 조정하기만 하면 됩니다. 그래서 이 논문은,

522
00:52:24,640 --> 00:52:28,880
Chlora는 양자화된 LLM의 효율적인 미세 조정에 중점을 둡니다.

523
00:52:33,600 --> 00:52:41,920
이제 이 미세 조정 LLM은 메모리 집약적인 절차이며 650억 개 정도의 모델이 필요합니다.

524
00:52:41,920 --> 00:52:49,840
매개변수는 16비트 미세 조정을 위해 680GB 이상의 GPU가 필요합니다. 그래서 Chlora는 이 평균을 줄입니다.

525
00:52:49,840 --> 00:52:58,480
650억 개의 매개변수를 780GB에서 48GB까지만 미세 조정하는 데 필요한 메모리 요구 사항입니다. 그래서 이 방법은

526
00:52:58,480 --> 00:53:05,280
또한 chatGBT 성능 수준의 99%에 도달하고 24시간의 미세 조정만 필요합니다.

527
00:53:05,280 --> 00:53:10,640
단일 GPU에서. 이것은 정말 기념비적이고 놀라운 결과입니다. 그럼 가자

528
00:53:10,720 --> 00:53:20,320
이 아키텍처에 대해 자세히 알아보세요. 이제 기본적으로 일반적인 미세 조정은

529
00:53:20,320 --> 00:53:26,000
기본 모델과 최적화 상태 및 이 매개변수가 업데이트되고 그라데이션 흐름이 발생합니다.

530
00:53:29,040 --> 00:53:38,400
정상적으로 발생합니다. LLora는 트랜스포머 모델의 양자화였습니다.

531
00:53:38,480 --> 00:53:44,480
훈련 가능한 작은 매개변수 세트를 사용하여 메모리 요구사항을 줄입니다. 그래서 모든 매개변수는

532
00:53:44,480 --> 00:53:53,840
미세 조정에는 사용되지 않습니다. 훈련 가능한 매개변수의 작은 세트만 사용됩니다.

533
00:53:55,200 --> 00:54:01,680
흔히 어댑터라고 불린다. 따라서 전체 모델은 고정된 상태로 유지되며 이러한 어댑터는 업데이트 중에만 업데이트됩니다.

534
00:54:01,680 --> 00:54:06,800
미세 조정. 따라서 SGD 중 기울기는 사전 조정된 고정 모델을 통과합니다.

535
00:54:07,760 --> 00:54:16,000
그런 다음 손실 기능을 최적화하기 위해 업데이트되는 어댑터에 추가됩니다. Chlora는 이 방법을 개선합니다.

536
00:54:16,000 --> 00:54:21,760
변환기 모델을 4비트 정밀도로 양자화합니다. 따라서 16비트 변환기 대신

537
00:54:21,760 --> 00:54:29,520
우리는 4비트 변환기를 사용하고 있으며 메모리 급증을 처리하기 위해 페이지 최적화 프로그램도 사용하고 있습니다.

538
00:54:30,000 --> 00:54:38,720
따라서 우리는 곧 이 혁신에 대해 자세히 살펴보겠습니다. 따라서 이 논문의 핵심 혁신은 다음과 같습니다.

539
00:54:38,720 --> 00:54:45,520
그들은 새로운 데이터 유형 4비트 일반 부동 소수점을 도입했습니다. 이론적으로 그것은 정보입니다.

540
00:54:45,520 --> 00:54:51,760
정규 분포 중량에 최적입니다. 그들은 또한 이중 양자화를 활용하여

541
00:54:51,760 --> 00:54:57,120
평균 메모리 공간. 그래서 그들이 하는 일은 양자화를 수행하는 것입니다.

542
00:54:57,120 --> 00:55:02,560
양자화 상수도 양자화하고 있습니다. 그래서 이것은 이중 양자화이고 이것은 감소합니다

543
00:55:02,560 --> 00:55:07,760
메모리 사용 공간도 늘리고 메모리 스파이크를 관리하기 위해 페이징 최적화 프로그램을 사용하고 있습니다.

544
00:55:09,040 --> 00:55:14,320
이제 4비트 일반 부동 소수점에 대해 논의해 보겠습니다. 따라서 이 양자화 접근 방식은 다릅니다.

545
00:55:14,960 --> 00:55:20,720
이는 양자화 저장소 전체에 걸쳐 데이터 균형을 더욱 균등하게 유지합니다. 전통적인 방법은 그렇지 않을 수도 있습니다.

546
00:55:20,720 --> 00:55:25,200
특히 이상치가 있거나 값의 범위가 넓은 경우 데이터를 균일하게 배포합니다.

547
00:55:25,760 --> 00:55:30,160
따라서 이 방법은 각 Bin의 값 수를 균등화하는 데 중점을 둡니다.

548
00:55:30,160 --> 00:55:35,360
정규 분포를 최적화합니다. 따라서 이는 정보 손실을 최소화하는 것을 목표로 합니다.

549
00:55:35,360 --> 00:55:41,040
양자화 과정. 따라서 이는 일반적으로 신경망 가중치에 특히 적합합니다.

550
00:55:41,040 --> 00:55:46,400
정규분포를 따른다. 그래서 그들은 이상치를 더 균등하게 퍼뜨렸습니다. 그것들을 넣는 대신

551
00:55:46,400 --> 00:55:51,520
덩어리나 상자 안에 함께 넣은 다음 양자화하면 이상값이 더 균등하게 퍼집니다.

552
00:55:51,520 --> 00:55:55,840
정규 분포의 형태로 전체를 더 잘 표현할 수 있습니다.

553
00:55:55,840 --> 00:56:00,640
더 적은 수의 비트로 배포합니다. 그래서 이것은 전통적인 방법보다 더 효율적입니다.

554
00:56:02,480 --> 00:56:08,240
이제 이중 양자화입니다. 따라서 이것은 양자화 상수를 압축하는 2단계 프로세스입니다.

555
00:56:08,240 --> 00:56:13,520
첫 번째 양자화 단계에서 사용되는 것입니다. 따라서 이는 양자화를 더욱 압축합니다.

556
00:56:13,520 --> 00:56:18,720
메모리를 절약하기 위한 상수입니다. 상수에 대한 보조 양자화 프로세스를 구현합니다.

557
00:56:18,720 --> 00:56:24,400
메모리 손실 없이 메모리 공간을 줄이기 위해 8비트 부동 소수점을 사용합니다. 그래서 이것은

558
00:56:24,400 --> 00:56:29,280
두 번째 양자화 계층을 추가함으로써 기존의 단일 단계 양자화와 다릅니다.

559
00:56:29,280 --> 00:56:37,760
상수. 따라서 이는 매개변수 메모리 비용을 크게 줄입니다. 페이지 최적화 프로그램은

560
00:56:37,760 --> 00:56:44,800
CPU와 GPU 간의 자동 페이지 간 전송. 이것은 컴퓨터 네트워크 측면에 더 가깝습니다.

561
00:56:44,800 --> 00:56:49,840
LFE GPU 처리를 위한 것입니다. 따라서 GPU에 가끔 메모리가 부족해지면

562
00:56:50,720 --> 00:56:57,440
GPU와 이 CPU 간에 페이지 간 전송을 수행합니다. 이는 NVIDIA를 활용합니다.

563
00:56:57,440 --> 00:57:05,600
통합 메모리 기능. 이제 clora와 표준 미세 조정을 비교해 보겠습니다. 그래서 이것들은 몇몇입니다

564
00:57:05,600 --> 00:57:13,680
1억 2천 5백만에서 650억까지 다양한 크기의 LLM, OPT, Bloom, Pithya 및 Lama를 양자화했습니다.

565
00:57:13,680 --> 00:57:19,360
다양한 데이터 유형을 사용합니다. 따라서 그들은 언어 모델링과 일련의 제로샷 작업에 대해 평가됩니다.

566
00:57:19,360 --> 00:57:28,080
다양한 4비트 드릴 유형을 사용하는 라마 모델을 사용한 평균 제로샷 정확도는 다음과 같습니다. 그리고 우리처럼

567
00:57:28,080 --> 00:57:36,880
볼 수 있듯이, 그들이 도입한 일반 부동 소수점, 일반 4비트 부동 소수점 및 동적 양자화

568
00:57:36,880 --> 00:57:44,960
평균 제로샷 정확도에서 다른 방법보다 성능이 뛰어나며 심지어 일반 방법보다 성능이 뛰어납니다.

569
00:57:44,960 --> 00:57:51,360
부동 데이터 유형. 죄송합니다. 일반적인 float 데이터 유형과 일반 float 데이터 유형이 아닙니다.

570
00:57:53,760 --> 00:58:00,000
따라서 이중 양자화는 약간의 이득만 가져온다는 것을 알 수 있습니다.

571
00:58:00,000 --> 00:58:04,640
특정 크기의 모델에 맞게 메모리 공간을 세밀하게 제어합니다.

572
00:58:07,760 --> 00:58:13,360
이는 또한 더미 공통 크롤링 데이터 세트에 대한 일부 결과이며 이는 평균입니다.

573
00:58:13,360 --> 00:58:19,040
다양한 데이터 유형에 대한 Pexity별. 보시다시피 일반 부동 소수점과 동적 양자화

574
00:58:19,040 --> 00:58:27,840
다른 방법보다 성능이 뛰어납니다. 이제 16비트 미세 조정과의 비교입니다.

575
00:58:28,160 --> 00:58:44,800
Roberta와 T5 모델은 실제 8천만에서 110억까지입니다. 그리고 이제 그들은 질문을 하고 있습니다.

576
00:58:44,800 --> 00:58:51,600
4비트 어댑터 미세 조정을 수행하면 4비트 추론에서 손실된 성능을 복구할 수 있습니까?

577
00:58:51,600 --> 00:58:59,280
그래서 그들은 변환기를 4비트로 양자화하고 추론을 비교하고 있습니다.

578
00:59:00,960 --> 00:59:05,200
그래서 그들의 방식에서는 4비트 어댑터 미세 조정을 다른 방식과 연결하여,

579
00:59:05,200 --> 00:59:13,040
그들은 이 어댑터 미세 조정을 수행하지 않았으며 4비트 추론만 수행했습니다. 보시다시피,

580
00:59:13,040 --> 00:59:19,120
우리는 두 데이터 세트 모두에 대해 16비트, 8비트 및 4비트 어댑터 방법이 있음을 관찰했습니다.

581
00:59:19,120 --> 00:59:23,280
완전히 미세 조정된 16비트 기본 모델의 성능을 재현합니다.

582
00:59:26,720 --> 00:59:32,480
이는 부정확한 양자화로 인한 성능 손실을 완전히 복구할 수 있음을 의미합니다.

583
00:59:32,480 --> 00:59:40,480
양자화 후 어댑터 미세 조정을 통해. 그리고 지금은 챗봇 상태로 clora에 대해 논의하고 있습니다.

584
00:59:40,480 --> 00:59:46,960
예술. 보시다시피 Guanaco는 clora와 함께 사용한 모델입니다. 그리고 우리가 볼 수 있듯이,

585
00:59:46,960 --> 00:59:58,400
평균 정확도 또는 제로 샷 정확도에서 이 모델은 다른 모든 모델보다 성능이 뛰어납니다.

586
00:59:58,400 --> 01:00:05,200
따라서 양자화된 4비트 모델을 아무런 조정 없이 미세 조정하는 것이 가능하다고 안전하게 말할 수 있습니다.

587
01:00:05,200 --> 01:00:13,920
성능 저하. 이는 다양한 크기의 라마를 미세 조정한 결과이기도 합니다.

588
01:00:13,920 --> 01:00:22,000
그리고 해당 데이터 세트. 보시다시피 모든 결과는 매우 비슷합니다.

589
01:00:23,040 --> 01:00:26,240
미세 조정 결과 없이 라마에게.

590
01:00:32,080 --> 01:00:37,680
이제 다음 문서인 대규모 언어 모델을 위한 BitNet 스케일링 1비트 변환기로 넘어갑니다.

591
01:00:38,560 --> 01:00:45,920
처음에 1비트 변환기를 사용하는 것에 대해 읽으면 꽤 놀랍습니다.

592
01:00:46,720 --> 01:00:51,680
따라서 우리는 이 문서를 자세히 살펴보고 실제로 이를 어떻게 구현하는지 살펴보겠습니다.

593
01:00:52,640 --> 01:00:59,280
이것은 매우 흥미로운 논문입니다. 이제 이것은 확장 가능하고 안정적인 1비트 변환기입니다.

594
01:00:59,280 --> 01:01:06,160
건축학. 그들은 BitLinear를 소개합니다. 기본적으로 nn.linear 레이어를 변환합니다.

595
01:01:06,160 --> 01:01:11,280
신경망의 선형 레이어를 BitLinear 레이어로 변환합니다. 그리고 그것은

596
01:01:14,560 --> 01:01:20,320
처음부터 1비트 가중치를 훈련하기 위해 만들어졌습니다. 그래서 그들은 처음부터 훈련을 수행하고 있습니다.

597
01:01:20,320 --> 01:01:26,800
하지만 그들은 1비트 변환기를 사용하고 있습니다. 따라서 가중치의 정밀도는 1비트입니다.

598
01:01:28,000 --> 01:01:31,280
따라서 그들은 1비트 정밀도 가중치에 대해 직접 훈련하고 있습니다.

599
01:01:31,920 --> 01:01:38,400
훈련 후 정밀도가 감소합니다. 이제 이 문서의 주요 혁신 중 일부

600
01:01:38,400 --> 01:01:47,280
양자화 인식 훈련입니다. 따라서 이 모델은 무게가 제한되어 있어도 성능이 좋습니다.

601
01:01:47,280 --> 01:01:53,120
1비트 표현으로. 모델을 양자화하는 다른 모델과 달리

602
01:01:53,120 --> 01:01:58,240
훈련 후에는 훈련 중에 양자화됩니다. 그래서 훈련은 그런 사람들과 함께 이루어집니다.

603
01:01:58,240 --> 01:02:05,520
런타임 중 가중치의 1비트 표현입니다. 그래서 그들은 또한 다른 배포를 하고 있습니다.

604
01:02:05,520 --> 01:02:10,800
최적화 상태에 대한 고정밀 모델 병렬성과 같은 최적화 기술 및

605
01:02:10,800 --> 01:02:17,360
낮은 정밀도 훈련으로 인한 문제를 해결하기 위해 그라디언트를 사용하고 큰 학습 속도를 사용합니다.

606
01:02:17,360 --> 01:02:27,120
무게. 이제 이것은 아키텍처 다이어그램입니다. BitLinear 레이어의 세부 사항입니다.

607
01:02:27,120 --> 01:02:33,120
그리고 이것이 전체적인 아키텍처입니다. 기본적으로 선형 레이어를 BitLinear로 대체합니다.

608
01:02:33,120 --> 01:02:40,880
레이어. 입력이 들어와서 레이어 정규화를 한 후, 절대값 양자화(absmax Quantization)를 합니다.

609
01:02:40,880 --> 01:02:46,400
가중치를 1비트로 변환하기 위해 수행됩니다. 그런 다음 이는 비정합화되고 출력은 다음과 같습니다.

610
01:02:46,400 --> 01:02:53,440
생산. 그리고 각각에는 BitLinear 레이어의 두 블록이 있습니다.

611
01:02:53,520 --> 01:03:02,080
피드포워드 네트워크. 그리고 그 뒤에는 Gal U가 따라옵니다. 그리고 BitLinear도 마찬가지입니다.

612
01:03:02,080 --> 01:03:06,080
주의 투영 층, 주의 층, 피드포워드 층,

613
01:03:06,800 --> 01:03:13,680
가중치를 1비트로 변환하기 위해 BitLinear가 적용됩니다. 그래서 BitLinear의 참신함은 기본적으로

614
01:03:13,680 --> 01:03:20,400
학습 안정성과 모델 정확도를 유지하는 능력에 있습니다.

615
01:03:20,400 --> 01:03:26,320
가중치를 1비트로 극단적으로 양자화합니다. 따라서 다른 방법에서는 일반적으로 발견되지 않습니다.

616
01:03:31,280 --> 01:03:38,240
이제 가중치는 기본적으로 마이너스 1 또는 1을 할당하는 사인 함수를 사용하여 이진화됩니다.

617
01:03:38,240 --> 01:03:43,120
체중 표시를 기준으로 합니다. 따라서 가중치가 0보다 크면 1의 값이 부여됩니다. 그리고 만약에

618
01:03:43,120 --> 01:03:49,600
0보다 작으면 마이너스 1 값이 할당됩니다. 따라서 스케일링 계수는 다음과 같이 계산됩니다.

619
01:03:49,600 --> 01:03:55,280
이진화된 가중치와 원래 가중치 간의 차이를 최소화합니다. 그래서 가중치는

620
01:03:55,280 --> 01:03:59,760
계산 중에는 마이너스 1과 1이 됩니다. 그런 다음 스케일링 계수가 계산됩니다.

621
01:03:59,760 --> 01:04:04,640
이진화된 가중치와 가중치 간의 차이를 최소화하기 위한 디콘타이제이션 절차

622
01:04:04,640 --> 01:04:10,880
원래 가중치. 활성화 함수는 텐서에 대해 8비트 정밀도로 양자화됩니다.

623
01:04:10,880 --> 01:04:17,600
효율성과 안정성을 위해 훈련 중에 그리고 추론 중에 토큰별로. 따라서 가중치는 양자화됩니다.

624
01:04:17,600 --> 01:04:25,040
학습 중에는 1비트로 활성화 함수는 8비트로 양자화됩니다. 그리고 추론하는 동안,

625
01:04:25,040 --> 01:04:32,640
토큰별로 양자화됩니다. 이제 이러한 BitLinear 가중치는 이진화되고 다음과 같습니다.

626
01:04:32,640 --> 01:04:42,240
평균이 0이 되도록 중앙 집중화되었습니다. 따라서 기본적으로 가중치를 얻으면 먼저 이를 중앙 집중화하여

627
01:04:42,240 --> 01:04:49,760
평균은 0입니다. 그러면 우리는 그 부호에 더하기 1이나 빼기 1을 얻게 될 것입니다. 그런 다음 게시물과 스케일링

628
01:04:49,760 --> 01:04:54,320
요인은 원래 가중치 분포와 일치하도록 이진화 후에 적용됩니다.

629
01:04:58,880 --> 01:05:07,040
BitLinear의 활성화 함수는 B비트 정밀도로 양자화됩니다. 이 실험에서는

630
01:05:07,120 --> 01:05:13,440
출력 변화를 보장하면서 8비트 정밀도(abs max)로 양자화되었습니다.

631
01:05:13,440 --> 01:05:20,880
안정성을 위해 유지됩니다. 이는 범위를 확장하고 레이어 표준을 수행하여 수행됩니다.

632
01:05:22,320 --> 01:05:29,040
그리고 비선형 함수 이전의 활성화는 빼기를 통해 0과 Q8 범위로 확장됩니다.

633
01:05:29,040 --> 01:05:32,240
모든 값이 음수가 아닌 입력의 최소값입니다.

634
01:05:33,040 --> 01:05:41,840
전체 정밀도 계산을 위해 출력의 분산

635
01:05:42,800 --> 01:05:47,840
출력의 변화는 표준 초기화 방법을 사용하는 것의 규모입니다.

636
01:05:47,840 --> 01:05:53,360
샘플 등반 또는 더 무거운 초기화는 훈련 안정성에 큰 이점이 있습니다.

637
01:05:53,360 --> 01:06:01,120
따라서 양자화 후 분산을 보존하기 위해 그들은 양자화 전에 레이어 표준 함수를 도입합니다.

638
01:06:01,680 --> 01:06:07,200
활성화 양자화. 따라서 이러한 방식으로 출력 y의 분산은 다음과 같이 추정됩니다.

639
01:06:08,240 --> 01:06:19,200
ln 함수의 기대값, ln 함수의 기대값,

640
01:06:23,120 --> 01:06:29,520
이는 1과 같습니다. 따라서 BitLinear는 레이어 표준 계산에 이 분산을 사용합니다.

641
01:06:31,440 --> 01:06:42,080
또한 그룹 양자화 및 정규화를 사용하여 모델 병렬성을 수행합니다. 그래서 그들은 분할한다

642
01:06:42,080 --> 01:06:49,360
여러 장치의 행렬 곱셈이 모델 병렬성을 수행하는 방식입니다.

643
01:06:49,360 --> 01:06:54,960
그러나 거기에는 문제가 있습니다. 여기서 논의한 모든 매개변수와

644
01:06:54,960 --> 01:07:00,960
행렬 곱셈(알파, 베타 등)의 경우 전체 텐서에서 계산됩니다.

645
01:07:01,520 --> 01:07:07,840
따라서 이러한 텐서는 파티션 차원에 따라 독립적이지 않습니다. 그래서 그들이 하는 일은

646
01:07:07,840 --> 01:07:14,240
가중치와 활성화를 그룹으로 나눈 다음 각 그룹의 매개변수를 독립적으로 추정합니다.

647
01:07:16,560 --> 01:07:22,080
따라서 가중치 행렬 w의 경우 파티션 차원을 따라 g 그룹으로 나눕니다.

648
01:07:22,080 --> 01:07:25,600
그런 다음 각 그룹의 매개변수를 독립적으로 추정합니다.

649
01:07:26,160 --> 01:07:33,760
그리고 이 공식은 각 그룹 g에 대해 다음의 각 그룹 g에 대해 다음을 나타냅니다.

650
01:07:33,760 --> 01:07:42,240
행렬 w의 가중치를 사용하여 스케일링 인자와 정규화 인자를 계산합니다.

651
01:07:42,240 --> 01:07:48,160
특정 그룹 내의 가치를 기반으로 합니다. 따라서 이를 통해 지역화된 계산이 가능해집니다.

652
01:07:48,160 --> 01:07:53,920
광범위한 동기화가 필요 없이 모델 병렬성을 촉진하는 각 그룹

653
01:07:53,920 --> 01:07:59,600
네트워크의 다른 부분에 걸쳐. 따라서 모델 병렬 처리를 수행하는 동안 네트워크 IO가 줄어듭니다.

654
01:08:00,720 --> 01:08:06,960
따라서 훈련 중에 그들은 직선 추정기, 혼합 정밀도 훈련 및 대규모 모델을 사용합니다.

655
01:08:06,960 --> 01:08:13,680
학습률. 따라서 직선 추정기가 하는 일은 우회하는 방법을 사용하는 것입니다.

656
01:08:14,320 --> 01:08:19,760
이 미분 불가능한 함수는 역전파 동안 기울기를 근사화합니다. 그래서

657
01:08:19,760 --> 01:08:27,040
기본적으로 우리는 가중치가 1비트에 불과하다는 것을 알고 있기 때문에 이를 통과하도록 허용하면

658
01:08:27,040 --> 01:08:42,320
역전파를 사용하면 가중치가 줄어듭니다. 그러면 우리 업그레이드가 망가질 것 같아

659
01:08:42,320 --> 01:08:47,760
원래. 따라서 직선 추정기는 함수의 기울기를 추정합니다.

660
01:08:47,760 --> 01:08:52,880
구체적으로 말하면 임계 함수의 미분을 무시하고 들어오는 값을 전달합니다.

661
01:08:52,880 --> 01:08:58,320
함수가 항등 함수인 것처럼 그래디언트를 사용합니다. 기본적으로, 우리가 이진화할 때

662
01:08:58,320 --> 01:09:02,960
가중치의 기울기는 0이 됩니다. 따라서 역전파 중에는 다음을 우회합니다.

663
01:09:02,960 --> 01:09:06,880
이진화 함수를 사용하고 들어오는 그래디언트를 다음 레이어로 직접 전달합니다.

664
01:09:08,640 --> 01:09:13,360
따라서 최적화에 대한 한 가지 과제는 잠재 가중치에 대한 작은 업데이트입니다.

665
01:09:13,360 --> 01:09:17,840
종종 1비트 가중치에는 차이가 없습니다. 따라서 편향된 기울기가 발생합니다.

666
01:09:17,840 --> 01:09:23,600
특히 시작 부분에서 1비트 가중치를 기반으로 추정되는 업데이트

667
01:09:23,600 --> 01:09:28,400
훈련의. 따라서 직선 추정기는 이러한 임계값 레이어를 무시하고 그냥 통과합니다.

668
01:09:28,400 --> 01:09:34,880
바로 다음 레이어에 있습니다. 또한 혼합 정밀 교육도 실시합니다. 그래서 그들은 둘 다 low를 사용합니다

669
01:09:34,880 --> 01:09:40,160
가중치에 대한 정밀 양자화 및 최적화 상태에 대한 고정밀 저장

670
01:09:40,160 --> 01:09:46,240
훈련 안정성과 정확성을 유지하기 위한 경사도입니다. 그들은 또한 대규모 학습을 사용합니다.

671
01:09:46,240 --> 01:09:51,520
작은 업데이트에 대한 1비트 가중치에 대한 둔감성을 극복하는 속도로, 이는 달성하는 데 도움이 됩니다.

672
01:09:51,520 --> 01:09:59,200
더 빠른 수렴 및 더 빠른 달성을 보상하고 초기 훈련 단계를 보상합니다.

673
01:09:59,200 --> 01:10:05,120
도전. 이제 BitNet의 에너지 소비를 논의하면 엄청난 양의

674
01:10:06,000 --> 01:10:11,120
에너지 소비가 증가합니다. 보시다시피 행렬 곱셈이 있지만

675
01:10:11,120 --> 01:10:16,480
m에 n을 곱하고 n에 b를 곱합니다. 이것은 두 개의 행렬, 바닐라 변환기입니다. 그만큼

676
01:10:18,560 --> 01:10:26,000
예상 에너지 소비는 이러한 차원의 곱이 될 것이며 BitNet은

677
01:10:26,000 --> 01:10:33,200
이 제품들을 합산하여 사용합니다. 그래서 이것은 큰 충돌과 같습니다. 그래서 이 BitNet은 1비트를 연결합니다.

678
01:10:33,200 --> 01:10:37,920
처음부터 변압기. 따라서 에너지 효율적인 방식으로 경쟁력 있는 결과를 얻습니다.

679
01:10:38,560 --> 01:10:46,000
다음 슬라이드에서는 이러한 결과 중 일부를 볼 수 있습니다. 그래서 BitNet은 크게

680
01:10:46,880 --> 01:10:52,240
최첨단 양자화 방법보다 성능이 뛰어납니다. 그리고 모델 크기가 커짐에 따라

681
01:10:53,200 --> 01:10:58,880
절감 비용이 더욱 중요해집니다. 차이가 더 커집니다

682
01:10:58,880 --> 01:11:04,480
부동 소수점 16으로 훈련된 모델로 경쟁력 있는 성능을 달성합니다.

683
01:11:05,840 --> 01:11:13,760
여기에서 볼 수 있듯이 300억 개의 매개변수 모델과 에너지 차이를 비교해 보겠습니다.

684
01:11:13,760 --> 01:11:22,720
32비트에서 심지어 16비트 사이에서도 엄청납니다. 따라서 BitNet은

685
01:11:23,280 --> 01:11:27,120
다른 양자화 방법과 일반 방법이 사용하는 에너지.

686
01:11:30,320 --> 01:11:33,600
이제 이것은 제로샷 결과입니다.

687
01:11:37,680 --> 01:11:42,960
그들은 추론 에너지 소비를 정확도와 비교하고 있습니다. 그리고 우리가 볼 수 있듯이,

688
01:11:42,960 --> 01:11:54,960
BitNet은 FP16 변환기보다 성능이 훨씬 뛰어납니다. 정확도는 비슷하거나

689
01:11:54,960 --> 01:12:00,080
실제로는 약간 더 크지만 에너지 소비는 훨씬 적습니다.

690
01:12:00,560 --> 01:12:13,920
이제 FP16 트랜스포머와의 비교입니다. 그리고 그들은 이번에 손실을 비교하고 있습니다. 그래서 우리는

691
01:12:13,920 --> 01:12:21,360
보시다시피 BitNet은 훨씬 더 나은 손실을 달성합니다. 추론 비용은 훨씬 적지만,

692
01:12:21,360 --> 01:12:24,480
FP16 트랜스포머와 동일한 성능을 얻으려면

693
01:12:25,120 --> 01:12:37,600
이것도 몇 가지 결과입니다. 보시다시피, 실제로 양자화를 수행하려고 하면

694
01:12:38,320 --> 01:12:51,280
한 비트, BitNet은 가중치에 훈련 비트를 사용하는 유일한 비트입니다.

695
01:12:51,840 --> 01:13:00,880
훈련 가중치, 훈련 및 추론을 위한 단 1비트입니다. 그리고 우리는 볼 수 있습니다.

696
01:13:00,880 --> 01:13:08,960
하나의 비트 가중치만 보간하고 정확도를 보간하면,

697
01:13:08,960 --> 01:13:15,360
그러면 BitNet은 실제로 8비트만큼, 거의 8비트만큼 좋은 성능을 발휘합니다.

698
01:13:15,360 --> 01:13:25,840
무게. 그리고 모델 크기가 커질수록 에너지 비용 절감율은 38.8배 증가합니다.

699
01:13:25,840 --> 01:13:30,320
3천만 개의 매개변수 모델의 경우. 그래서 이 표에서는 이미 논의한 것 같습니다.

700
01:13:32,240 --> 01:13:40,640
계속해서 더 많은 다운스트림 작업을 수행하면 BitNet이 FP16보다 더 안정적입니다.

701
01:13:40,640 --> 01:13:46,560
동일한 학습률을 갖는 변환기. 우리는 매우 큰 학습률을 사용하는 것을 볼 수 있습니다.

702
01:13:46,560 --> 01:13:56,080
BitNet은 매우 작고 매우 작은 가중치를 설명합니다. 그렇다면 FP16과 비교하자면

703
01:13:56,080 --> 01:14:02,640
변환기, 그것은 FP16 변환기가 이 학습 속도에서도 전혀 수행할 수 있는 것과 같습니다.

704
01:14:03,920 --> 01:14:09,040
그리고 이것들은 또한 배포된 학습률이 다르고 혼란스럽습니다.

705
01:14:09,040 --> 01:14:16,960
비교됩니다. 따라서 이 학습률은 실제로 가장 낮은 혼란도에서 가장 잘 수행됩니다.

706
01:14:16,960 --> 01:14:22,080
따라서 이는 학습률이 높을수록 수렴이 더 좋아진다는 의미입니다.

707
01:14:25,360 --> 01:14:30,160
이제 이것은 훈련 후 양자화와의 몇 가지 비교입니다. 그리고 보시다시피 BitNet은

708
01:14:31,600 --> 01:14:35,600
이러한 모든 훈련 후 양자화 방법보다 성능이 뛰어납니다.

709
01:14:36,000 --> 01:14:42,320
그런데 실제로는 일반 변압기에 가장 가까운 변압기입니다.

710
01:14:42,320 --> 01:14:48,160
16비트 가중치와 16비트 활성화 기능을 갖춘 변환기. 그래서, 그리고 그에 비해,

711
01:14:48,160 --> 01:14:53,360
BitNet에는 1비트 가중치와 8비트 활성화만 있습니다. 이것들은 제로 짧고 거의 없습니다

712
01:14:53,360 --> 01:14:58,960
짧은 결과. 그리고 우리가 볼 수 있듯이 BitNet은 이 모든 것 중에서 가장 좋은 성능을 발휘합니다.

713
01:14:58,960 --> 01:15:09,520
그리고 이것들은 또한 다양한 데이터 세트를 사용한 추가 결과입니다. 그리고 우리가 볼 수 있듯이,

714
01:15:09,520 --> 01:15:16,240
BitNet은 이 모든 테이블에서 가장 좋은 성능을 발휘합니다. 그리고 그들은 또한

715
01:15:18,000 --> 01:15:23,280
예, 그렇습니다. 모든 데이터 세트 중에서 가장 높거나 비슷한 정확도를 가지고 있습니다.

716
01:15:23,280 --> 01:15:33,200
이제 이 백서의 핵심 내용은 BitNet이 경쟁력 있는 성과를 달성했다는 것입니다.

717
01:15:33,200 --> 01:15:39,040
기존 방식에 비해 기억력과 에너지 수요를 크게 줄이면서 작업 결과를 향상시킵니다.

718
01:15:39,040 --> 01:15:44,640
모델. 완전 정밀 모델과 유사한 스케일링 법칙을 따릅니다. 그래서 이것은 강함을 나타냅니다.

719
01:15:44,640 --> 01:15:49,040
규모를 더욱 확대할 가능성이 있습니다. 따라서 이 문서의 융합 계획에는 다음이 포함됩니다.

720
01:15:49,040 --> 01:15:54,480
BitNet의 크기 및 교육 단계를 포함하고 해당 응용 프로그램 및 기타 아키텍처를 탐색합니다.

721
01:15:55,760 --> 01:16:01,840
이것은 네 가지 양자화 절차를 논의하면서 만든 비교 차트입니다.

722
01:16:01,840 --> 01:16:07,040
우리가 논의한 것입니다. 보시다시피 정밀도에 관한 한,

723
01:16:07,040 --> 01:16:12,720
LLM은 8비트 양자화이고, 8비트 최적화 프로그램도 8비트 양자화입니다.

724
01:16:12,720 --> 01:16:18,800
Chlora는 4비트이고 BitNet은 1비트이며 활성화는 8비트입니다.

725
01:16:19,520 --> 01:16:23,120
사용할 기술은 벡터 방식 분해와 혼합 정밀도 분해입니다.

726
01:16:23,840 --> 01:16:31,200
8비트 최적화 프로그램은 블록 단위 양자화와 이중 양자화의 동적 이중 양자화를 사용합니다.

727
01:16:31,200 --> 01:16:37,440
또한 최적화 상태의 양자화. Chlora는 이중, 미안하지만 8비트 최적화 프로그램을 사용합니다.

728
01:16:37,440 --> 01:16:42,960
최적화 상태의 동적 양자화와 Chlora는 이중 양자화를 사용합니다.

729
01:16:42,960 --> 01:16:51,600
기반의 옵티마이저는 일반 흐름뿐만 아니라 새로운 데이터 유형입니다. 그리고 BitNet은 비트 선형 레이어를 사용합니다.

730
01:16:51,600 --> 01:16:57,440
및 그룹 양자화. LLMinted의 주요 혁신은 완전한 정밀도를 유지한다는 것입니다.

731
01:16:57,520 --> 01:17:03,840
8비트 비트의 성능. 8비트 옵티마이저는 옵티마이저 성능을 유지합니다.

732
01:17:06,240 --> 01:17:12,240
Chlora는 표준 하드웨어 및 GPU에서 크고 큰 모델의 미세 조정을 가능하게 합니다.

733
01:17:12,240 --> 01:17:19,200
단 1비트 정밀도의 BitNet 기술 변환기입니다. LLMinted 실험은 다음까지 수행되었습니다.

734
01:17:19,200 --> 01:17:25,760
1,750억 개의 매개변수. Chlora는 최대 650억 개의 매개변수를 사용했으며 BitNet은 일반 매개변수만 사용했습니다.

735
01:17:26,400 --> 01:17:30,960
대규모 언어 모델이 추가되었지만 향후 작업에서는 더 큰 모델을 사용하도록 추가되었습니다.

736
01:17:32,080 --> 01:17:38,720
LLMinted에는 성능 저하가 없습니다. 8비트 최적화 프로그램은 32비트 최적화 프로그램과 매우 유사하며

737
01:17:38,720 --> 01:17:44,160
Chlora는 또한 최첨단 모델에 매우 가깝고 BitNet은 경쟁력이 있고 비교할 수 있습니다.

738
01:17:44,160 --> 01:17:51,600
완전 정밀 변압기에. LLM의 효율성은 메모리 공간을 50%까지 줄이는 것입니다.

739
01:17:51,840 --> 01:17:58,160
8비트 최적화 프로그램은 또한 상당한 메모리 절약 효과를 제공하며 Chlora는 효율적으로 미세 조정을 수행합니다.

740
01:17:58,160 --> 01:18:04,640
제한된 리소스와 제한된 GPU 및 BitNet을 조정하면 메모리와 에너지 소비가 줄어듭니다.

741
01:18:04,640 --> 01:18:12,160
큰 차이로. LLMinted의 응용 프로그램에는 일반 대규모 LLM만 포함됩니다.

742
01:18:12,160 --> 01:18:17,040
8비트 옵티마이저는 대규모 언어 모델이나 다양한 작업을 위한 옵티마이저입니다.

743
01:18:17,040 --> 01:18:23,040
Transformers와 Chlora는 대규모 언어 모델의 미세 조정을 수행하고 BitNet은 교육용입니다.

744
01:18:23,040 --> 01:18:29,840
메모리와 에너지의 일부만 사용하는 대규모 언어 모델입니다. 그럼 그렇지, 이건

745
01:18:29,840 --> 01:18:31,520
내 발표를 마치겠습니다.