1
00:00:00,000 --> 00:00:13,460
안녕하세요, 제 이름은 Anthony Boyko입니다. 저는 제 파트너와 여러분이 방금 이야기하기 시작한 비전 트랜스포머 강의의 나머지 4개 논문에 대해 이야기할 것입니다.

2
00:00:13,460 --> 00:00:25,740
첫 번째는 신흥 자산이자 자체 감독 비전 변환기로서 라벨이 없는 자체 증류에 중점을 둡니다. 본 논문에서 제안하는 모델은 Dino라고도 한다.

3
00:00:25,740 --> 00:00:31,380
이는 비전 변환기에 대한 자체 감독 방식이며 이를 기반으로 합니다.

4
00:00:31,380 --> 00:00:46,140
몇 가지 규정에 따라 추가 미세 조정 없이 이웃 카나리아의 성공을 다이어트하고 강조하며 운동량 인코더와 다중 작물 확대가 필요합니다. 이에 대해서는 나중에 프레젠테이션에서 논의하겠습니다.

5
00:00:46,140 --> 00:00:49,040
라벨이 없는 자가 증류입니다.

6
00:00:49,040 --> 00:00:54,460
그것은 무엇입니까? 그래서 저는 아주 간략한 개요를 살펴보는 것으로 첫 번째 시작을 하려고 합니다.

7
00:00:54,460 --> 00:01:01,220
그것이 무엇인지, 이어서 덧붙이겠습니다. 점점 더 깊이 있게 될 것입니다. 입력 이미지 X를 상상해 보세요.

8
00:01:01,220 --> 00:01:10,340
우리는 한 쌍의 뷰 X 1과 X 2를 생성할 것입니다. 따라서 이것은 임의의 변환입니다. 이미지를 회전한다고 상상해 보세요.

9
00:01:10,340 --> 00:01:14,020
자르고, 흐리게 하고, 그런 성격의 것들을 말이죠.

10
00:01:14,020 --> 00:01:17,940
우리는 그것들을 네트워크 G 베타에 입력할 것입니다.

11
00:01:17,940 --> 00:01:23,380
이 경우 다이어그램은 학생 1명, 교사 1명이 있는 곳을 보여줍니다.

12
00:01:23,820 --> 00:01:27,340
각각 S와 T로 표시되지만 더 많은 학생을 가질 수도 있습니다.

13
00:01:28,260 --> 00:01:30,860
우리는 소프트 맥스에 표시된 대로 예측을 할 것입니다.

14
00:01:31,620 --> 00:01:36,780
그런 다음 확률을 사용하여 손실 함수가 교차 엔트로피인 손실을 계산하겠습니다.

15
00:01:38,660 --> 00:01:49,300
그런 다음 가중치를 업데이트합니다. 여기에서 알 수 있는 몇 가지 사항은 교사가 학생들의 지수 이동 평균에 영향을 받는다는 것입니다. 그 목적에 대해서는 나중에 설명하겠습니다.

16
00:01:49,540 --> 00:01:58,660
이것이 지수 이동 평균의 약자입니다. 교사 네트워크에 센터링 작업 중지 차원 붕괴가 있습니다.

17
00:01:59,740 --> 00:02:02,380
그리고 우리가 별로 원하지 않기 때문에

18
00:02:05,220 --> 00:02:11,940
교사는 예측을 통해 이를 학습합니다. 정지 경사도가 있습니다. 따라서 값이 업데이트되지 않습니다.

19
00:02:12,780 --> 00:02:23,940
먼저 네트워크 비용 함수에 대해 살펴보겠습니다. 예를 들어, 우리가 여기서 실제로 달성하려는 것은 무엇입니까? 글쎄, 우리는 전역 뷰 집합 X와 로컬 뷰 집합 X 1을 받았습니다.

20
00:02:23,940 --> 00:02:35,940
X 소수입니다. 죄송합니다. 교차 엔트로피 손실을 최소화하고 싶습니다. 이는 아키텍처의 다중 자르기 구성 요소인 아래 첨자 C 아래 L로 표시됩니다.

21
00:02:36,260 --> 00:02:46,940
저자가 사용했거나 이것이 아키텍처의 다중 자르기 구성 요소입니다. 저자는 224 제곱 및 96 제곱의 전역 보기를 사용합니다.

22
00:02:46,940 --> 00:02:50,700
그래서 이것은 작은 이미지와 큰 이미지입니다.

23
00:02:50,700 --> 00:03:00,300
전역 보기는 원본 이미지의 큰 부분입니다. 50%보다 큰 것을 상상해 보세요. 로컬 뷰는 작은 패치입니다.

24
00:03:01,300 --> 00:03:14,660
우리는 이 교차 엔트로피 손실을 사용하여 두 뷰를 최소화하거나 두 뷰 간의 손실을 최소화하려고 합니다. 따라서 전역 보기와 로컬 보기 사이에 있습니다. 그래서 이것이 차이점을 최소화하려는 방법입니다.

25
00:03:15,660 --> 00:03:30,020
그리고 첫 번째 합계는 세트 내의 모든 로컬 뷰이고 로컬 뷰는 글로벌 뷰와 동일하지 않음을 알 수 있습니다. 그런 다음 다양한 글로벌 관점을 모두 검토합니다.

26
00:03:30,020 --> 00:03:48,020
지식 증류와 달리 교사에게 우선순위는 없습니다. 그래서 우리는 학생들의 이전 반복을 사용하여 우선순위를 정함으로써 이 문제를 해결합니다. 그리고 이것은 운동량 인코더입니다.

27
00:03:49,020 --> 00:04:01,020
지수 이동 평균은 이 운동량 인코더가 작동하는 방식입니다. 이는 교사 네트워크가 가중치를 업데이트하는 방법에 대한 이전 반복을 기반으로 합니다.

28
00:04:01,020 --> 00:04:11,020
모델을 초기화하면 두 네트워크 모두 동일한 임의 가중치로 시작되기 때문입니다. 그러면 교사를 어떻게 업데이트합니까?

29
00:04:11,020 --> 00:04:20,020
근거가 없다면 학생을 기반으로 그렇게 하고 학생들은 이제 이 업데이트된 교사로부터 배울 것입니다.

30
00:04:20,020 --> 00:04:32,020
따라서 이것의 값은 일부 매개변수 람다입니다. 이는 기본적으로 원래 교사 네트워크에서 얼마나 많은 것을 유지하고 있는지를 나타냅니다. 그리고 학생들 사이의 그 가치의 역수입니다.

31
00:04:32,020 --> 00:04:46,020
따라서 이것은 기본적으로 원래 교사 네트워크에서 얼마나 많은 것을 유지하고 있는지에 대한 것이며 0과 1 사이의 값의 역수는 학생이 교사에게 얼마나 많은 영향을 미치는가가 될 것입니다.

32
00:04:46,020 --> 00:04:53,020
기본적으로 이동 평균이 얼마나 되는지가 교사에게 영향을 미칠 것입니다.

33
00:04:53,020 --> 00:05:03,020
그래서 앞서 센터링으로 붕괴를 피하는 것에 대해 이야기했습니다. 기본적으로 모델을 너무 많이 훈련하면 모델이 차원 축소를 경험할 수 있다는 것입니다.

34
00:05:03,020 --> 00:05:13,020
그런 일이 발생하면 유용한 예측 변수가 되지 않습니다. 이는 결과에서 일종의 변수를 잃었다는 의미이기 때문입니다.

35
00:05:13,020 --> 00:05:19,020
그러면 저자는 이를 어떻게 방지합니까? 음, 이 두 가지 작업입니다.

36
00:05:19,020 --> 00:05:33,020
개별적으로 사용하면 실제로 치수 축소가 더 빨라질 수 있음을 알 수 있습니다. 따라서 기본적으로 데이터 세트에 따라 둘 사이의 균형을 맞추는 작업입니다.

37
00:05:33,020 --> 00:05:40,020
센터링 작업을 사용하여 Teacher 네트워크의 업데이트 규칙이 각 배치의 평균에 종속되도록 조정합니다.

38
00:05:40,020 --> 00:05:49,020
기본적으로 이것이 의미하는 바는 각 배치와 훈련이 모든 값의 평균에 영향을 받기 때문에 분산이 적다는 것입니다.

39
00:05:49,020 --> 00:06:01,020
따라서 배치 간의 차이가 더 적다는 것을 알 수 있으며, 이는 각 업데이트로 인해 이상값의 영향을 덜 받을 가능성이 있음을 의미합니다.

40
00:06:01,020 --> 00:06:11,020
그러나 이는 결과적으로 그 격차가 줄어들기 때문에 훈련이 균일한 분포로 붕괴될 수 있음을 의미합니다.

41
00:06:11,020 --> 00:06:30,020
따라서 가장자리 강화인 샤프닝이 있습니다. 이는 반대 효과를 가지며 소프트맥스 정규화에서 낮은 온도를 사용하여 수행됩니다. 기본적으로 확률이 소프트맥스에 있거나 확연한 경우 차이가 발생합니다. 거기에 가치를 두세요.

42
00:06:30,020 --> 00:06:41,020
그리고 아래 값이 보이면 센터링 공식이 있습니다. 그래서 우리는 교사 네트워크를 갖고 있고 중심 값인 편향 항을 추가하고 있습니다.

43
00:06:41,020 --> 00:06:59,020
그런 다음 센터링 값은 배치 값을 기반으로 조정되는 일부 매개변수에 의해 계산됩니다. 즉, 해당 매개변수 M은 배치가 영향을 미치는 정도입니다.

44
00:07:00,020 --> 00:07:10,020
그래서 우리는 이것이 어떻게 이루어지는지, 이 모델이 달성하려는 목표는 무엇인지, 실제로 무엇을 사용하는지에 대해 많이 이야기했습니다.

45
00:07:10,020 --> 00:07:25,020
따라서 이를 위한 아키텍처는 입력 이미지를 가져와 이를 비전 변환기나 ResNet 백본에 공급한 다음 프로젝션 헤드를 통과하고 프로젝션 헤드는 3층 다층 퍼셉트론입니다.

46
00:07:25,020 --> 00:07:38,020
그런 다음 L2 표준에 공급되는 데 사용됩니다. 이 함수는 피타고라스와 매우 유사합니다. 여기서는 거리를 구하기 위해 각 구성 요소의 제곱근을 사용합니다.

47
00:07:38,020 --> 00:07:44,020
그런 다음 출력을 만드는 데 사용하는 완전히 연결된 레이어가 있습니다.

48
00:07:44,020 --> 00:07:54,020
이제 우리는 그들이 실행한 몇 가지 실험에 대해 살펴보겠습니다. 먼저 그들은 선형 및 k-근접 이웃 평가 모두에서 보고자 했던 ImageNet에서 이를 비교했습니다.

49
00:07:55,020 --> 00:08:02,020
그들은 ResNet 50과 비전 변환기 아키텍처 모두에서 이를 수행했습니다.

50
00:08:02,020 --> 00:08:11,020
그리고 디노가 모든 분야에서 최고의 성과를 내는 것을 볼 수 있습니다.

51
00:08:11,020 --> 00:08:18,020
또한 감독 방법을 비교할 때 소형 비전 변환기에서만 수행한 것을 볼 수 있습니다.

52
00:08:18,020 --> 00:08:30,020
따라서 이러한 테스트에서는 아키텍처 크기가 클수록 더 나은 결과를 볼 수 있습니다.

53
00:08:30,020 --> 00:08:49,020
여기서도 볼 수 있는 또 다른 점은 큰 8개 크기 패치가 있는 가장 큰 Dino 크기와 같이 이러한 더 큰 비전 변환기와 비교할 때 Dino에 대한 매개 변수가 훨씬 적다는 것입니다.

54
00:08:49,020 --> 00:08:59,020
크기가 16인 경우에도 85개의 매개변수가 표시되고 그 다음에는 312개와 63개의 이미지가 표시됩니다.

55
00:08:59,020 --> 00:09:07,020
그리고 나중에 실험에서 볼 수 있듯이 패치 크기가 작을수록 좋습니다.

56
00:09:07,020 --> 00:09:21,020
유일한 놀라운 점은 k-near 이웃이 어떤 이유로든 가장 큰 비전 변환기 네트워크에서 실제로 최고의 성능을 발휘하지 못한다는 것입니다. 가장 작은 것에서 더 나은 성능을 발휘합니다.

57
00:09:21,020 --> 00:09:33,020
이제 그들은 ImageNet의 네 가지 작업(이미지 검색, 복사 감지, 비디오, 즉시 분할 및 전송)에 대한 자기 지도 학습도 비교합니다.

58
00:09:34,020 --> 00:09:49,020
이미지 검색은 ImageNet 및 Google Landmarks V2 데이터 세트에서 평가되며 성공을 측정하는 방법은 평균 평균 정밀도를 통해 이루어지며 옥스퍼드와 파리를 두 위치로 다시 방문한 것을 기반으로 합니다.

59
00:09:49,020 --> 00:09:59,020
여기서 M과 H는 분할의 심각도를 나타내므로 중간 분할과 하드 분할이 모두 데이터세트에 내재되어 있습니다.

60
00:10:00,020 --> 00:10:14,020
이 실험에서 제가 조금 이상하게 생각하는 점 중 하나는 다른 모든 실험이 ImageNet에서 훈련된다는 것입니다. 여기서 가장 성과가 좋은 실험은 Google 랜드마크라는 다른 데이터세트에서 훈련됩니다.

61
00:10:14,020 --> 00:10:34,020
따라서 Google Landmarks를 사용하면 Dino가 가장 좋은 성능을 발휘하지만 동일한 데이터 소스에 대해 사전 학습되지 않았기 때문에 이 R101이 RMAC 아키텍처와 공정한 비교라고 반드시 생각하지는 않습니다.

62
00:10:34,020 --> 00:10:42,020
따라서 반드시 디노의 성과가 더 좋다는 것은 아닙니다.

63
00:10:42,020 --> 00:10:52,020
다음은 복사 감지입니다. 평가는 INRA 사본 데이터 데이터세트의 강력한 하위 집합에 대해 이루어집니다. 목표는 왜곡된 이미지를 감지하는 것입니다.

64
00:10:52,020 --> 00:11:06,020
기본적으로 앞서 말했듯이 우리는 다양한 효과를 수행할 수 있는 이러한 뷰를 만듭니다. 따라서 이것의 목표는 인공적인 증강 중 하나가 발생했는지 확인하는 것입니다.

65
00:11:07,020 --> 00:11:23,020
따라서 그들은 슬라이드에 설명된 데이터 세트에서 무작위로 샘플링된 10K 소멸자 이미지에 대해 이를 훈련하고 복사 감지는 기능에 대한 동일 부호 유사성을 사용하여 정밀도의 순위를 매깁니다.

66
00:11:24,020 --> 00:11:45,020
20,000개의 이미지가 특징을 사용하도록 학습되었으므로 이것이 의미하는 바는 모델을 미세 조정하거나 20,000개의 이미지에 대해 모델을 훈련한 다음 그 중 10,000개를 강화한 다음 감지할 수 있는지 확인하는 것입니다. 그 10,000.

67
00:11:46,020 --> 00:11:56,020
Dino가 더 작은 차원 크기와 더 작은 해상도에서도 최고의 성능을 발휘한다는 것을 알 수 있습니다.

68
00:11:56,020 --> 00:12:09,020
즉, 이는 해상도가 높을수록 모델이 작업해야 하는 픽셀이 더 많아지고 세분성 차이를 더 잘 볼 수 있기 때문에 꽤 큰 개선입니다.

69
00:12:10,020 --> 00:12:15,020
다음은 비디오 순간 분할입니다.

70
00:12:15,020 --> 00:12:19,020
기본적으로 우리는 비디오 파일의 특징을 추적하려고 합니다.

71
00:12:19,020 --> 00:12:24,020
예를 들어, 우리가 도로에서 운전하고 있고 운전 가능한 부분을 보고 싶다고 상상해 보세요.

72
00:12:24,020 --> 00:12:38,020
따라서 이것이 이 작업의 목표가 될 것입니다. 기본적으로 비디오가 진행되는 동안 자동차로 운전할 수 있는 부분이든, 카메라를 통해서든, 다양한 클래스를 유지하는 것입니다.

73
00:12:39,020 --> 00:12:49,020
날아다니는 동물처럼 영상 속 동물처럼 분리되는 것.

74
00:12:49,020 --> 00:12:57,020
ImageNet에서 훈련되었으며 이에 대해 두 가지 다른 측정항목을 사용합니다. 평균 영역 유사성이 있고 윤곽선이 있습니다.

75
00:12:57,020 --> 00:13:08,020
따라서 윤곽선은 선과 비슷하고 평균 영역은 전체 영역과 같습니다. 그래서, 하나는 가장자리와 같고 하나는 면적입니다.

76
00:13:08,020 --> 00:13:17,020
그리고 오른쪽에서 볼 수 있듯이 둘 사이의 평균과 같이 두 가지를 모두 비교한 다음 독립적으로 비교하는 것이 있습니다.

77
00:13:17,020 --> 00:13:30,020
그리고 Dino는 ImageNet 제품 중에서 최고의 성능을 발휘합니다. 그러나 훨씬 더 나은 성능을 보이는 다른 데이터 세트가 있었습니다.

78
00:13:30,020 --> 00:13:40,020
따라서 해당 데이터 세트에서도 이 작업을 시도했어야 했지만 ImageNet에서는 Dino가 가장 좋은 성능을 발휘했습니다.

79
00:13:48,020 --> 00:13:50,020
자, 여기 이 비디오의 몇 가지 예가 있습니다.

80
00:13:50,020 --> 00:13:59,020
즉각적인 세분화, 보다 질적인 결과를 보고 싶다면 빨간색 영역이 분할된 개체인 것처럼 볼 수 있습니다.

81
00:13:59,020 --> 00:14:09,020
그런 다음 감독된 접근 방식에서는 작은 빨간색 점을 더 많이 볼 수 있습니다. 특히 분할하려는 오리가 아닌 이미지의 오리 그룹에서 특히 그렇습니다.

82
00:14:10,020 --> 00:14:29,020
기본적으로 분할은 마스크를 얻는 것입니다. 그래서 우리는 행렬을 상상해 보면 객체가 특정 클래스에 있는 지점을 강조하려고 노력하고 있습니다.

83
00:14:29,020 --> 00:14:36,020
이에 대한 임계값은 60%이며 이는 변환기의 셀프 어텐션 맵을 기반으로 합니다.

84
00:14:36,020 --> 00:14:47,020
그리고 비교 유사성은 죄송합니다. 비교는 Pascal VOC12 데이터 세트의 이미지에서 자카드 유사성을 사용하고 있습니다.

85
00:14:47,020 --> 00:14:53,020
그리고 Dino는 모델과 비교했을 때 훨씬 더 나은 성능을 보였습니다.

86
00:14:53,020 --> 00:14:58,020
모델과 비교한 결과는 무작위와 거의 동일했습니다.

87
00:14:58,020 --> 00:15:10,020
다음 작업은 전이 학습입니다. 따라서 전이 학습을 평가할 때 Dino와 감독 방식은 두 네트워크 모두에 대해 거의 모든 데이터 세트를 수행합니다.

88
00:15:10,020 --> 00:15:27,020
그 차이는 매우 작습니다. 따라서 이들 중 대부분은 ImageNet과 같은 것 외에는 상당히 미미한 개선이지만 그럼에도 불구하고 여전히 개선된 것입니다.

89
00:15:27,020 --> 00:15:36,020
따라서 Dino의 폐지 연구는 기본적으로 Dino 모델의 어떤 부분이 실제로 다른 부분보다 더 유익한지 확인하려고 노력하는 것입니다.

90
00:15:36,020 --> 00:15:49,020
먼저, 작은 패치 크기가 더 나은 성능을 보인다는 점을 확인했습니다. 그러나 비용은 상당히 느립니다. 따라서 16 x 16 패치는 8 x 8 패치보다 성능이 더 나쁩니다.

91
00:15:50,020 --> 00:15:56,020
하지만 8 x 8 패치만 있으면 모델이 학습할 토큰이 더 많아지기 때문에 분명히 속도가 느려질 것입니다.

92
00:15:56,020 --> 00:16:03,020
그리고 처리량 대비 성능 증가를 통해 이를 확인할 수 있습니다.

93
00:16:03,020 --> 00:16:16,020
증가 이점이 더 두드러지는 곳은 DIT 변환기에서 16에서 8로 가는 것인데 비전 변환기에서는 여러 퍼센트 포인트 증가합니다.

94
00:16:16,020 --> 00:16:20,020
1번에 더 가까웠어요.

95
00:16:20,020 --> 00:16:29,020
다음으로, 기본적으로 Dino의 어떤 기능이 기본 설정과 비교하여 다양한 성능에 영향을 미치는지 강조합니다.

96
00:16:29,020 --> 00:16:38,020
예를 들어 싱크 혼 노브의 효과는 최소화됩니다. 해당 설정을 포함한다면.

97
00:16:38,020 --> 00:16:52,020
기본 모델과 비교하면 이웃을 사용할 수 있는 경우는 0.6%, 선형에서는 0.1%의 차이가 있습니다.

98
00:16:52,020 --> 00:17:02,020
그러나 운동량 인코더가 없으면 정확도는 0이 됩니다. 그래서 분명히 이것이 중요합니다.

99
00:17:02,020 --> 00:17:16,020
다음으로, 다작물은 약 5%이거나 각각의 연도 이웃 선형 감소를 보고 있는지 여부에 따라 4~5%입니다.

100
00:17:16,020 --> 00:17:23,020
마찬가지로 교차 엔트로피 대신 평균 제곱 오차로 이동하면 상당한 감소를 볼 수 있습니다.

101
00:17:33,020 --> 00:17:38,020
다음으로 마스크 자동 인코더가 확장 가능한 비전 학습자에 대해 이야기하겠습니다.

102
00:17:38,020 --> 00:17:54,020
따라서 이 문서에서는 비대칭 인코더 디코더 아키텍처를 소개합니다. 즉, 인코더는 데이터 세트의 하위 집합을 사용하고 디코더는 인코딩된 데이터와 학습된 구성 요소를 사용하여 나머지 입력 이미지를 표현한다는 의미입니다.

103
00:17:54,020 --> 00:17:59,020
그리고 의미 있는 지하 표면이 되기 위해 입력 이미지의 높은 비율을 마스킹하는 것을 보여줍니다.

104
00:17:59,020 --> 00:18:17,020
내 말은 이미지의 큰 부분을 통해 마스크처럼 학습하는 것은 비전 학습 및 마스크 자동 인코더 사용과 관련하여 좋은 예측 변수일 뿐이라는 것입니다.

105
00:18:17,020 --> 00:18:25,020
훈련 속도는 모델의 입력 매개변수에 따라 2.8배에서 4.1배로 증가합니다.

106
00:18:25,020 --> 00:18:33,020
그럼 먼저 마스크가 무엇인지부터 알아보겠습니다. 글쎄요, 제가 좀 더 일찍 얘기한 적이 있지만, 사용할 입력 이미지의 어떤 부분을 결정하는 데는 매트릭스를 사용하는 것입니다.

107
00:18:33,020 --> 00:18:49,020
따라서 왼쪽에 이 치타가 있는 경우 색칠된 모든 부분은 마스크에서 사용하려는 이미지 부분이고 나머지 모든 부분은 회색 섹션에서 0으로 표시됩니다.

108
00:18:49,020 --> 00:19:02,020
그리고 마스크의 목적은 그 이미지를 재구성하는 것입니다. 이것이 중간입니다. 오른쪽의 초기 입력 이미지가 주어지면 모델이 예측하는 재구성과 같습니다.

109
00:19:03,020 --> 00:19:14,020
그래서 우리가 알면 마스크가 무엇인지 알 수 있습니다. 자, 여기서는 어떤 전략이 중요할까요? 여기에서 볼 수 있듯이 무작위로 블록이 있고 그리드가 있는데 어느 것이 더 나은 성능을 발휘하는지 알 수 있습니다.

110
00:19:14,020 --> 00:19:24,020
이미지의 25%만 마스크하면 50, 75%가 서로 다른 성능 비율을 수행하는 등 다양한 크기는 어떻습니까?

111
00:19:24,020 --> 00:19:37,020
그리고 여기에서 볼 수 있듯이 무작위를 볼 때 그 중 가장 좋은 성능을 발휘한다는 것을 알 수 있습니다. 왜냐하면 그리드를 보는 것처럼 그리드가 있는 부분이 사물을 가리지는 않았지만요.

112
00:19:37,020 --> 00:19:47,020
매우 명확합니다. 마스크에 명확한 구분이 있는 블록 패턴과 같은 그리드가 있어 제대로 작동하지 않았습니다.

113
00:19:47,020 --> 00:19:59,020
그리고 블록에는 근처 어디에도 정보가 전혀 없는 흐릿한 부분과 유사한 유사한 부분이 표시됩니다. 따라서 무작위인 경우 해당 픽셀을 잘 예측할 수 없는 것과 같습니다.

114
00:19:59,020 --> 00:20:07,020
특정 측면은 전체적으로 약간 더 나쁠 수 있지만 이미지는 더 좋습니다.

115
00:20:07,020 --> 00:20:12,020
그럼 이제 마스크 자동 인코더란 무엇일까요? 잘,

116
00:20:13,020 --> 00:20:21,020
우리는 지난 논문에서 했던 것처럼 간단한 접근 방식을 시작할 것이고, 그것을 설명하는 방법을 천천히 확장하여 더욱 복잡하게 만들 것입니다.

117
00:20:21,020 --> 00:20:32,020
먼저 입력 이미지를 가져와 입력의 일부를 무시하거나 마스킹한 다음 인코더에 입력합니다.

118
00:20:32,020 --> 00:20:40,020
남은 데이터에 몇 가지 추가 기능을 추가합니다. 이것이 위치 데이터입니다. 이것이 우리가 배우려고 하는 기능입니다.

119
00:20:40,020 --> 00:20:46,020
따라서 디코더가 이미지를 다시 생성할 수 있을 때입니다.

120
00:20:46,020 --> 00:20:52,020
그런 다음 이미지를 디코딩하면 해당 데이터를 사용하여 재구성합니다.

121
00:20:52,020 --> 00:20:55,020
우리는 디코딩된 데이터를 사용하여 이미지를 재구성합니다.

122
00:20:55,020 --> 00:21:04,020
오른쪽 그림에는 대량 데이터가 있습니다. 우리는 이 대량 데이터만 포함합니다. 이 파란색 부분은 마스크가 있던 부분의 안개를 나타냅니다.

123
00:21:04,020 --> 00:21:11,020
또는 이러한 입력 이미지에 대한 위치 데이터와 같은 경우 다른 모든 것은 회색 사각형이거나 디코더에서 학습하려는 것입니다.

124
00:21:11,020 --> 00:21:17,020
그런 다음 디코딩된 데이터를 통해 이미지를 재구성합니다.

125
00:21:17,020 --> 00:21:28,020
좀 더 공식적으로는 입력을 일련의 패치로 정의하면서 이에 접근합니다. 이것이 바로 그리드입니다. 우리는 해당 패치 세트를 샘플링하고 나머지는 마스크합니다.

126
00:21:28,020 --> 00:21:32,020
따라서 각 패치는 이전 사각형에 그리드가 있습니다.

127
00:21:32,020 --> 00:21:39,020
마스크 인코더는 비전 변환기를 사용하여 마스크되지 않은 패치를 입력으로 사용합니다.

128
00:21:39,020 --> 00:21:48,020
마스크되지 않은 패치를 삽입합니다. 그런 다음 일련의 변환기 블록을 사용하여 이를 처리합니다. 이에 대해서는 나중에 자세히 설명하겠습니다.

129
00:21:48,020 --> 00:22:00,020
디코더는 인코딩된 가시 패치이자 마스크 토큰 세트입니다. 이러한 대량 토큰은 누락된 각 패치를 나타내는 공유 학습 기능 벡터입니다.

130
00:22:00,020 --> 00:22:13,020
여기서 재구성 대상은 재구성된 이미지를 형성하기 위해 재구성되는 디코더의 출력입니다. 그리고 우리는 예측된 이미지와 원본 이미지 사이의 평균 제곱 오차에 대한 손실을 입력했습니다.

131
00:22:13,020 --> 00:22:18,020
따라서 폐지 연구는 다시 한번 모델에서 중요한 것입니다.

132
00:22:18,020 --> 00:22:27,020
그래서 그들이 비교하는 두 가지 다른 것이 있습니다. 미세 조정 및 선형 프로브입니다.

133
00:22:27,020 --> 00:22:31,020
인코더의 일부입니다. 그래서.

134
00:22:31,020 --> 00:22:39,020
첫 번째 부분은 '얼마나 많은 블록을 해야 할까요?'라고 말하는 것입니다.

135
00:22:39,020 --> 00:22:44,020
그리고 너무 멀리 가고 싶지 않은 중간 지점이 있다는 것을 알 수 있습니다.

136
00:22:44,020 --> 00:22:50,020
우리는 두 모델 모두 미세 조정과 선형을 모두 수행하여 8에서 가장 좋은 성능을 발휘했습니다.

137
00:22:50,020 --> 00:22:54,020
그리고 너비.

138
00:22:54,020 --> 00:23:00,020
그것은 특징 벡터가 얼마나 현명한가입니다.

139
00:23:00,020 --> 00:23:05,020
나는 이것이 또한 입력 이미지 크기와 더 많은 관련이 있다고 생각합니다.

140
00:23:05,020 --> 00:23:09,020
512에서 더 나은 성능을 발휘합니다.

141
00:23:09,020 --> 00:23:13,020
그리고 다음은

142
00:23:13,020 --> 00:23:21,020
대량 토큰을 사용하거나 더 나은 인코딩을 사용하지 않고 인코딩합니다.

143
00:23:21,020 --> 00:23:23,020
그리고 당신은 볼 수 있습니다.

144
00:23:23,020 --> 00:23:27,020
그래서 무리는 그것이 얼마나 많은 복잡성을 추가하는지와 비슷합니다.

145
00:23:27,020 --> 00:23:32,020
대량 토큰을 포함하지 않는 경우. 그래서 기본적으로 우리는 단지 포함합니다.

146
00:23:32,020 --> 00:23:37,020
이미지에서 의미 있는 입력이 되는 부분입니다.

147
00:23:38,020 --> 00:23:43,020
선형 프로빙 성능이 크게 향상되고 미세 조정이 약간 증가한 것을 확인하세요.

148
00:23:43,020 --> 00:23:48,020
하지만 처리해야 하는 작업은 3.3배 적습니다.

149
00:23:48,020 --> 00:23:51,020
그래서 속도가 크게 향상되었습니다.

150
00:23:51,020 --> 00:23:53,020
재건축 대상이 되는 곳.

151
00:23:53,020 --> 00:24:00,020
PCA 또는 정규화 성능이 더 나은 픽셀을 볼 수 있습니다.

152
00:24:00,020 --> 00:24:03,020
토큰 접근 방식.

153
00:24:03,020 --> 00:24:05,020
그리고 날짜 확대.

154
00:24:05,020 --> 00:24:14,020
무작위 크기로 자른 것이 큰 크기로 자른 것보다 성능이 더 좋습니다.

155
00:24:14,020 --> 00:24:17,020
응.

156
00:24:17,020 --> 00:24:24,020
그리고 대량 샘플링. 이것이 비율과의 차이점입니다.

157
00:24:24,020 --> 00:24:32,020
어떤 종류의 전략과 여기에서 75% 마스크를 사용하는 무작위가 가장 효과적입니다.

158
00:24:32,020 --> 00:24:36,020
이제 모델과의 비교를 살펴보겠습니다.

159
00:24:36,020 --> 00:24:43,020
여기에서 볼 수 있듯이 Dino와 비교하면 더 좋습니다.

160
00:24:43,020 --> 00:24:54,020
또한 이미지 네트 1k뿐만 아니라 다른 데이터 세트에서도 미세 조정되는 경우에도 마찬가지입니다.

161
00:24:54,020 --> 00:25:01,020
그리고 모든 규모에서 더 나은 성능을 발휘합니다.

162
00:25:02,020 --> 00:25:09,020
그리고 네, 여기서 보게 될 또 다른 핵심 사항은 다음과 같습니다.

163
00:25:09,020 --> 00:25:15,020
큰 것 16, 큰 것 16, 거대한 것 16.

164
00:25:15,020 --> 00:25:22,020
모델이므로 모델의 크기와 패치 크기를 나타냅니다.

165
00:25:22,020 --> 00:25:33,020
그리고 이미지는 모두 224 x 224입니다. 단, 거대한 비전 트랜스포머의 크기는 448입니다.

166
00:25:33,020 --> 00:25:43,020
아니면 그 아래첨자가 있는 것.

167
00:25:43,020 --> 00:25:48,020
다음은 또 다른 주요 실험입니다. 기본적으로입니다.

168
00:25:48,020 --> 00:25:53,020
단순한 선형 프로빙이나 전체 미세 조정이 아닙니다.

169
00:25:53,020 --> 00:25:58,020
그들은 둘 사이에 미니 또는 미드 그라운드를 시도하고 싶어합니다.

170
00:25:58,020 --> 00:26:02,020
이것은 우리가 말할 수 있는 것과 같습니다.

171
00:26:02,020 --> 00:26:08,020
일부 변환기 블록과 같은 모델의 일부를 훈련합니다.

172
00:26:08,020 --> 00:26:11,020
그리고 모두 훈련하기보다는 결과를 개선하세요.

173
00:26:11,020 --> 00:26:19,020
선형 프로빙이 캡처하지 않기 때문에 이 작업을 수행하려는 경우 이 아이디어가 필요합니다.

174
00:26:19,020 --> 00:26:27,020
선형 방법이기 때문에 비선형 특성이지만 선형 특성에는 매우 좋습니다.

175
00:26:27,020 --> 00:26:32,020
미세 조정과 딥 러닝 접근 방식을 통해 이러한 비선형 특징을 포착할 수 있습니다.

176
00:26:32,020 --> 00:26:34,020
그래서.

177
00:26:34,020 --> 00:26:41,020
데이터 세트에 이러한 비선형 특징이 있다는 것을 알고 있다면 일부 변환기 블록을 미세 조정할 수 있습니다.

178
00:26:41,020 --> 00:26:44,020
그리고 그 순서는 구체적입니다.

179
00:26:44,020 --> 00:26:51,020
이 문서의 저자는 특정 변압기 블록을 순서대로 훈련했습니다.

180
00:26:51,020 --> 00:26:56,020
처음부터 시작하는 것이 아니라 모두가 동일한 이점을 갖지 않기 때문입니다.

181
00:26:56,020 --> 00:26:59,020
그러나 당신은 볼 수 있습니다.

182
00:26:59,020 --> 00:27:04,020
우리가 훈련할 때 의미 있는 차이를 만든다는 것입니다.

183
00:27:04,020 --> 00:27:08,020
4~6에서는 상당한 개선을 볼 수 있습니다.

184
00:27:08,020 --> 00:27:16,020
0과 반대로 18에서 24로 가더라도 12에서조차 큰 개선이 보이지 않습니다.

185
00:27:16,020 --> 00:27:24,020
따라서 부분적으로만 미세 조정하면 모델 속도가 크게 향상될 수도 있습니다.

186
00:27:24,020 --> 00:27:30,020
다음은 전이학습이다. 이는 모든 머신러닝에서 일반적인 작업입니다.

187
00:27:30,020 --> 00:27:35,020
우리가 무언가를 한 번 훈련하면 할 수 있습니다.

188
00:27:35,020 --> 00:27:39,020
구성 요소를 학습한 다른 작업으로 전환합니다.

189
00:27:39,020 --> 00:27:46,020
따라서 분기의 마스코트는 다른 모든 논문보다 더 나은 성능을 발휘합니다.

190
00:27:46,020 --> 00:27:53,020
그리고 다른 모든 데이터 세트에서는 당연히 가장 큰 모델이 더 나은 성능을 발휘합니다.

191
00:27:53,020 --> 00:28:05,020
여기서도 픽셀이나 토큰을 재구성 대상으로 사용하는 것과 비교하며 이들 간의 차이는 이 델타를 통해 하단에 표시됩니다.

192
00:28:05,020 --> 00:28:11,020
실제로 보면 둘 사이에 큰 차이가 없다는 것을 알 수 있습니다.

193
00:28:11,020 --> 00:28:16,020
토큰을 사용하는지, 정규화된 픽셀을 사용하는지 여부.

194
00:28:17,020 --> 00:28:30,020
따라서 다음 논문은 주의를 사용하지 않는 변환기에 대한 일반화된 아키텍처를 제안하는 비전에 실제로 필요한 메타포머입니다. 이는 풀링과 같은 간단한 토큰 혼합기도 경쟁력 있는 결과와 컴퓨터 비전 작업을 생성할 수 있음을 보여줍니다.

195
00:28:30,020 --> 00:28:42,020
메타 포머이므로 은유가 무엇인지, 모델인지 간략하게 설명하고 좀 더 깊이 들어가 보겠습니다.

196
00:28:43,020 --> 00:28:48,020
따라서 은유는 추상화된 아키텍처입니다. 변압기에서 운전하는 것입니다.

197
00:28:48,020 --> 00:29:06,020
그리고 여기서의 아이디어는 변환기로부터 주의를 제거하고 의도 의도가 토큰 믹서인 곳입니다. 비유가 일반화된 토큰 믹서를 사용하고 특정 구현에서 원하는 것을 사용할 수 있다고 가정해 보겠습니다.

198
00:29:06,020 --> 00:29:09,020
그리고 저자는 그것을 보여줍니다.

199
00:29:09,020 --> 00:29:22,020
더 복잡한 주의 작업 대신 풀 포머라고 불리는 이 아키텍처를 사용하면 이러한 블록을 갖는 방법과 같은 순서를 지정하는 메타 포머가 더 중요합니다.

200
00:29:22,020 --> 00:29:26,020
네, 그들은 이 풀링을 사용하고 있습니다.

201
00:29:26,020 --> 00:29:30,020
연결을 차단합니다.

202
00:29:30,020 --> 00:29:35,020
대신, 그리고.

203
00:29:35,020 --> 00:29:38,020
그럼 먼저 풀 포머(Poll Former)가 무엇인지부터 이야기해보겠습니다.

204
00:29:38,020 --> 00:29:44,020
죄송합니다. 여기로 다시 돌아가겠습니다. 이것들이 무엇인지 설명드리겠습니다. 그래서 당신을 상쾌하게합니다.

205
00:29:44,020 --> 00:29:54,020
이러한 변환기 블록은 일부 입력 임베딩을 가지고 있다는 것입니다. 그런 다음 토큰 믹서를 통해 정규화를 적용합니다. 그래서 토큰 믹서.

206
00:29:55,020 --> 00:30:05,020
입력 임베딩의 기능과 모델의 영향 정도에 영향을 미칩니다. 또 다른 정규화를 거친 다음 다층 퍼셉트론을 거쳐 입력을 증가시킵니다.

207
00:30:07,020 --> 00:30:10,020
이것이 바로 풀 전의 모습입니다.

208
00:30:13,020 --> 00:30:15,020
블록의 모습입니다.

209
00:30:16,020 --> 00:30:27,020
먼저 풀 이전 블록에 대해 이야기하겠습니다. 그것은 정규화, 풀링, 그리고 정규화, 즉 채널입니다.

210
00:30:27,020 --> 00:30:31,020
먼저 입력 이미지가 있습니다. 이 고양이가 있다고 가정 해 봅시다.

211
00:30:31,020 --> 00:30:37,020
세 개는 이미지의 빨간색, 녹색, 파란색이라는 서로 다른 채널일 뿐입니다.

212
00:30:37,020 --> 00:30:40,020
이미지를 삽입합니다.

213
00:30:40,020 --> 00:30:46,020
그리고 첫 번째 단계에서는 4개씩 다운샘플링합니다.

214
00:30:46,020 --> 00:31:04,020
이 단계에서는 아키텍처의 전체 블록 수의 6분의 1의 비율을 사용합니다. 따라서 이러한 변환기 아키텍처에서는 점점 더 많은 수의 블록을 가질 수 있습니다.

215
00:31:04,020 --> 00:31:09,020
그리고 이것은 기본적으로 그 비율이 그 숫자의 6분의 1이라고 말하는 것입니다.

216
00:31:09,020 --> 00:31:19,020
그런 다음 두 번째로 또 다른 패치 임베딩을 진행합니다. 풀 이전 블록의 6분의 1을 사용하여 다시 절반으로 줄였습니다.

217
00:31:19,020 --> 00:31:30,020
그런 다음 절반을 삽입한 후 다시 크기를 줄입니다. 그리고 이번에는 전체 블록 수의 절반을 사용한 다음 삽입하고 여섯 번째 블록을 수행합니다.

218
00:31:30,020 --> 00:31:32,020
그런 다음 출력을 생성합니다.

219
00:31:32,020 --> 00:31:42,020
하지만 네, 여기서 주목해야 할 핵심 사항은 풀 이전 블록의 비율입니다. 첫 번째 아키텍처가 있다고 가정해 보겠습니다. 가장 작은 크기는 6개였습니다.

220
00:31:42,020 --> 00:31:53,020
1단계, 2단계, 4단계에는 각각 하나의 블록이 있고 3단계에는 3개의 블록이 있습니다.

221
00:31:53,020 --> 00:32:05,020
결과는 다음과 같습니다. 이는 이미지 분류, 객체 감지 및 분할에 관한 것이며 세 가지 작업에 대한 정적 분할을 말합니다.

222
00:32:05,020 --> 00:32:20,020
여기에는 다양한 아키텍처가 있으며 비교 대상이 되는 다양한 유형을 나타냅니다. 예를 들어, 풀 포머(pool form)가 제안됩니다.

223
00:32:21,020 --> 00:32:29,020
모든 다층 퍼셉트론은 공간 MLP를 통해 수행됩니다. 그래서 그 사이트입니다.

224
00:32:29,020 --> 00:32:44,020
오른쪽 삼각형과 위쪽을 향한 삼각형은 주의 기반 토큰 믹서이고 아래쪽 삼각형은 공명이므로 다양한 유형의 토큰과 비교됩니다.

225
00:32:44,020 --> 00:32:50,020
토큰 믹서와 풀링은 매우 간단한 작업임에도 불구하고 그 모든 것보다 더 나은 성능을 발휘합니다.

226
00:32:50,020 --> 00:32:57,020
또한 이 최대값은 실제와 같은 수입니다.

227
00:32:57,020 --> 00:33:00,020
실제 컴퓨팅 작업을 수행해야 합니다.

228
00:33:00,020 --> 00:33:12,020
또한 더 작은 모델 크기가 왼손인 경우 모든 비교에서 더 낮은 숫자에서 더 나은 정확도를 수행합니다.

229
00:33:12,020 --> 00:33:18,020
객체 감지 및 즉각적인 분할.

230
00:33:18,020 --> 00:33:25,020
따라서 이것은 단지 다른 크기의 경계 상자와 비교하는 것입니다.

231
00:33:25,020 --> 00:33:40,020
마스킹 비율이 다릅니다. 따라서 소형, 중형, 대형 개체와 경계 상자의 비율 임계값 풀 이전이 resnet 비교보다 더 나은 성능을 발휘합니다.

232
00:33:40,020 --> 00:33:44,020
마스크 또는 훈련을 받았다는 점에서 빨간색입니다.

233
00:33:44,020 --> 00:33:50,020
그리고 작은 크기를 제외하면 매개변수도 적습니다.

234
00:33:50,020 --> 00:33:55,020
이는 다른 실험과 일치합니다.

235
00:33:55,020 --> 00:33:59,020
분할된 세분화입니다.

236
00:33:59,020 --> 00:34:04,020
훈련용으로 20K 이미지를 사용하고 검증용으로 2K 이미지를 사용했습니다.

237
00:34:04,020 --> 00:34:19,020
공진 기반 아키텍처와 장력 기반 아키텍처를 모두 비교한 결과, 모든 아키텍처보다 성능이 뛰어나고 매개변수 크기가 더 작습니다.

238
00:34:19,020 --> 00:34:28,020
여기서 목표 측정항목은 합집합에 대한 평균 교차점입니다.

239
00:34:28,020 --> 00:34:33,020
그래서 평가 연구는 그래서 이것이 괜찮다고 말하는 것입니다.

240
00:34:33,020 --> 00:34:36,020
이에 대한 결과가 일반화되었습니다.

241
00:34:36,020 --> 00:34:44,020
우리는 은유에 대해 이야기하고 있기 때문에 더 좋습니다. 우리는 변환기를 일반화할 수 있는지 알아보려고 합니다.

242
00:34:44,020 --> 00:34:48,020
그리고 그것이 단순한 관심이 아니라는 것을 보여주세요.

243
00:34:48,020 --> 00:34:51,020
따라서 풀링 크기를 조정하면 됩니다.

244
00:34:51,020 --> 00:34:58,020
성능에 약간의 차이가 있음을 알 수 있지만 크게는 아니지만 깊이 있는 컨볼루션으로 이동합니다.

245
00:34:58,020 --> 00:35:09,020
계산 시 성능 요구 사항과 유사하게 더 큰 증가를 확인할 수 있습니다.

246
00:35:09,020 --> 00:35:23,020
그리고 또 다른 것은 정규화를 향한 것입니다. 정규화가 없으면 배치와 레이어 간의 차이가 훨씬 더 심해집니다. 그러나 이 수정된 레이어 정규화가 가장 좋습니다.

247
00:35:23,020 --> 00:35:33,020
따라서 정규화가 없으면 relu 사이에 훨씬 더 나쁜 차이를 수행하고 Lou와 이러한 다른 활성화 레이어를 보면 약간의 차이가 있음을 알 수 있습니다.

248
00:35:33,020 --> 00:35:43,020
그리고 이와 같은 다른 구성 요소는 잔여 잔여 연결과 다층 퍼셉트론 헤드를 제거하면 됩니다.

249
00:35:43,020 --> 00:35:47,020
정확도는 거의 0에 가깝습니다.

250
00:35:47,020 --> 00:36:01,020
따라서 이는 이 아키텍처에 풀링을 사용했음에도 불구하고 아키텍처가 주의를 기울일 때 더 나은 성능을 발휘한다는 것을 보여줍니다. 그래서 여기에서는 3단계와 4단계를 전환했습니다.

251
00:36:01,020 --> 00:36:07,020
이는 주의 토큰 믹서가 포함된 전체 변압기 블록의 2/3에 해당합니다.

252
00:36:07,020 --> 00:36:24,020
수행해야 하는 계산과 매개변수의 약 3분의 1 증가보다 약간만 25%만 증가하면 성능이 몇 퍼센트 증가하는 것을 볼 수 있습니다.

253
00:36:24,020 --> 00:36:42,020
따라서 이 문서가 일반화에 중점을 두더라도 주의가 모델을 개선하지 않는다고 말하는 것이 아니라 아키텍처를 만들 때 실제로 집중하고 싶은 핵심 사항이 아니라고 말하는 것이 핵심입니다.

254
00:36:42,020 --> 00:36:52,020
다음은 변압기 기반 실시간 모바일 비전 애플리케이션을 위한 이전의 효율적인 추가 주의입니다. 그래서 여기에는 효율적인 덧셈 주의가 도입되었습니다.

255
00:36:52,020 --> 00:37:10,020
장력과 다른 모든 것들이 행렬 곱셈인 부가적 접근 방식을 사용하여 비용이 많이 드는 행렬 위치 작업을 줄입니다. 따라서 우리가 이러한 큰 입력과 많은 처리량을 처리할 때 우리는 많은 반복을 실행하기 때문에

256
00:37:10,020 --> 00:37:25,020
시간이 지남에 따라 다중 행렬 곱셈이 추가되는 비용이 많이 드는 작업입니다. 여기서 핵심은 우리가 소비한 대부분의 시간이 이러한 감소가 어떻게 발생하는지에 대해 이야기하는 것입니다.

257
00:37:25,020 --> 00:37:34,020
예, 우리가 상기한 바와 같이 주의 제곱은 차원과 함께 두 행렬 q와 k의 소프트 최대값을 취하여 계산됩니다.

258
00:37:34,020 --> 00:37:54,020
그리고 시간 복잡도는 차원 크기의 n 제곱배입니다. 그러나 K 대신 q를 전치하면 그 복잡성은 n 제곱 곱하기 d 대신 n 곱하기 d 제곱과 같이 d 제곱으로 이동합니다.

259
00:37:54,020 --> 00:38:06,020
Q, K, V는 변압기에 사용되는 세 가지 서로 다른 행렬입니다. 키, 값 및 쿼리입니다.

260
00:38:06,020 --> 00:38:22,020
따라서 주의력이 향상되는 첫 번째 방법은 분리 가능한 자기 주의력을 이용하는 것입니다. 따라서 K 쿼리가 주어지면 키 또는 K 키와 V 값이 요소별로 코딩됩니다.

261
00:38:22,020 --> 00:38:31,020
따라서 요소를 인코딩하는 경우 비선형적으로 확장되기 때문에 행렬 방식으로 인코딩하는 것보다 더 빠르게 수행됩니다.

262
00:38:31,020 --> 00:38:40,020
먼저 이를 수행하기 위해 쿼리 행렬 q를 하나의 벡터 q로 n에 투영하고 소프트 최대값을 적용하여 컨텍스트 점수를 생성합니다.

263
00:38:40,020 --> 00:38:51,020
컨텍스트 점수에 행렬 K를 곱하고 풀을 사용하여 컨텍스트 벡터 S와 V 간의 요소별 곱셈을 생성하여 어텐션 점수를 반환합니다.

264
00:38:51,020 --> 00:39:05,020
따라서 이 두 행렬을 단순히 곱하는 대신 여러 개의 작은 곱셈의 합을 얻습니다.

265
00:39:05,020 --> 00:39:18,020
다음은 전통적으로 주의가 세 가지 구성 요소에 따라 달라지는 것을 보았듯이 효율적인 추가 주의입니다. 인코딩 중에 이 키 값 상호 작용을 제거하면 어떻게 될까요?

266
00:39:18,020 --> 00:39:27,020
이것이 바로 효율적인 덧셈 주의입니다. 따라서 모델은 오히려 선형 생산 계층을 통해 해당 상호 작용을 유지합니다.

267
00:39:27,020 --> 00:39:38,020
이제 모델링은 두 개의 행렬 q와 K에 의존합니다. 그러면 이것이 어떻게 수행됩니까?

268
00:39:38,020 --> 00:39:51,020
이 글로벌 어텐션 쿼리 벡터를 생성합니다. 따라서 우리는 알파가 W 첨자 a와 같은 가중치가 어텐션 가중치에 대한 학습 가능한 매개변수인 이 쿼리 벡터를 나타내도록 할 것입니다.

269
00:39:51,020 --> 00:40:03,020
그리고 우리는 사전 행렬에 이 가중치 매개변수를 곱하여 이 쿼리 벡터를 계산합니다. 이 가중치 매개변수는 차원의 제곱으로 나뉩니다.

270
00:40:03,020 --> 00:40:07,020
이제 전역 쿼리 벡터를 만들어 보겠습니다.

271
00:40:07,020 --> 00:40:17,020
따라서 이것이 주의 점수와 같기 전에 요소별 곱셈을 통해 이 전역 쿼리 벡터를 생성하겠습니다.

272
00:40:17,020 --> 00:40:34,020
따라서 우리는 쿼리 행렬을 사용하여 학습된 Attention을 끌어 전역 쿼리 벡터를 생성합니다. 즉, 두 벡터의 요소별 곱셈의 합, 즉 Attention 벡터에 쿼리 벡터를 곱한 것입니다.

273
00:40:34,020 --> 00:40:42,020
쿼리 행렬과 효율적인 추가 주의 출력입니다.

274
00:40:42,020 --> 00:41:01,020
키 행렬 K와 전역 쿼리 벡터 q 사이의 요소별 곱셈이 수행됩니다. 따라서 이 단계의 시간 복잡도는 N 제곱 D 또는 N X D 제곱이 아니라 N x D입니다.

275
00:41:01,020 --> 00:41:05,020
그래서 당신은 선형 변환 차를 수행합니다.

276
00:41:05,020 --> 00:41:12,020
이것이 우리가 포함하지 않은 누락된 행렬을 유지하는 방법입니다. 그런 다음 정규화된 쿼리 행렬을 추가합니다.

277
00:41:12,020 --> 00:41:16,020
Q 모자. 그래서,

278
00:41:16,020 --> 00:41:30,020
이것이 하는 일은 E 행렬을 취하고 이 전역 쿼리 벡터를 곱하는 것입니다. 그리고 벡터이기 때문에 다른 행렬보다 빠르게 곱할 것입니다.

279
00:41:30,020 --> 00:41:51,020
그런 다음 선형 변환을 수행하여 누락된 상호 작용을 학습합니다. 그런 다음 이를 거대한 행렬의 용어로 추가합니다. 왜냐하면 우리는 선형 변환에 값이 전체 시스템에 미치는 영향을 포함시켰기 때문입니다.

280
00:41:51,020 --> 00:41:58,020
이제 이러한 차이점에 대한 보다 시각적인 접근 방식이 있습니다.

281
00:41:58,020 --> 00:42:06,020
앞서 설명한 방법입니다. 첫 번째는 일반적인 자기 관심입니다. 그것은 3개의 행렬 전치 1입니다.

282
00:42:06,020 --> 00:42:08,020
둘을 곱해 보세요.

283
00:42:08,020 --> 00:42:11,020
그런 다음 소프트 최대값을 실행합니다.

284
00:42:11,020 --> 00:42:18,020
그런 다음 값을 곱하십시오. 그런 다음 선형 레이어를 사용하여 출력을 만듭니다.

285
00:42:18,020 --> 00:42:30,020
가장 고통스러운 자기 주의는 Q 행렬의 요소별입니다. 그런 다음 곱셈을 수행하고 이를 풀링한 다음 값을 곱합니다.

286
00:42:30,020 --> 00:42:34,020
효율적인 첨가주의.

287
00:42:34,020 --> 00:42:39,020
해당 요소별 벡터에 주의 단계를 포함시키면 됩니다.

288
00:42:39,020 --> 00:42:41,020
그런 다음 그것들을 합산하면 됩니다.

289
00:42:41,020 --> 00:42:45,020
그리고 K를 곱합니다.

290
00:42:45,020 --> 00:42:48,020
그리고 그 변화를 수행합니다.

291
00:42:48,020 --> 00:43:08,020
또한 정규화도 포함됩니다. 따라서 각 self attention의 복잡성을 살펴보면 일반적으로 공간 차원의 공간 차원이고 미래 차원에서 N x N 전치 의도 사용과 D x D입니다.

292
00:43:08,020 --> 00:43:13,020
그런 다음 분리는 요소별 작업을 사용하여 효율성과 효율성을 향상시킵니다.

293
00:43:13,020 --> 00:43:21,020
더 작은 작업이 중요해지면서 관심이 한 단계 더 발전했습니다.

294
00:43:21,020 --> 00:43:32,020
Swift Quarter 인코더는 예, 그래서 우리는 주의 점수가 어떻게 계산되는지, 어떻게 계산되는지에 대해 이야기했습니다.

295
00:43:33,020 --> 00:43:41,020
그리고 변환기가 어떻게 학습하는지, 이제 우리는 이전 논문과 유사한 일반적인 아키텍처에 대해 이야기하고 싶습니다. 이게 다 4단계라면.

296
00:43:41,020 --> 00:43:52,020
모델이 동일한 비율로 감소하는 경우 입력 이미지의 크기는 4배, 8배, 16배 32배로 감소합니다.

297
00:43:52,020 --> 00:44:01,020
그리고 이를 컨볼루셔널 인코더에 입력한 다음 이전 블록인 Swift에 입력한 다음 2씩 다운 샘플링합니다.

298
00:44:01,020 --> 00:44:04,020
그런 다음 해당 4단계를 반복하면 됩니다.

299
00:44:04,020 --> 00:44:14,020
Swift 이전 인코더 각각은 깊이별 컨볼루션 3x3 컨볼루션 및 1x1 컨볼루션에 의한 로컬 표현을 갖습니다.

300
00:44:14,020 --> 00:44:20,020
그런 다음 앞서 설명한 효율적인 추가 주의 레이어를 사용하여 선형 변환을 수행합니다.

301
00:44:20,020 --> 00:44:28,020
그리고 각각의 공통 진화 인코더는 1 컨볼루션에 의한 깊이별 컨볼루션 정규화입니다.

302
00:44:28,020 --> 00:44:36,020
Gilu와 Convo인 활성화 계층입니다.

303
00:44:36,020 --> 00:44:39,020
결과는 다음과 같습니다.

304
00:44:39,020 --> 00:44:44,020
따라서 스위프트 포머는 회복기 트랜스포머와 트랜스 트랜스포머 사이의 하이브리드입니다.

305
00:44:44,020 --> 00:44:52,020
그리고 매개변수가 더 적습니다.

306
00:44:52,020 --> 00:44:59,020
그런 다음 다른 하이브리드 접근 방식보다 대부분 정확하지만 정확도가 더 높습니다.

307
00:44:59,020 --> 00:45:04,020
그리고 대기 시간이 더 짧습니다. 이 경우에는 보이지 않습니다.

308
00:45:04,020 --> 00:45:12,020
대기 시간은 밀리초 단위로 이야기하기 때문에 일반적으로 가장 큰 문제입니다. 따라서 어떤 성능 설정에서도

309
00:45:12,020 --> 00:45:19,020
예측, 실시간으로 무언가를 한다면 초당 60프레임 정도여야 합니다. 최소한의 수준인 것 같아요.

310
00:45:19,020 --> 00:45:31,020
따라서 현실적으로 10밀리초 미만의 지연 시간이면 그 목표를 달성할 수 있습니다. 더 큰 것은 처리량입니다.

311
00:45:31,020 --> 00:45:40,020
다른 모든 하이브리드 접근 방식보다 처리량이 더 좋습니다.

312
00:45:40,020 --> 00:45:47,020
반드시 다른 모든 변압기가 필요한 것은 아니지만 대부분의 경우 다른 모든 하이브리드가 필요합니다.

313
00:45:47,020 --> 00:45:53,020
여기서 처리량은 단지 훈련 속도일 뿐입니다. 그래서 기차가 더 빨라요.

314
00:45:53,020 --> 00:45:57,020
따라서 해야 할 작업이 적더라도 마찬가지입니다.

315
00:45:57,020 --> 00:46:03,020
예를 들어 DIT와 같이 처리량이 느린 경우.

316
00:46:03,020 --> 00:46:07,020
두 번째 블록에 T를 대시하세요.

317
00:46:07,020 --> 00:46:12,020
있음에도 불구하고 처리량이 더 높습니다.

318
00:46:12,020 --> 00:46:16,020
더

319
00:46:16,020 --> 00:46:21,020
해야 할 계산과 같습니다. 그러니까 그 경우처럼,

320
00:46:21,020 --> 00:46:26,020
당신은 훈련에 더 오랜 시간을 소비하게 될 것입니다.

321
00:46:26,020 --> 00:46:32,020
기술적으로 더 빠른 것은 더 많은 시간을 훈련해야 하기 때문입니다.

322
00:46:32,020 --> 00:46:42,020
또는 더 많은 시대가 필요하지만 양식을 통해 더 나은 결과를 얻을 수 있습니다.

323
00:46:42,020 --> 00:46:47,020
다음으로는 탐지와 이미지 분할입니다. 지난번 논문과 비슷해요.

324
00:46:47,020 --> 00:46:52,020
이러한 탐지 인스턴스 분할은 경계 상자를 기반으로 합니다.

325
00:46:52,020 --> 00:46:56,020
다른 임계값에 적용되고 다른 임계값에 마스크도 적용됩니다.

326
00:46:56,020 --> 00:47:00,020
그리고 스위치 포머(Switch Former)는 이들 중 최고의 성능을 발휘합니다.

327
00:47:00,020 --> 00:47:06,020
그리고 그들은 또한 의미론을 수행합니다. 그것은 노동조합을 넘어서는 교차점이다.

328
00:47:06,020 --> 00:47:11,020
앞서 설명한 것과 동일한 측정항목입니다.

329
00:47:11,020 --> 00:47:14,020
감사합니다.