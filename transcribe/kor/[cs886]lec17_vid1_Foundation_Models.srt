1
00:00:00,000 --> 00:00:07,000
안녕하세요 여러분, 저는 Arbunan Chandra입니다. 제 친구 Achan Soni와 함께

2
00:00:07,000 --> 00:00:09,160
확산 모델에 대한 강의를 진행합니다.

3
00:00:09,160 --> 00:00:14,560
워털루 대학교 경쟁 과학과의 1학년 M 수학 학생

4
00:00:14,560 --> 00:00:19,960
이것은 CS86 기초 모델에 대한 최근 발전 과정에 대한 프리젠테이션입니다.

5
00:00:19,960 --> 00:00:26,200
Wenhu Chek 교수의지도.

6
00:00:26,200 --> 00:00:30,280
이것이 우리 프레젠테이션의 기본 개요입니다. 먼저 생성의 기본 사항을 살펴보겠습니다.

7
00:00:30,280 --> 00:00:35,680
모델을 사용하여 점수 함수와 점수 기반 모델을 이해하는 데 꽤 많은 시간을 할애할 것입니다.

8
00:00:35,680 --> 00:00:40,120
그런 다음 SDS와 점수 기반 모델 간의 연관성을 이해하려고 노력할 것입니다.

9
00:00:40,120 --> 00:00:46,480
그런 다음 DGPM, DDIM 및 DPM 솔버와 같은 널리 사용되는 샘플링 기술을 다룹니다.

10
00:00:46,480 --> 00:00:50,760
마지막으로 Open Eye의 최신 연구인 일관성 모델을 다루겠습니다.

11
00:00:50,760 --> 00:00:58,600
바닐라 확산 모델을 개선하려고 시도합니다.

12
00:00:58,600 --> 00:01:03,280
생성 모델과 심층 생성 모델에는 매우 많은 클래스가 있습니다.

13
00:01:03,280 --> 00:01:08,200
모델은 지난 10년 동안 꽤 컸었습니다. 가끔 픽셀과 같은 모델이 있었습니다.

14
00:01:08,200 --> 00:01:14,640
이미지의 픽셀을 반복적으로 생성하지만 이후 모델 클래스에 의해 인계되었습니다.

15
00:01:14,640 --> 00:01:16,840
VA나 GAN처럼 말이죠.

16
00:01:16,840 --> 00:01:23,120
생성 모델은 최근 2년 동안 인기를 얻었으며 천천히 그리고

17
00:01:23,120 --> 00:01:28,480
점차적으로 현재 수행되고 있는 심층 생성 모델 중 가장 지배적인 클래스가 됨

18
00:01:28,480 --> 00:01:35,520
FID 점수 측면에서 GAN 및 VA보다 훨씬 더 나은 수준입니다.

19
00:01:35,520 --> 00:01:37,960
생성 모델링이란 무엇입니까?

20
00:01:37,960 --> 00:01:43,400
기계 학습 애플리케이션에는 훈련, 검증 및 테스트 세트가 있습니다.

21
00:01:43,400 --> 00:01:48,440
이러한 데이터 포인트는 우리에게 알려지지 않은 일부 기본 데이터 분포에서 추출됩니다.

22
00:01:48,440 --> 00:01:52,440
심층 생성 모델링과 생성 모델링의 목표는 다음과 같은 신경망을 훈련시키는 것입니다.

23
00:01:52,440 --> 00:01:57,120
추출된 유한한 수의 샘플로부터 이 기본 데이터 분포를 학습할 수 있습니다.

24
00:01:57,120 --> 00:01:58,880
그것에서.

25
00:01:58,880 --> 00:02:03,720
학습된 분포와 실제 모델에서 샘플링하여 새로운 데이터를 생성합니다.

26
00:02:03,720 --> 00:02:08,400
예상되는 로그 레그 로드를 최대화하거나 로그 레그 간의 차이를 최소화하도록 훈련되었습니다.

27
00:02:08,400 --> 00:02:10,600
학습된 데이터와 경험적 데이터 분포.

28
00:02:10,960 --> 00:02:15,680
이러한 차이를 최소화하기 위한 많은 수학적 트릭이 있으며 우리는 이를 탐구할 것입니다.

29
00:02:15,680 --> 00:02:20,240
다음 슬라이드에서 설명하겠습니다.

30
00:02:20,240 --> 00:02:24,880
따라서 광범위하게 우리는 우리에게 알려지지 않고 눈으로만 볼 수 있는 원본 데이터 분포를 가지고 있습니다.

31
00:02:24,880 --> 00:02:31,480
일부 IID 샘플 훈련 데이터를 통해 우리에게 알려주었고 우리는 다음을 수행할 수 있는 생성 모델을 배우고 싶습니다.

32
00:02:31,480 --> 00:02:37,000
이 원래 데이터 분포를 근사화하고 학습된 데이터 분포를 형성합니다.

33
00:02:37,000 --> 00:02:42,360
오른쪽에 표현되어 있습니다.

34
00:02:42,360 --> 00:02:45,400
그렇다면 이러한 종류의 모델의 학습 목표는 무엇입니까?

35
00:02:45,400 --> 00:02:50,160
목표는 기본적으로 경험적 데이터 분포 간의 차이를 최소화하는 것입니다.

36
00:02:50,160 --> 00:02:53,400
그리고 우리 모델에 의해 학습된 분포입니다.

37
00:02:53,400 --> 00:02:58,240
모델이 좋은 분포를 학습하면 원래 분포와 매우 유사해야 합니다.

38
00:02:58,240 --> 00:03:05,000
이제 우리의 분포가 GAN 이미지의 분포라고 가정하면 학습된 분포에서 무엇을 할 수 있습니까?

39
00:03:05,000 --> 00:03:10,600
분명히 우리는 이 분포에서 새로운 데이터 포인트를 생성하는 샘플링을 사용할 수 있습니다.

40
00:03:10,600 --> 00:03:13,920
그러나 확률을 평가하기 위해 역으로 사용할 수도 있습니다.

41
00:03:13,920 --> 00:03:20,160
즉, 이 고양이 이미지와 같은 기존 데이터 포인트를 사용하여 분포에 전달할 수 있습니다.

42
00:03:20,160 --> 00:03:22,720
확률 질량이 얼마나 좋은지 확인합니다.

43
00:03:22,720 --> 00:03:28,200
이제 이것은 매우 흔한 고양이 이미지이므로, 우리 모델이 좋은 모델이라면

44
00:03:28,200 --> 00:03:29,680
그것에 높은 확률을 할당합니다.

45
00:03:29,880 --> 00:03:35,320
이제 맨 아래에 있는 고양이는 매우 이상한 고양이처럼 보입니다. 따라서 모델이

46
00:03:35,320 --> 00:03:38,200
좋은 모델은 낮은 확률을 할당합니다.

47
00:03:38,200 --> 00:03:45,120
요약하자면 모델 패밀리가 있고 그 매개변수가 있으므로 선택하고 싶습니다.

48
00:03:45,120 --> 00:03:50,840
경험적 데이터 분포에 가장 가까운 이상적으로 P 세타 별인 최고의 세타

49
00:03:50,840 --> 00:03:57,240
P 데이터를 학습하고 나면 샘플링, 확률 진화 및 기타 작업을 수행할 수 있습니다.

50
00:03:57,240 --> 00:03:58,240
것들.

51
00:03:59,120 --> 00:04:03,400
그러나 모델 분포를 학습하는 데 있어서 가장 중요한 과제는 원본 분포의 복잡성입니다.

52
00:04:03,400 --> 00:04:04,400
데이터 배포.

53
00:04:04,400 --> 00:04:11,800
데이터 포인트의 수는 제한되어 있으며 차원에 따라 복잡성이 확장됩니다.

54
00:04:11,800 --> 00:04:14,040
데이터 입력 데이터 중.

55
00:04:14,040 --> 00:04:18,160
이제 우리는 이미지, 오디오, 비디오를 다루고 있으므로 매우 고차원적입니다.

56
00:04:18,160 --> 00:04:26,000
이는 기본 모델 학습의 계산 복잡성을 대폭 증가시킵니다.

57
00:04:26,000 --> 00:04:28,000
유통을 많이함.

58
00:04:29,000 --> 00:04:33,120
우리는 분명히 가우스 분포와 같은 간단한 모델로 시작할 수 있지만

59
00:04:33,120 --> 00:04:37,600
복잡한 기본 분포를 포착하는 데는 2주가 소요됩니다.

60
00:04:37,600 --> 00:04:45,040
이 예를 보면 이는 이봉 분포의 예이지만 이 가우스 분포는

61
00:04:45,040 --> 00:04:50,000
두 모드 사이에 있는 모드 중 하나만 학습합니다.

62
00:04:50,000 --> 00:04:57,920
따라서 학습된 올바른 분포가 아니며 기본 데이터로 사용되는 것은 분명합니다.

63
00:04:57,920 --> 00:05:01,800
유통이 점점 더 복잡해지고 있기 때문에 자연스럽게 다음 방향으로 나아가야 합니다.

64
00:05:01,800 --> 00:05:07,680
보다 표현력이 풍부한 신경을 향해 나아가는 더 깊고 큰 계산 그래프

65
00:05:07,680 --> 00:05:12,200
확률 분포를 모델링하기 위한 범용 함수 근사치로서의 네트워크

66
00:05:12,200 --> 00:05:13,200
자료.

67
00:05:13,200 --> 00:05:19,560
따라서 생성 모델링과 심층 신경망을 결합하면 두 가지 심층 생성 모델링을 얻을 수 있습니다.

68
00:05:19,560 --> 00:05:20,560
모델.

69
00:05:20,560 --> 00:05:26,400
신경망과 같은 함수 근사기를 통해 근사화된 심층 생성 모델

70
00:05:26,400 --> 00:05:31,440
주어진 출력이 유효한 확률 분포가 아니라는 자체 문제가 있습니다.

71
00:05:31,440 --> 00:05:36,200
실제 확률 분포를 얻으려면 정규화해야 합니다.

72
00:05:36,200 --> 00:05:43,000
0과 1 사이에 있고 최대 1까지 더해지며 이것이 주요 골칫거리입니다.

73
00:05:43,000 --> 00:05:50,160
따라서 일부 입력 x에 대해 이것을 본다면 신경망에서 f of x로 꺼냅니다.

74
00:05:50,160 --> 00:05:54,600
양의 지수화를 보장하지만 이는 정규화되지 않습니다.

75
00:05:54,600 --> 00:05:59,320
따라서 이를 정규화하기 위해 정규화 상수 z theta로 나눕니다.

76
00:05:59,320 --> 00:06:02,320
이를 정규화 상수 또는 분할 함수라고 합니다.

77
00:06:02,320 --> 00:06:08,360
불행하게도 우리는 모든 입력을 통합해야 하기 때문에 z θ를 알지 못합니다.

78
00:06:08,360 --> 00:06:13,800
세타의 z를 얻기 위해 e의 x의 f 세타 거듭제곱의 예입니다.

79
00:06:13,800 --> 00:06:22,000
이제 x의 fθ는 매우 복잡한 함수일 수 있으며 이 적분은 종종 그렇지 않습니다.

80
00:06:22,000 --> 00:06:25,800
다루기 힘든 통합입니다.

81
00:06:25,800 --> 00:06:30,800
Gaussian z theta 또는 z new와 같은 간단한 경우에는 1 x 2 pi d로 나타납니다.

82
00:06:30,800 --> 00:06:33,520
2d는 입력 데이터의 차원입니다.

83
00:06:33,520 --> 00:06:39,400
따라서 주의 사항의 단순 합집합 차원에서는 루트 2파이의 1이 됩니다.

84
00:06:39,400 --> 00:06:48,160
가우스 분포 공식에 나오는 간단한 일이지만 다른 함수 클래스에서는 이

85
00:06:48,160 --> 00:06:53,240
일은 다루기 힘든 것으로 밝혀졌습니다.

86
00:06:53,240 --> 00:06:57,160
이제 문제는 이 다루기 힘든 z theta를 어떻게 처리하고 이를 제거할 수 있느냐는 것입니다.

87
00:06:57,160 --> 00:07:00,800
최적화 과정에서?

88
00:07:00,800 --> 00:07:08,560
이제 기존 생성 모델은 크게 세 가지 클래스로 분류될 수 있습니다.

89
00:07:08,560 --> 00:07:12,440
그래서 우리는 에너지 기반 모델과 같은 대조 학습 기반 방법을 가지고 있습니다.

90
00:07:12,440 --> 00:07:17,240
이는 기본 분포를 모델링하는 측면에서 매우 유연하며

91
00:07:17,240 --> 00:07:26,160
공식에 암시적으로 z 세타 항이 있고 그것이 정확한 확률이 있기 때문에

92
00:07:26,160 --> 00:07:30,200
이 모델에서는 진화가 매우 어렵기 때문입니다.

93
00:07:30,200 --> 00:07:36,160
그런 다음 우리는 VA의 정규화 흐름 모델 및 자동 회귀와 같은 부하 기반 모델과 같습니다.

94
00:07:36,160 --> 00:07:39,720
모델.

95
00:07:39,720 --> 00:07:44,920
이는 z theta가 다루기 쉬운지 확인하는 제한적인 모델링 클래스를 만들어 작동합니다.

96
00:07:44,920 --> 00:07:52,320
또는 어떤 형태로든 학습할 수 있지만 이러한 모델에서 문제는 다음과 같습니다.

97
00:07:52,320 --> 00:07:59,560
일반적으로 고품질 샘플을 학습할 수 있는 능력이 모델 클래스를 제한하고 있습니다.

98
00:07:59,560 --> 00:08:06,520
자연적으로 감소한 다음 확률이 없는 암시적 생성 모델을 갖게 됩니다.

99
00:08:06,520 --> 00:08:11,400
분포는 샘플링 프로세스 모델로 암시적으로 표현됩니다.

100
00:08:11,400 --> 00:08:17,520
따라서 가장 눈에 띄는 예는 데이터 분포의 새로운 샘플이 있는 GAN입니다.

101
00:08:17,520 --> 00:08:24,240
학습된 생성을 사용하여 임의의 가우스 벡터를 변환하여 합성됩니다.

102
00:08:24,240 --> 00:08:29,520
이제 오른쪽 그림을 보면 확산 모델이 달콤한 영역에 있음을 알 수 있습니다.

103
00:08:29,520 --> 00:08:35,000
상당한 모드 적용 범위와 다양성을 갖춘 고품질 샘플을 생성하는 지점

104
00:08:35,000 --> 00:08:39,680
그리고 현재 확산 모델도 예쁘게 만들 수 있다는 것을 보여주는 작품이 있습니다.

105
00:08:39,680 --> 00:08:43,800
프레젠테이션의 뒷부분에서 다루게 될 샘플링만큼 빠릅니다.

106
00:08:43,800 --> 00:08:47,520
따라서 일반적으로 확산 모델은 점수 기반 생성 모델의 광범위한 클래스에 속합니다.

107
00:08:47,520 --> 00:08:52,040
모델과 확산 모델은 이러한 모델 형태의 특정 관계이며

108
00:08:52,040 --> 00:08:54,360
이것이 우리가 다음에 다룰 내용입니다.

109
00:08:54,360 --> 00:08:59,480
그래서 우리는 판별자와 별도의 생성자의 공동 아키텍처를 가진 GAN을 가지고 있습니다.

110
00:08:59,480 --> 00:09:05,080
우리가 함께 훈련하고 판별자가 생성 이미지를 구별하는 방법을 학습합니다.

111
00:09:05,080 --> 00:09:11,560
원본 이미지에서 생성기가 점차적으로 실제 생활을 생성하는 데 더 능숙해집니다.

112
00:09:11,560 --> 00:09:13,760
Gaussian GAN의 이미지.

113
00:09:13,760 --> 00:09:20,360
이들은 먼저 X를 코드북이나 근본적인 중요한 잠재성으로 변환하고 그 잠재성에서 우리는

114
00:09:20,360 --> 00:09:26,760
이미지를 샘플링하고 생성하여 재구성할 수 있으며 이 프로세스가 좋아지면 샘플링할 수 있습니다.

115
00:09:26,760 --> 00:09:31,760
Z에서 좋은 새 이미지를 생성합니다.

116
00:09:31,760 --> 00:09:37,240
이제 점차적으로 가우스 노이즈를 추가하는 것이 목표인 확산 모델이 있습니다.

117
00:09:37,240 --> 00:09:48,120
VA와는 달리 시간이 지남에 따라 역과정으로 이미지를 재생성합니다.

118
00:09:48,120 --> 00:09:50,040
이것이 VE 손실 함수입니다.

119
00:09:50,040 --> 00:09:56,760
로그 길이 루프를 최대화하고 변형 계열을 최소화했습니다.

120
00:09:56,760 --> 00:09:59,320
그리고 우리가 배우려고 하는 P 세타입니다.

121
00:09:59,320 --> 00:10:04,400
따라서 이 항을 어기면 변형의 엔트로피 항에 Q를 더한 값도 갖게 됩니다.

122
00:10:04,400 --> 00:10:10,160
y와 엔트로피 항은 기본 세부 사항의 최대 적용 범위를 보장합니다.

123
00:10:10,160 --> 00:10:13,520
우리가 선택하는 대략적인 변형군에 의해 수행됩니다.

124
00:10:13,520 --> 00:10:18,680
GAN의 경우, 우리는 이 미니맥스 공식을 가지고 있으며 최적화가 다음과 같다고 가정합니다.

125
00:10:18,680 --> 00:10:23,360
완료되면 판별자와 생성자 사이에 청사진이 생성됩니다.

126
00:10:23,360 --> 00:10:29,040
즉, 생성자가 생성한 이미지가 너무 좋아서 판별자가

127
00:10:29,120 --> 00:10:35,200
실제 이미지인지 가짜 생성 이미지인지 판단하기가 어렵습니다.

128
00:10:35,200 --> 00:10:38,760
그 손실은 절반으로 수렴됩니다.

129
00:10:38,760 --> 00:10:44,600
이제 우리는 마침내 핵심 기능과 점수 기반 생성 모델로 이동합니다.

130
00:10:44,600 --> 00:10:49,080
앞서 살펴본 것처럼 최상의 모델과 암시적 생성 모델은 모두 상당한 가능성을 가지고 있습니다.

131
00:10:49,080 --> 00:10:54,720
최고의 모델에는 가능성에 대한 강력한 제한이 필요합니다.

132
00:10:54,720 --> 00:11:00,920
가능성 계산을 위해 매력적인 정규화 상수를 보장하는 모델링 클래스

133
00:11:00,920 --> 00:11:06,360
최대 우도 훈련을 최적화하기 위해 변형 클래스와 같은 목표를 실현합니다.

134
00:11:06,360 --> 00:11:12,160
GAN 및 암시적 생성 모델의 경우 훈련 목표는 근본적으로 적대적입니다.

135
00:11:12,160 --> 00:11:16,960
너무 느슨하게 불안정하지 않고 모드 붕괴로 이어집니다.

136
00:11:16,960 --> 00:11:20,800
이것이 이러한 제한 사항 중 일부를 우회할 수 있는 확률 분포를 나타내는 방법입니다.

137
00:11:20,800 --> 00:11:25,520
이는 주로 물리학의 열역학 및 통계역학에서 빌려와 응용한 것입니다.

138
00:11:25,520 --> 00:11:28,240
생성 모델에.

139
00:11:28,240 --> 00:11:33,200
핵심 아이디어는 데이터 분포의 로그 확률의 기울기를 모델링하는 것입니다.

140
00:11:33,200 --> 00:11:39,160
Steen 점수 함수라고 불리는 수량이며 이것이 우리가 하려고 하는 것입니다.

141
00:11:39,160 --> 00:11:40,160
에 집중하세요.

142
00:11:40,160 --> 00:11:44,720
따라서 이러한 점수 기반 모델은 다음과 같이 매력적인 정규화 상수를 가질 필요가 없습니다.

143
00:11:44,720 --> 00:11:50,520
우리는 공식화하는 동안 보게 될 것이며 기본적으로 GAN은 출시되었으며 다음을 통해 직접 학습할 수 있습니다.

144
00:11:50,520 --> 00:11:53,600
점수 매칭.

145
00:11:53,600 --> 00:11:59,480
그렇다면 모델의 매개변수를 사용하지 않고 확률 분포를 어떻게 표현할 수 있을까요?

146
00:11:59,480 --> 00:12:07,080
그래서 우리는 기본적으로 기울기인 점수 함수라고 불리는 이 수량을 사용합니다.

147
00:12:07,080 --> 00:12:11,080
x(x)의 로그(p)에 대해.

148
00:12:11,080 --> 00:12:19,440
따라서 표시되는 화살표가 기본적으로 그라디언트이고 점수 함수는 다음과 같습니다.

149
00:12:19,440 --> 00:12:26,800
표시되고 기본 색상 영역은 실제 PDF이며 기본적으로 두 가지를 묘사합니다.

150
00:12:26,800 --> 00:12:32,560
이 모드와 이 모드에서 확률 질량이 집중된 모드 분포

151
00:12:32,560 --> 00:12:33,960
방법.

152
00:12:33,960 --> 00:12:38,240
따라서 PDF가 미분 가능하다고 가정하면 점수 함수 계산은 매우 쉽고

153
00:12:38,240 --> 00:12:42,480
간단한 방법으로 수행됩니다.

154
00:12:42,480 --> 00:12:46,600
따라서 점수 함수를 사용하는 주요 이점은 정규화 상수를 제거할 수 있다는 것입니다.

155
00:12:46,600 --> 00:12:56,040
이는 확률 밀도의 합을 보장하는 기준을 물리적으로 의미합니다.

156
00:12:56,040 --> 00:13:02,920
함수는 1과 같고, 곡선 아래의 면적은 1인 반면, 그래디언트를 취하면

157
00:13:02,920 --> 00:13:08,760
x/p/x에 관해서는 이런 종류의 것으로 나타납니다. 이것은 기본적으로 다음과 같습니다.

158
00:13:08,760 --> 00:13:15,980
여기서는 곡선 아래 영역을 1로 보장하는 개념에서 점수 함수가 존재하지 않습니다.

159
00:13:15,980 --> 00:13:20,660
그렇다면 원래 확률 밀도 함수 대신 점수 함수에 관심을 두는 이유는 무엇입니까?

160
00:13:20,660 --> 00:13:23,860
깊은 에너지 낭비 모델의 예를 이해해 봅시다.

161
00:13:23,860 --> 00:13:28,420
fθ를 심층 에너지 낭비 모델의 출력으로 두고 이를 적절한 값으로 변환합니다.

162
00:13:28,420 --> 00:13:32,540
확률을 기하급수적으로 취하고 정규화 상수로 나누어서 보장합니다.

163
00:13:32,540 --> 00:13:35,700
양수이고 일부 합은 1이 됩니다.

164
00:13:35,700 --> 00:13:43,740
이제 대조 발산 기반 훈련을 수행하면 우리는 이것과 여기에 있습니다.

165
00:13:43,740 --> 00:13:49,740
세타와 z 세타에 관한 최대값이 관련되어 있으며 알 수 없으므로 이를 최대화합니다.

166
00:13:49,740 --> 00:13:58,940
방법이 어려워지고 세타에 대한 기울기를 취하면 매우 어려워집니다.

167
00:13:58,940 --> 00:14:04,900
pθ는 근본적으로 우리에게 알려져 있지 않기 때문에 우리는 단지 그것으로부터 샘플을 채취하는 것뿐입니다.

168
00:14:04,900 --> 00:14:09,380
그렇다면 다루기 힘든 분할 기능을 어떻게 우회할 수 있을까요?

169
00:14:09,380 --> 00:14:13,980
세타에 대해 경사를 취하는 대신 경사를 취하는 것으로 다시 돌아가면 어떻게 될까요?

170
00:14:13,980 --> 00:14:16,660
점수 함수 측면에서 x에 대해.

171
00:14:16,660 --> 00:14:21,180
따라서 이 공식은 이전에 논의한 점수 함수와 정확히 동일합니다.

172
00:14:21,180 --> 00:14:26,420
x에 대한 기울기를 취하면 이는 단지 종속적이기 때문에 0이 됩니다.

173
00:14:26,420 --> 00:14:33,580
세타에 대해 그리고 ebms에 대해 조금 계산하면 점수 일치 공식이 바뀌게 됩니다.

174
00:14:33,580 --> 00:14:34,580
이거면 돼.

175
00:14:34,580 --> 00:14:39,900
여기서 우리는 sθ가 정규화 상수와 무관하다는 것을 분명히 볼 수 있습니다.

176
00:14:39,900 --> 00:14:43,180
이제 점수 추정을 위한 프레임워크를 공식화해 보겠습니다.

177
00:14:43,180 --> 00:14:50,100
따라서 우리는 id 훈련 데이터 포인트를 샘플링하는 알 수 없는 p 데이터를 가지고 있습니다.

178
00:14:50,100 --> 00:14:55,420
우리는 기본적으로 x의 x log p 데이터의 기울기인 s theta를 배워야 합니다.

179
00:14:55,420 --> 00:15:06,580
그래서 우리는 원래의 점수 함수와 점수 함수를 학습하려는 점수 모델을 제안합니다.

180
00:15:06,580 --> 00:15:10,020
목표는 기본적으로 이 두 가지를 최대한 가깝게 만드는 것입니다.

181
00:15:10,020 --> 00:15:14,820
둘 다 벡터 필드이므로 다음으로 계산하고 최소화하는 방법을 살펴보겠습니다.

182
00:15:14,820 --> 00:15:18,580
그 거리.

183
00:15:18,580 --> 00:15:22,700
그래서 이것은 기본적으로 단순히 공간에 대한 등가 거리에 대한 평균을 내고 최소화하는 것입니다.

184
00:15:22,700 --> 00:15:29,100
저것.

185
00:15:29,100 --> 00:15:32,620
따라서 수학적으로 목표는 전체에 대한 평균 등가 거리로 작성할 수 있습니다.

186
00:15:32,620 --> 00:15:40,260
공간을 최소화하고 이를 Fisher Diabinance라고 하지만 불행히도 우리는

187
00:15:40,260 --> 00:15:45,140
p 데이터가 우리에게 알려졌더라면 우리가 취할 필요가 없었을 것이기 때문에 이 사실을 모릅니다.

188
00:15:45,140 --> 00:15:47,580
어쨌든 너무 머리가 아프다.

189
00:15:47,580 --> 00:15:49,940
그렇다면 p 데이터를 어떻게 요소화할까요?

190
00:15:49,940 --> 00:15:55,740
따라서 이를 제안한 논문에서 사용된 한 가지 깔끔한 트릭은 통합을 사용하는 것이었습니다.

191
00:15:55,740 --> 00:16:02,540
부분 또는 대 정리로 그리고 부분별 적분을 사용하여 조작함으로써 우리는

192
00:16:02,540 --> 00:16:09,540
기대값의 p 데이터와 여기의 p 데이터가 사라지고 마침내 다음이 제공됩니다.

193
00:16:09,540 --> 00:16:16,180
점수 매칭 방정식이라고 불리는 방정식인데 보시다시피 p 데이터는 그렇지 않습니다.

194
00:16:16,180 --> 00:16:24,420
여기에 포함되므로 기본적으로 샘플을 그려 예상을 대체할 수 있습니다.

195
00:16:24,420 --> 00:16:29,300
이제 마지막 슬라이드에서 도출한 점수 일치 구성을 고려하면 다음과 같습니다.

196
00:16:29,300 --> 00:16:31,380
효율적인 방식으로 최적화되었나요?

197
00:16:31,380 --> 00:16:37,220
첫 번째 항은 단순히 L2 차원이므로 한 번의 백 준비를 통해 수행할 수 있지만

198
00:16:37,220 --> 00:16:43,460
학습된 점수 함수의 추적 계산은 매우 계산 비용이 많이 드는 것과 같습니다.

199
00:16:43,460 --> 00:16:47,780
그리고 데이터의 차원에 따라 확장됩니다.

200
00:16:47,780 --> 00:16:54,060
그래서 이를 효율적으로 수행하기 위한 두 가지 방법이 제안되었습니다. 그 중 하나는 디너징 점수 매칭입니다.

201
00:16:54,060 --> 00:16:57,300
오히려 슬라이스 점수 일치입니다.

202
00:16:57,300 --> 00:17:04,580
그래서 디너징 스코어 매칭은 기본적으로 이 노이즈 커널을 사용하고 컨볼루션 연산을 합니다.

203
00:17:04,580 --> 00:17:11,660
원본 px의 일부로 변환하여 시끄러운 버전을 형성합니다.

204
00:17:11,660 --> 00:17:14,540
이제 이 시끄러운 버전을 형성하면 어떤 이점이 있습니까?

205
00:17:14,540 --> 00:17:21,180
점수로 배우는 것이 훨씬 쉬운 경쟁인 것처럼 배우는 것이 훨씬 쉽습니다.

206
00:17:21,180 --> 00:17:22,340
어울리는 공식.

207
00:18:11,660 --> 00:18:36,980
그래서 우리는 p 데이터를 가지고 있고 시끄러운 커널을 사용하여 컨볼루션을 수행하고 q phi를 얻습니다.

208
00:18:36,980 --> 00:18:38,700
x 대시.

209
00:18:38,700 --> 00:18:52,380
따라서 여기서는 수학을 건너뛰겠지만 꽤 이해하기 쉽다는 것을 알 수 있습니다.

210
00:18:52,380 --> 00:18:56,100
그래서 마침내 우리는 디너징 점수 매칭 공식을 갖게 되었습니다.

211
00:18:56,100 --> 00:19:01,420
이것은 점수 함수의 추적이 다음으로 대체되는 원래 함수였습니다.

212
00:19:01,420 --> 00:19:17,660
p의 노이즈 버전이고 경험적으로 p 데이터에서 x를 샘플링하고 p 데이터에서 x 막대를 샘플링합니다.

213
00:19:17,660 --> 00:19:19,260
이 가우스.

214
00:19:19,260 --> 00:19:24,620
따라서 이 모든 것은 기본적으로 기대일 수 있으며 이 모든 것은 단순한 경험적 예측으로 대체될 수 있습니다.

215
00:19:24,620 --> 00:19:28,900
평균이며 계산하기 쉽습니다.

216
00:19:28,900 --> 00:19:36,100
그리고 이것은 분석적인 것으로 밝혀졌습니다. 여기에는 분석적인 솔루션이 있으며 여러분은 보게 될 것입니다.

217
00:19:36,100 --> 00:19:42,860
이는 유명한 DDPM 및 DDIM 논문에서도 흔히 볼 수 있습니다.

218
00:19:42,860 --> 00:19:49,620
따라서 매우 높은 차원의 데이터를 계산하는 것이 효율적이며 최적의 경우에 유용합니다.

219
00:19:49,620 --> 00:19:50,620
시끄러운.

220
00:19:50,620 --> 00:19:55,900
그러나 하나의 동전은 우리가 원본 세타의 p의 교란된 데이터 분포를 사용하고 있기 때문입니다.

221
00:19:55,900 --> 00:20:04,180
x의 q phi의 로그를 기준으로 채점하기 때문에 점수 추정을 제대로 수행할 수 없습니다.

222
00:20:04,180 --> 00:20:12,500
p 데이터 x의 로그인 x의 기울기와 정확히 동일하지는 않습니다.

223
00:20:12,500 --> 00:20:18,300
이제 이 작업을 계산적으로 보다 효율적으로 만드는 방법은 슬라이스 점수 일치를 수행하는 것입니다.

224
00:20:18,300 --> 00:20:26,300
이는 기본적으로 원래 점수 함수인 학습 점수 함수를 예측하는 것입니다.

225
00:20:26,300 --> 00:20:38,300
하나의 d 벡터에 그 방향을 따라 모든 것을 계산합니다.

226
00:20:38,300 --> 00:20:42,300
따라서 슬라이스 점수 매칭을 적용한 후 우리는 슬라이스라는 새로운 목표를 생각해냅니다.

227
00:20:42,300 --> 00:20:47,300
추적 항이 이 pt로 대체되고 적분을 적용하는 경우 균열 발산

228
00:20:47,300 --> 00:20:53,300
이를 통해 우리는 기본적으로 pv에서 가져온 다른 v에 대한 기대를 얻습니다.

229
00:20:53,300 --> 00:20:57,300
우리가 예측하고 있는 이 1차원 벡터의 분포를 살펴보겠습니다.

230
00:20:57,300 --> 00:21:09,300
이전과 같이 p 데이터에서 x를 그리면 완전히 효율적인 목표를 생각해 낼 수 있습니다.

231
00:21:09,300 --> 00:21:17,300
이것이 위에서 논의한 슬라이스 점수 매칭 함수의 요약입니다.

232
00:21:17,300 --> 00:21:24,300
완전히 효율적인 목표는 이러한 투영 용어에 의해 추적이 제거되고 우리는

233
00:21:24,300 --> 00:21:32,020
n개의 예측과 n개의 데이터 포인트를 샘플링하고 기본적으로 이를 경험적 평균으로 대체합니다.

234
00:21:32,020 --> 00:21:38,020
따라서 이 전체 절차는 차원 d와 무관하므로 계산적으로는 다음과 같습니다.

235
00:21:38,020 --> 00:21:42,520
다루기 쉬운.

236
00:21:42,520 --> 00:21:49,020
이제 우리는 데이터 포인트를 샘플링하고 점수 매칭을 수행하여 점수 함수를 학습하는 방법을 배웠습니다.

237
00:21:49,020 --> 00:21:56,020
이제 다음 단계는 여기서 샘플링하여 새로운 데이터 포인트를 생성하는 방법입니다.

238
00:21:56,020 --> 00:21:57,020
점수 기능을 배웁니다.

239
00:21:57,020 --> 00:22:00,020
이로써 생성 모델링 프로세스가 완료되었습니다.

240
00:22:00,020 --> 00:22:06,020
이제 우리는 x의 세타로서 점수 함수를 배웠으므로, 어떻게 그것으로부터 샘플링을 합니까?

241
00:22:06,020 --> 00:22:07,020
새로운 데이터 샘플을 생성합니다.

242
00:22:07,020 --> 00:22:14,020
따라서 우리는 다중 파일 규칙 질문에 대해 일반적인 유형의 다항식 mcmc mcmc 시스템을 사용합니다.

243
00:22:14,020 --> 00:22:24,020
따라서 공간에서 점의 초기 분포가 있다고 가정하고 다음을 사용하여 안내합니다.

244
00:22:24,020 --> 00:22:31,020
데이터 포인트로 이동하여 분포 영역으로 이동하는 점수 함수

245
00:22:31,020 --> 00:22:35,020
높은 확률값을 가지고 있습니다.

246
00:22:35,020 --> 00:22:39,020
그래서 이것이 일어나는 방법입니다.

247
00:22:39,020 --> 00:22:43,020
바닐라 형태에서는 이러한 것들이 두 가지 모드로 축소됩니다.

248
00:22:43,020 --> 00:22:50,020
따라서 샘플링 프로세스가 좀 더 균일해지도록 여기에 어떤 형태의 노이즈를 추가합니다.

249
00:22:50,020 --> 00:22:54,020
이 모드 붕괴는 발생하지 않습니다.

250
00:22:54,020 --> 00:23:01,020
그래서 우리는 이상적으로 다음을 사용하여 점수 함수와 샘플을 학습하는 방법을 찾았습니다.

251
00:23:01,020 --> 00:23:04,020
랑주뱅 다이나믹스.

252
00:23:04,020 --> 00:23:15,020
따라서 기본적으로 점수만 사용하여 p/x에서 샘플링하고 이를 학습으로 대체합니다.

253
00:23:15,020 --> 00:23:16,020
점수 기능.

254
00:23:16,020 --> 00:23:30,020
x의 p와 n의 0, i의 무작위 노이즈로 일부 정규 노이즈 분포를 초기화합니다.

255
00:23:30,020 --> 00:23:32,020
그리고 우리는 이 방정식을 위와 같이 사용합니다.

256
00:23:32,020 --> 00:23:38,020
여기서도 원래 점수 함수를 학습 점수 함수로 대체합니다.

257
00:23:38,020 --> 00:23:44,020
그리고 엡실론이 0에 가까워지고 t가 무한대에 가까워지면 기본적으로 xu는 다음과 같이 보장됩니다.

258
00:23:44,020 --> 00:23:49,020
x의 p로 수렴합니다.

259
00:23:49,020 --> 00:23:57,020
그러나 실제로 이 공식은 좋은 샘플을 생성하지 않습니다.

260
00:23:57,020 --> 00:24:02,020
따라서 Langevin Dynamics에서 바닐라 점수 매칭 공식을 사용하는 것은 작동하지 않습니다.

261
00:24:02,020 --> 00:24:09,020
이것은 이것을 언급한 신문에서 제가 찍은 사진입니다.

262
00:24:10,020 --> 00:24:15,020
불행하게도 Langevin Dynamics와의 바닐라 스코어 매칭은 작동하지 않습니다.

263
00:24:15,020 --> 00:24:17,020
그렇다면 작동하지 않는 이유는 무엇입니까?

264
00:24:17,020 --> 00:24:23,020
이는 주로 우리의 데이터 포인트가 주로 거짓말을 한다는 수동 가설 때문입니다.

265
00:24:23,020 --> 00:24:26,020
설명서의 작은 부분에.

266
00:24:26,020 --> 00:24:36,020
데이터 점수는 대부분의 공간에서 이러한 이유로 정의되지 않으며 이 계산은

267
00:24:36,020 --> 00:24:37,020
0으로 밝혀졌습니다.

268
00:24:37,020 --> 00:24:44,020
따라서 우리는 공간의 다른 부분에서 그라데이션을 얻지 못하고 모드를 혼합하지 않습니다.

269
00:24:44,020 --> 00:24:50,020
따라서 데이터 포인트가 없기 때문에 여기서 미적분학 점수 함수, 미적분학을 보면

270
00:24:50,020 --> 00:24:52,020
이 영역의 점수는 꽤 나쁩니다.

271
00:24:52,020 --> 00:24:55,020
그래서 이 지역과 이 지역에서는 꽤 정확합니다.

272
00:24:55,020 --> 00:24:57,020
여기서는 부정확합니다.

273
00:24:57,020 --> 00:25:00,020
그러면 이 문제를 어떻게 해결하나요?

274
00:25:00,020 --> 00:25:02,020
그렇다면 이를 어떻게 개선할 수 있을까요?

275
00:25:02,020 --> 00:25:10,020
그래서 기본적으로 우리는 노이즈를 추가하여 데이터 분포를 설정하고 기본적으로 이는 증가합니다.

276
00:25:10,020 --> 00:25:12,020
미적분학 점수 함수의 정확성.

277
00:25:12,020 --> 00:25:17,020
여기와 이 지역에도 일부 세그먼트가 있으므로 점수 함수는 다음과 같습니다.

278
00:25:17,020 --> 00:25:22,020
포인트의 방향에 따라 포인트가 훨씬 더 정확해집니다.

279
00:25:22,020 --> 00:25:29,020
그러나 밀도 부분은 더 이상 실제 데이터 밀도에 정확하게 근접하지 않습니다.

280
00:25:29,020 --> 00:25:35,020
그래서 그것은 또한 사기입니다.

281
00:25:35,020 --> 00:25:41,020
따라서 데이터 품질과 우리가 처리하는 방식의 규모 사이에는 본질적인 상충 관계가 있습니다.

282
00:25:41,020 --> 00:25:44,020
데이터 밀도가 낮은 지역.

283
00:25:44,020 --> 00:25:52,020
스펙트럼의 한쪽 끝에는 데이터 분포의 일부가 되도록 작은 노이즈 양을 추가합니다.

284
00:25:52,020 --> 00:25:57,020
여전히 원본 데이터에 가깝지만 데이터 밀도가 낮은 영역이 커질 수 있습니다.

285
00:25:57,020 --> 00:26:03,020
스펙트럼의 반대쪽에는 낮은 데이터 밀도를 유지하기 위해 많은 양의 노이즈를 추가합니다.

286
00:26:03,020 --> 00:26:06,020
지역은 작지만 이로 인해 원본 데이터가 파괴됩니다.

287
00:26:06,020 --> 00:26:11,020
따라서 스펙트럼의 양면을 중재하기 위해 저자는 다음과 같은 제안을 제안했습니다.

288
00:26:11,020 --> 00:26:16,020
다양한 소음 수준의 데이터를 동시에 수집하고 모든 소음의 정보를 집계합니다.

289
00:26:16,020 --> 00:26:19,020
수준.

290
00:26:19,020 --> 00:26:26,020
여기서 우리는 추가되는 노이즈의 양과 점수의 품질 사이의 균형을 볼 수 있습니다.

291
00:26:26,020 --> 00:26:31,020
기능이 학습되고 있습니다.

292
00:26:31,020 --> 00:26:43,020
따라서 구분당 노이즈가 없으면 데이터 밀도가 낮은 지역에서 추정 점수가 낮습니다.

293
00:26:43,020 --> 00:26:49,020
따라서 학습된 점수 함수는 매우 부정확하며 정보가 많지 않습니다.

294
00:26:49,020 --> 00:26:55,020
모드를 향해 나아가기 위해서는 어느 방향으로 움직여야 하는지에 대한 역동적인 과정.

295
00:26:55,020 --> 00:27:00,020
그러나 대안으로 단일 노이즈 스케일을 사용하여 커버할 데이터 분포를 설정할 수 있습니다.

296
00:27:00,020 --> 00:27:03,020
데이터 밀도가 낮은 지역의 상당 부분.

297
00:27:03,020 --> 00:27:06,020
추가해야 할 소음도 큽니다.

298
00:27:06,020 --> 00:27:10,020
이는 큰 역학이 높은 데이터 밀도에서 멀리 떨어져 있을 때 추가 정보를 제공합니다.

299
00:27:10,020 --> 00:27:17,020
영역과 멀리 떨어져 있는 실제로 학습된 점수 함수를 완전히 파괴합니다.

300
00:27:17,020 --> 00:27:21,020
원본 데이터 포인트의 점수.

301
00:27:21,020 --> 00:27:25,020
따라서 이 문제는 여러 개의 노이즈 스케일을 추가하여 해결할 수 있습니다.

302
00:27:25,020 --> 00:27:32,020
따라서 여러 척도로 분포된 소음 점수는 방향성을 제공할 수 있습니다.

303
00:27:32,020 --> 00:27:38,020
다양한 세분화된 정보를 제공하고 다양한 거리에서 유용한 지침을 제공합니다.

304
00:27:38,020 --> 00:27:41,020
데이터 밀도가 높은 지역에서.

305
00:27:41,020 --> 00:27:49,020
그러면 다양한 소음 점수를 사용하여 소음 상태 점수 네트워크에서 어떻게 샘플링합니까?

306
00:27:49,020 --> 00:27:50,020
수준?

307
00:27:50,020 --> 00:27:53,020
따라서 이 방법을 Annealed Langevin Dynamics라고 합니다.

308
00:27:53,020 --> 00:27:58,020
우리는 다양한 수준의 교란된 데이터 분포 순차에 대해 langevin 역학을 수행합니다.

309
00:27:58,020 --> 00:28:03,020
먼저 langevin 역학을 사용하여 가장 교란된 데이터 분포에서 샘플링한 다음

310
00:28:03,020 --> 00:28:08,020
결과 샘플은 다음 소음 수준 샘플링을 위한 초기 샘플로 사용됩니다.

311
00:28:08,020 --> 00:28:13,020
우리는 이런 방식을 계속하고 마지막으로 langevin 역학을 사용하여 최소한의 샘플링을 수행합니다.

312
00:28:13,020 --> 00:28:33,020
교란된 데이터 분포를 사용하여 원본 데이터 샘플을 생성하거나 재생성합니다.

313
00:28:33,020 --> 00:28:37,020
이것이 기본적으로 우리가 이전에 설명한 알고리즘입니다.

314
00:28:37,020 --> 00:28:49,020
여기서는 다양한 스케일 노이즈를 생성하고 이를 방정식에 추가하여 xt 거듭제곱을 도출합니다.

315
00:28:49,020 --> 00:28:55,020
여기에서는 랑주빈 역학과 어닐링된 랑주빈 역학을 보여줍니다.

316
00:28:55,020 --> 00:29:01,020
따라서 어닐링된 랑주빈 동역학은 상대 방식의 부정확한 추정을 효과적으로 완화합니다.

317
00:29:01,020 --> 00:29:03,020
다른 모드 사이.

318
00:29:03,020 --> 00:29:11,020
따라서 두 가지 질문이 혼합된 이 예에서 여기에서 랑주빈 역학이 명확하게 나타납니다.

319
00:29:11,020 --> 00:29:16,020
효과적으로 캡처되는 모드의 상대적 가중치를 캡처해야 합니다.

320
00:29:16,020 --> 00:29:20,020
어닐링된 랑주빈 동역학이며 정확한 샘플에 매우 가깝습니다.

321
00:29:20,020 --> 00:29:24,020
따라서 이 모드의 질량은 꽤 적습니다.

322
00:29:24,020 --> 00:29:32,020
여기 langevin 역학에 따르면 꽤 높습니다.

323
00:29:32,020 --> 00:29:37,020
교란된 각 데이터 분포에 대해 가장 구체적으로 우리는 그로부터 쉽게 샘플링할 수 있습니다.

324
00:29:37,020 --> 00:29:41,020
점수 추정을 사용하여 해당 점수를 추정합니다.

325
00:29:41,020 --> 00:29:45,020
그러나 이를 수행하는 가장 순진한 방법에는 수많은 별도의 점수 모델이 필요합니다.

326
00:29:45,020 --> 00:29:48,020
독립적으로 학습하려면 비용이 많이 듭니다.

327
00:29:48,020 --> 00:29:54,020
대신 단일 조건부 점수 네트워크를 사용하여 점수를 공동으로 추정하는 것을 제안합니다.

328
00:29:54,020 --> 00:29:56,020
모든 섭동 수준에 대해.

329
00:29:56,020 --> 00:29:59,020
점수 모델은 시그마를 입력으로 사용합니다.

330
00:29:59,020 --> 00:30:05,020
이 모델을 잡음 조건 점수 네트워크라고 합니다.

331
00:30:05,020 --> 00:30:08,020
그렇다면 노이즈 조건부 점수 네트워크를 어떻게 훈련시킬 수 있을까요?

332
00:30:08,020 --> 00:30:12,020
훈련은 점수 매칭을 사용하기 전의 점수 네트워크와 정확히 유사합니다.

333
00:30:12,020 --> 00:30:17,020
우리는 자연스럽게 점수를 추정하는 데 적합하므로 잡음 제거 점수 매칭을 사용하는 것을 선호합니다.

334
00:30:17,020 --> 00:30:19,020
또는 교란된 데이터 분포.

335
00:30:19,020 --> 00:30:22,020
그리고 우리는 잡음 제거 점수 일치 손실의 가중치 조합을 사용합니다.

336
00:30:22,020 --> 00:30:25,020
그래서 이것이 무게를 주는 것입니다.

337
00:30:25,020 --> 00:30:30,020
그리고 시그마 i의 랩 레이어는 종종 다음과 같이 간주됩니다. 이는 양의 가중치 함수입니다.

338
00:30:30,020 --> 00:30:34,020
그리고 그것은 종종 시그마 i 제곱으로 간주됩니다.

339
00:30:34,020 --> 00:30:41,020
여기서 노이즈 스케일링이 발생합니다.

340
00:30:41,020 --> 00:30:47,020
이 손실 함수는 매우 일반적이며 첫 번째 논문에서는 다른 형태로 사용되었습니다.

341
00:30:47,020 --> 00:30:53,020
2015년에 심층 생성 모델링을 위한 다양한 모델을 도입했습니다.

342
00:30:53,020 --> 00:31:02,020
그리고 DDPM의 2020년 논문에서 다른 형식으로 다시 사용되었습니다.

343
00:31:02,020 --> 00:31:08,020
따라서 이전 슬라이드에서 언급한 것처럼 이 양의 가중치 함수는 다음과 같이 취할 수 있습니다.

344
00:31:08,020 --> 00:31:16,020
시그마 i의 임의의 양의 함수이며 시그마 i 제곱을 취하는 것이 선호됩니다.

345
00:31:16,020 --> 00:31:21,020
요약하자면, 이것이 기본적으로 어닐링 엔지니어링 역학이 작동하는 방식입니다.

346
00:31:21,020 --> 00:31:26,020
노이즈 수준이 점차 높아지는 점수 함수가 있습니다.

347
00:31:26,020 --> 00:31:32,020
그리고 해당 소음 수준으로부터 확률 분포를 학습합니다.

348
00:31:32,020 --> 00:31:37,020
잡음 조건부 점수 모델을 사용합니다.

349
00:31:37,020 --> 00:31:44,020
어닐링 엔지니어링 역학을 사용하여 위에서 샘플링하면 생성된 샘플이 이제 생성됩니다.

350
00:31:44,020 --> 00:31:50,020
품질이 매우 좋습니다.

351
00:31:50,020 --> 00:31:57,020
또한 이러한 모델의 측정 항목, 시작 점수 및 FID 점수 측면에서도

352
00:31:57,020 --> 00:32:02,020
또한 꽤 훌륭하고 시중의 최고의 GAN 모델과 동등합니다.

353
00:32:02,020 --> 00:32:07,020
다음은 다양한 해상도의 다양한 이미지 데이터세트에 대한 추가 샘플입니다.

354
00:32:07,020 --> 00:32:10,020
모두 위에 언급된 기술에 따라 훈련되고 샘플링되었습니다.

355
00:32:10,020 --> 00:32:14,020
따라서 생성된 이미지의 품질과 품질이 매우 우수하다는 것을 알 수 있습니다.

356
00:32:14,020 --> 00:32:18,020
다양성도 꽤 좋습니다.

357
00:32:18,020 --> 00:32:22,020
이제 확률론적 미분방정식을 사용하는 점수 기반 생성 모델로 넘어갑니다.

358
00:32:22,020 --> 00:32:28,020
SGS와 ODE를 사용한 조건부 확산 모델을 볼 수 있습니다.

359
00:32:28,020 --> 00:32:34,020
이전에는 여러 노이즈 스케일을 추가하는 것이 점수 기반 생성 모델의 성공에 어떻게 중요한지 이미 논의했습니다.

360
00:32:34,020 --> 00:32:38,020
노이즈 스케일보다 생성된 샘플이 더 좋습니다.

361
00:32:38,020 --> 00:32:42,020
따라서 저자는 노이즈 스케일의 수를 무한대로 일반화하여 다음을 얻었습니다.

362
00:32:42,020 --> 00:32:47,020
고품질의 샘플뿐만 아니라 정확한 우도 계산도 가능합니다.

363
00:32:47,020 --> 00:32:51,020
역 문제 해결을 위한 제어 가능한 생성.

364
00:32:51,020 --> 00:32:54,020
그렇다면 NST로 데이터를 어떻게 교란시킬 수 있을까요?

365
00:32:54,020 --> 00:32:58,020
데이터를 임의의 솔트 및 페이퍼 가우스 노이즈로 교란하는 것은 쉽습니다.

366
00:32:58,020 --> 00:33:01,020
어려운 부분은 반대 과정을 수행하는 것입니다.

367
00:33:01,020 --> 00:33:04,020
따라서 노이즈 스케일의 수가 무한대에 가까워지면

368
00:33:04,020 --> 00:33:08,020
데이터 분포는 지속적으로 증가하는 노이즈 수준으로 인해 본질적으로 교란됩니다.

369
00:33:08,020 --> 00:33:13,020
이 경우 잡음 교란 절차는 연속 시간 확률론적 과정입니다.

370
00:33:13,020 --> 00:33:19,020
아래 동영상에서 보여주듯이요.

371
00:33:19,020 --> 00:33:26,020
따라서 처음에는 유한한 시간 단계에서 서로 다른 스케일의 노이즈를 추가했다는 것을 여기서 볼 수 있습니다.

372
00:33:26,020 --> 00:33:36,020
이제 우리는 연속적인 시간 잡음 분포에서 샘플을 추출하여 이를 근사화할 수 있습니다.

373
00:33:36,020 --> 00:33:42,020
이것이 원래 데이터 분포이고 이것이 사전 샘플링입니다.

374
00:33:42,020 --> 00:33:47,020
우리의 경우에는 대부분 균일한 가우스 분포입니다.

375
00:33:47,020 --> 00:33:53,020
따라서 처음에는 유한한 시간 단계에서 다양한 노이즈 레벨을 그립니다.

376
00:33:53,020 --> 00:34:00,020
이제 그 사이의 단계를 계속 증가시키면 교란된 소음이 지속적으로 분포됩니다.

377
00:34:00,020 --> 00:34:11,020
그리고 우리는 이를 x의 Pt로 표시합니다. 여기서 t는 0과 유한 시간 자본 T 사이의 실수입니다.

378
00:34:11,020 --> 00:34:15,020
따라서 이것은 x의 P0로 표시된 원래 데이터 분포입니다.

379
00:34:15,020 --> 00:34:19,020
이것이 우리가 최종적으로 수렴하는 노이즈 분포입니다.

380
00:34:19,020 --> 00:34:28,020
대부분의 경우 이는 x의 Pt 대문자 T인 표준 가우스입니다.

381
00:34:28,020 --> 00:34:34,020
그렇다면 x의 P0에서 가져온 깨끗한 데이터 샘플에 노이즈를 어떻게 제거할까요?

382
00:34:34,020 --> 00:34:37,020
우리는 확률론적 프로세스를 사용하여 이를 수행합니다.

383
00:34:37,020 --> 00:34:43,020
노이즈를 추가한 후 다소 가우스 분포에 가깝게 수렴됩니다.

384
00:34:43,020 --> 00:34:48,020
이는 순방향 확률미분 방정식을 사용하여 수행됩니다.

385
00:34:48,020 --> 00:34:55,020
결정론적 항 외에 극미량의 노이즈가 추가된 드리프트 항도 있습니다.

386
00:34:55,020 --> 00:35:03,020
이제 일반화의 손실 없이 결정론적 표류를 무시한 장난감 SD를 살펴보겠습니다.

387
00:35:03,020 --> 00:35:10,020
여기 람다는 연속적인 람다 i 세대와 이전에 가졌던 소음 수준입니다.

388
00:35:10,020 --> 00:35:16,020
그리고 이것은 이전과 같이 아주 작은 소음입니다.

389
00:35:16,020 --> 00:35:20,020
이제 우리가 정의한 이전 항목에서 샘플을 어떻게 생성합니까?

390
00:35:20,020 --> 00:35:24,020
우리는 역확률 과정을 사용하여 이를 수행합니다.

391
00:35:25,020 --> 00:35:33,020
이것이 바로 우리가 정의한 순방향 확률미분방정식이었습니다.

392
00:35:33,020 --> 00:35:41,020
이제 앤더슨은 1982년에 모든 확률론적 미분방정식에 대한 분석적 해법인 역SD를 제시했습니다.

393
00:35:41,020 --> 00:35:49,020
여기서는 소음 수준 외에 이전에 접했던 점수 함수도 볼 수 있습니다.

394
00:35:49,020 --> 00:35:53,020
그 외에도 아주 작은 소음도 있습니다.

395
00:35:53,020 --> 00:35:56,020
이제 시간 반대 방향으로 갑니다.

396
00:35:56,020 --> 00:36:04,020
이것은 순방향 및 역방향 확률미분방정식을 요약한 것입니다.

397
00:36:04,020 --> 00:36:12,020
점수 함수는 다시 점수 매칭을 사용하여 점수 모델로 대체될 수 있습니다.

398
00:36:12,020 --> 00:36:19,020
이는 잡음 제거 과정의 훈련 목표로 밝혀졌습니다.

399
00:36:19,020 --> 00:36:27,020
여기서 이 긍정적인 가중치 함수는 일반적으로 각 시간 단계에서 추가되는 노이즈의 양을 측정하는 상수입니다.

400
00:36:27,020 --> 00:36:36,020
일반적으로 시그마 t 제곱으로 유지되지만 시그마 t와 관련된 양수일 수 있습니다.

401
00:36:36,020 --> 00:36:43,020
따라서 역SD를 역시간 확률론적 프로세스와 유사하게 해결하여 샘플을 생성할 수 있습니다.

402
00:36:43,020 --> 00:36:47,020
Euler-Moiroma 방법과 같은 SD 솔버를 사용할 수 있습니다.

403
00:36:47,020 --> 00:36:51,020
이는 OD를 해결하기 위한 오일러의 방법과 동일한 아이디어를 기반으로 합니다.

404
00:36:51,020 --> 00:36:57,020
기본적으로 우리는 무한한 시간 간격 dt를 작은 시간차 델타 t로 대체할 수 있습니다.

405
00:36:57,020 --> 00:37:03,020
가우시안 노이즈를 통해 극소 백색 노이즈를 델타 t에 따른 분산으로 대체합니다.

406
00:37:04,020 --> 00:37:13,020
여기서 델타 t는 역잡음 제거 프로세스이고 대문자 T에서 0으로 이동하므로 음의 시간 단계입니다.

407
00:37:13,020 --> 00:37:19,020
점수 함수를 시간 함수로 근사화하기 위해 시간 의존성 점수 기반 모델을 훈련할 수 있습니다.

408
00:37:19,020 --> 00:37:23,020
이 시간 의존성 점수 기반 모델은 시간 t에 대한 신경망 조건입니다.

409
00:37:23,020 --> 00:37:30,020
먼저 t를 무작위로 샘플링한 다음 앞서 이미 정의한 해당 점수 일치 손실을 최소화하여 훈련할 수 있습니다.

410
00:37:31,020 --> 00:37:34,020
이것이 우리가 만든 근사치입니다.

411
00:37:34,020 --> 00:37:43,020
x의 t를 x의 델타로 변경하고 dw를 z의 gt로 변경하고 z는 가우스 노이즈입니다.

412
00:37:43,020 --> 00:37:51,020
이산 오일러-모이로마(Euler-Moiroma) 유형의 방법을 사용하여 확률론적 프로세스를 시뮬레이션하고 있으므로

413
00:37:51,020 --> 00:37:56,020
값을 추정하는 동안 오류가 있을 수 있습니다.

414
00:37:57,020 --> 00:38:01,020
예측자-수정자 샘플링 방법을 사용하여 이를 수정할 수 있습니다.

415
00:38:01,020 --> 00:38:09,020
예측자는 수치적 SG 솔버이고 교정자는 점수 기반 MCMC 추정자입니다.

416
00:38:09,020 --> 00:38:23,020
그러면 이 방법은 어떻게 작동하나요?

417
00:38:23,020 --> 00:38:29,020
역시간 SG를 풀 때 먼저 예측기를 사용하여 다음 시간 단계에서 중간 샘플의 대략적인 추정치를 얻습니다.

418
00:38:29,020 --> 00:38:32,020
그런 다음 교정기를 사용하여 샘플을 미세 조정합니다.

419
00:38:32,020 --> 00:38:37,020
이 절차는 교란되지 않은 원래 데이터 분포에서 최종적으로 샘플을 얻을 때까지 여러 번 반복됩니다.

420
00:38:37,020 --> 00:38:48,020
교정기-교정기 방법은 ST를 해결하는 수치적 방법으로 무효화된 Langevin 동역학을 조합합니다.

421
00:38:48,020 --> 00:38:54,020
그러나 예측기의 도입은 Langevin 역학이 서로 다른 잡음 규모 사이를 원활하게 전환하는 데 도움이 됩니다.

422
00:38:54,020 --> 00:38:59,020
따라서 교정자-교정자 네트워크와 일부 아키텍처 개선을 통해

423
00:39:00,020 --> 00:39:07,020
소음 상태 점수 네트워크도 GAN을 충족하는 최첨단 결과를 얻을 수 있었습니다.

424
00:39:07,020 --> 00:39:12,020
그들의 모델은 FID 점수 2.2와 시작 점수 9.89를 달성했습니다.

425
00:39:12,020 --> 00:39:16,020
이전 최고의 결과는 데이터 증강을 통해 SILGAN2에 의해 달성되었습니다.

426
00:39:16,020 --> 00:39:19,020
이러한 방법은 데이터 증대 없이 수행되었습니다.

427
00:39:19,020 --> 00:39:26,020
또한 무조건 생성에 대한 FID 점수는 조건부 생성에 대한 최신 기술보다 훨씬 좋습니다.

428
00:39:26,020 --> 00:39:31,020
그리고 이것은 실제로 이 단계에서 큰 돌파구였습니다.

429
00:39:31,020 --> 00:39:41,020
이러한 개선을 통해 노이즈 상태 점수 네트워크는 GAN과 동등한 고해상도 1024 x 1024 이미지를 생성할 수 있습니다.

430
00:39:44,020 --> 00:39:47,020
다른 데이터 세트에서도 예를 볼 수 있습니다.

431
00:39:48,020 --> 00:39:55,020
이제 이러한 종류의 모델에서 정확한 작업 부하를 어떻게 계산합니까?

432
00:39:55,020 --> 00:39:58,020
이를 위해서는 SD를 ODE로 변환해야 합니다.

433
00:40:06,020 --> 00:40:08,020
그래서 이것이 우리가 이전에 고려했던 SD였습니다.

434
00:40:08,020 --> 00:40:10,020
해당 ODE는 다음과 같습니다.

435
00:40:10,020 --> 00:40:14,020
그리고 여기서 이것은 이전에 정의한 점수 함수에 따라 달라집니다.

436
00:40:14,020 --> 00:40:17,020
그리고 우리가 이미 알고 있는 소음 수준.

437
00:40:31,020 --> 00:40:37,020
따라서 우리는 이 공식을 연속적인 시간-무한 정규화 흐름으로 간주할 수 있습니다.

438
00:40:37,020 --> 00:40:40,020
이는 2018년 신경 ODE 논문에 정의된 것입니다.

439
00:40:40,020 --> 00:40:45,020
따라서 이러한 고유한 ODE 솔루션은 가역 매핑을 생성합니다.

440
00:40:45,020 --> 00:40:48,020
반전시키기 위해 우리는 T20에서 거꾸로 ODE를 풀었습니다.

441
00:40:51,020 --> 00:40:53,020
이것이 우리의 이전 배포판이었습니다.

442
00:40:53,020 --> 00:41:05,020
또한 ODE가 사전 분포에서 추출한 잡음을 고품질 데이터 샘플(x의 p theta)에 매핑하는 것을 볼 수 있습니다.

443
00:41:06,020 --> 00:41:12,020
이제 x의 pθ와 생성된 샘플의 로그 우도를 어떻게 얻을 수 있을까요?

444
00:41:12,020 --> 00:41:17,020
그래서 우리는 2018년 신경 ODE 논문에서 제안된 변수 변경 공식을 사용하여 이를 얻습니다.

445
00:41:17,020 --> 00:41:26,020
그리고 이는 다항식 시간으로 계산할 수 있고 편견 없는 추정자인 점수 함수에만 의존합니다.

446
00:41:26,020 --> 00:41:33,020
그리고 이 적분은 1차원 적분이므로 ODE 솔버를 사용하여 쉽게 풀 수 있습니다.

447
00:41:34,020 --> 00:41:35,020
이제 그것의 장점은 무엇입니까?

448
00:41:35,020 --> 00:41:46,020
정확한 우도 값을 얻는 것 외에도 ODE를 사용하여 샘플을 풀고 그리는 것이 훨씬 더 효율적입니다.

449
00:41:46,020 --> 00:41:55,020
보시다시피 SD 솔버는 수천 번의 점수 함수 평가를 수행한 반면 적응형 ODE 솔버는 거의 100번을 수행했습니다.

450
00:41:55,020 --> 00:41:58,020
즉, 계산이 10배 감소한 것입니다.

451
00:41:59,020 --> 00:42:12,020
그리고 이러한 방법은 DDIM에서와 같이 가속화된 샘플링 방법을 만들기 위해 이후의 더 인기 있는 논문에서만 사용되었습니다.

452
00:42:12,020 --> 00:42:29,020
따라서 블랙박스 ODE 솔버와 흐름 기반 모델은 여기에서 볼 수 있듯이 이전 방법에 비해 최첨단 음의 로그 우도 값, 더 낮고 더 나은 FID 점수를 달성했습니다.

453
00:42:32,020 --> 00:42:37,020
확률 흐름 모델에는 고유하게 식별 가능한 인코딩이라는 또 다른 장점도 있습니다.

454
00:42:37,020 --> 00:42:49,020
일반 흐름 모델과 VAE의 경우, 이 항은 모델의 매개변수 세타에 의존하기 때문에 서로 다른 모델을 사용하면 잠재 공간에서 서로 다른 잠재가 발생합니다.

455
00:42:49,020 --> 00:42:57,020
그러나 확률 흐름 ODE를 통한 점수 기반 모델은 훈련 데이터 세트에 의존하는 점수 함수에만 의존합니다.

456
00:42:57,020 --> 00:43:04,020
따라서 이는 모델의 매개변수와 무관하므로 다른 모델을 사용하더라도 잠재 공간에서 동일한 잠재 공간이 발생합니다.

457
00:43:05,020 --> 00:43:20,020
논문에 제시된 실험에서 우리는 두 개의 서로 다른 잠재성을 사용하더라도 잠재 공간의 비슷한 지점으로 거의 수렴하고 서로 다른 시간 단계에 걸쳐 항상 서로 흐른다는 것을 알 수 있습니다.

458
00:43:22,020 --> 00:43:26,020
점수 함수와 점수 테스트 모델을 사용하여 제어 수준 생성을 수행할 수도 있습니다.

459
00:43:27,020 --> 00:43:35,020
이것이 우리의 원래 데이터 분포 P(x)였습니다. 이제 우리는 이를 y 값에 따라 조건을 지정합니다. 이는 레이블이 될 수도 있고 값을 지정할 수도 있습니다.

460
00:43:36,020 --> 00:43:43,020
따라서 우리의 경우 이제 또 다른 순방향 모델이 있습니다. 이는 x가 주어진 y의 P이고 y는 제어 신호입니다.

461
00:43:43,020 --> 00:43:48,020
따라서 이 경우 y는 기본적으로 분류자 레이블입니다.

462
00:43:49,020 --> 00:43:59,020
따라서 베이즈 규칙을 사용하여 이것을 분석하면 이전 데이터 분포인 y에 대한 x의 P를 x에 대한 y의 P를 y의 P로 나눈 값으로 얻습니다.

463
00:43:59,020 --> 00:44:12,020
따라서 우리는 P/y를 모르지만 이에 대해 점수 함수 규칙을 적용하면 로그를 취하고 x에 대한 기울기를 취하면 이 값은 0이 됩니다. 왜냐하면 y의 P에 대한 로그이기 때문입니다. x에 종속되지 않습니다.

464
00:44:13,020 --> 00:44:25,020
그러면 우리는 오랫동안 사용했던 x의 무조건 점수 S theta와 x가 주어진 경우 x의 log of y의 기울기인 이 값이 남습니다.

465
00:44:25,020 --> 00:44:30,020
이제 이것은 기본적으로 분류기 또는 수동으로 정의된 다른 것일 수 있는 순방향 모델입니다.

466
00:44:30,020 --> 00:44:37,020
따라서 우리는 이것을 그대로 유지할 수 있으며 동일한 점수 모델에 대해 다른 전달 모델을 연결할 수 있습니다.

467
00:44:38,020 --> 00:44:49,020
이제 y가 클래스 수준이고 x가 주어진 y의 P가 시간 종속 분류자라면 이러한 종류의 분류자 안내 이미지 생성을 수행할 수 있습니다.

468
00:44:51,020 --> 00:44:58,020
인페인팅과 같은 다른 작업도 수행할 수 있습니다. 여기서는 이것이 실제값이고, 이것이 마스크된 이미지이고, 이것이 인페인팅된 이미지입니다.

469
00:44:59,020 --> 00:45:11,020
우리는 또한 이미지의 색상화를 수행할 수 있으므로 이것이 실측 값이고 이것은 회색조 이미지 y이며 y가 주어지면 색상화된 이미지 x를 얻습니다.

470
00:45:13,020 --> 00:45:21,020
그래서 마지막으로 점수 기반 생성 모델을 소개했고, SD와 OD를 사용하여 샘플을 추출하는 방법도 살펴보았습니다.

471
00:45:22,020 --> 00:45:30,020
따라서 x에 대한 분포의 기울기인 점수 함수는 쉽게 추정할 수 있으며 모델의 매개변수에 의존하지 않습니다.

472
00:45:31,020 --> 00:45:38,020
이는 구조적 유연성을 제공하며 모델의 정규화 상수 또는 가역성에 제한되지 않습니다.

473
00:45:39,020 --> 00:45:44,020
훈련은 안정적이므로 GAN에서처럼 미니맥스 최적화나 적대적 훈련이 필요하지 않습니다.

474
00:45:44,020 --> 00:45:51,020
둘째, 점수 기반 생성 모델은 일반적으로 GAN과 비슷하거나 심지어 이를 능가하는 매우 높은 샘플 품질을 달성합니다.

475
00:45:52,020 --> 00:45:56,020
이는 현재 CFAT 및 기타 일반 데이터 세트에 대한 최첨단 방법입니다.

476
00:45:57,020 --> 00:46:02,020
최대 1024 x 1024 해상도의 이미지로 확장 가능합니다.

477
00:46:03,020 --> 00:46:12,020
마지막으로 애니메이션 감지 등 많은 다운스트림 애플리케이션에 사용되는 점수 함수의 정확한 가능성을 계산할 수도 있습니다.

478
00:46:13,020 --> 00:46:21,020
CFAT 10에서 얻은 가능성은 매우 비교적이며 균일하게 역양자화된 데이터에 대해 평가된 최첨단 기술입니다.

479
00:46:22,020 --> 00:46:28,020
신경 OD와 동등하므로 보간 및 온도 스케일링과 같은 많은 인상적인 기능도 가능합니다.

480
00:46:29,020 --> 00:46:39,020
또한 이러한 점수 기반 모델로 학습된 인코딩은 VA 및 일반 흐름 모델의 경우와 달리 고유하게 식별 가능합니다.

481
00:46:40,020 --> 00:46:43,020
지금까지 점수 기반 생성 모델에 대해 이야기했습니다.

482
00:46:44,020 --> 00:46:50,020
이제 잡음 제거 확산 프롤로지스틱 모델로 알려진 생성 모델의 더 넓은 범주에 대해 이야기해 보겠습니다.

483
00:46:51,020 --> 00:46:56,020
이는 주어진 훈련 데이터 세트와 유사한 새로운 데이터 샘플을 생성하는 방법을 학습할 수 있는 알고리즘입니다.

484
00:46:57,020 --> 00:47:05,020
DDPM의 확산 항은 원본 내용이 완전히 가려질 때까지 데이터 샘플에 노이즈를 점진적으로 추가하는 프로세스를 나타냅니다.

485
00:47:06,020 --> 00:47:11,020
이 과정은 순수한 노이즈가 될 때까지 이미지를 천천히 뒤섞는 것과 유사합니다.

486
00:47:12,020 --> 00:47:17,020
이 프로세스 부분을 순방향 확산 프로세스라고 하며 비교적 간단하고 고정되어 있습니다.

487
00:47:19,020 --> 00:47:22,020
반면 DDPM의 핵심은 반대 프로세스입니다.

488
00:47:23,020 --> 00:47:25,020
확산을 제거하거나 반전시키는 방법을 배웁니다.

489
00:47:26,020 --> 00:47:33,020
랜덤 노이즈에서 시작하여 모델은 점차적으로 샘플을 단계별로 구성하여 결국 이미지와 같은 일관된 데이터 포인트로 이어집니다.

490
00:47:34,020 --> 00:47:38,020
이 프로세스는 데이터에서 학습되며 모델의 복잡성이 여기에 있습니다.

491
00:47:39,020 --> 00:47:41,020
이제 순방향 확산 과정에 대해 이야기해 보겠습니다.

492
00:47:42,020 --> 00:47:50,020
데이터 샘플 X0이 주어지면 데이터 샘플에 아무것도 남지 않을 때까지 점차적으로 노이즈를 계속 추가하고 순수한 노이즈가 있게 됩니다.

493
00:47:51,020 --> 00:47:54,020
순방향 프로세스는 Markov 체인 모델이라고 가정합니다.

494
00:47:55,020 --> 00:48:02,020
이는 특정 타임스탬프 Xt에 대해 Xt의 확률 Q가 모델에만 의존한다는 것을 의미합니다.

495
00:48:03,020 --> 00:48:06,020
이는 이전 타임스탬프가 아니라 이전 타임스탬프에 따라 달라집니다.

496
00:48:08,020 --> 00:48:18,020
따라서 마르코프 체인 모델에 따르면 X0이 주어지면 1에서 T까지 X의 결합 분포 Q는 Xt에서 1을 뺀 Xt의 Q의 곱이 될 수 있습니다.

497
00:48:19,020 --> 00:48:23,020
그리고 Xt에서 1을 뺀 값이 주어지면 Xt의 Q를 가우스 분포로 정의할 수 있습니다.

498
00:48:26,020 --> 00:48:32,020
여기서 베타 T는 변형 스케줄러이며 단계 크기를 제어합니다.

499
00:48:33,020 --> 00:48:36,020
특정 시간 단계에 추가되는 노이즈의 양을 제어합니다.

500
00:48:37,020 --> 00:48:47,020
더 단순화하기 위해 알파 T를 1에서 베타 T를 뺀 것과 같고 알파 막대 T를 모든 알파 물결표에 mt를 곱한 값으로 정의하겠습니다.

501
00:48:48,020 --> 00:49:00,020
이는 X0이 주어지면 Xt의 Q가 알파 막대 T X0의 제곱근과 같은 평균을 갖는 가우스 분포가 된다는 것을 의미합니다.

502
00:49:00,020 --> 00:49:03,020
분산은 1에서 알파 T bar I을 뺀 것과 같습니다.

503
00:49:04,020 --> 00:49:13,020
하지만 한 가지 문제가 있습니다. Xt에 대해 샘플링하려면 시간 t가 0이 되는 시점부터 T번 분포를 샘플링해야 합니다.

504
00:49:14,020 --> 00:49:15,020
이는 바람직하지 않습니다.

505
00:49:20,020 --> 00:49:21,020
그러면 어떻게 해결할 수 있나요?

506
00:49:22,020 --> 00:49:28,020
X0이 주어진 경우 Xt의 확률 분포 Q는 마지막 슬라이드에서 논의한 대로 가우스 분포라는 점에 주목했습니다.

507
00:49:29,020 --> 00:49:31,020
이는 확산 커널이라고도 합니다.

508
00:49:34,020 --> 00:49:41,020
이에 대해 매개변수 트릭을 사용하면 임의의 시간 mt에서 이 분포에서 Xt를 직접 샘플링할 수 있습니다.

509
00:49:42,020 --> 00:49:43,020
이것이 재매개변수화 트릭입니다.

510
00:49:44,020 --> 00:49:52,020
여기서 Xt는 분포의 평균에 n0i에서 샘플링된 작은 노이즈의 분산을 곱한 값과 같습니다.

511
00:49:53,020 --> 00:50:03,020
여기서 한 가지 주의할 점이 있습니다. 작은 t를 대문자 T로 바꾸면 이 확산 커널을 사용하여 최종 시간 단계를 직접 샘플링할 수 있습니다.

512
00:50:04,020 --> 00:50:10,020
그리고 우리는 이것이 순수한 노이즈이기 때문에 최종 시간 단계가 가능한 한 n0i에 가까워지기를 원합니다.

513
00:50:11,020 --> 00:50:15,020
따라서 알파바 T가 0이 되도록 베타 T를 선택합니다.

514
00:50:17,020 --> 00:50:21,020
알파 T 값이 낮을수록 노이즈가 더 많이 추가됩니다.

515
00:50:23,020 --> 00:50:25,020
이제 분산 스케줄러 베타 T에 대해 이야기해 보겠습니다.

516
00:50:26,020 --> 00:50:31,020
베타 T의 값은 일반적으로 시간에 따라 선형적으로 증가하도록 선택됩니다.

517
00:50:33,020 --> 00:50:40,020
베타 0은 일반적으로 10의 4제곱승으로 가정하고 베타 T가 0.02가 될 때까지 선형적으로 증가합니다.

518
00:50:42,020 --> 00:50:48,020
베타 T는 시간 t에서 1을 뺀 값에 비해 시간 t에 추가된 노이즈의 백분율로 볼 수 있습니다.

519
00:50:49,020 --> 00:50:58,020
그런데 여기서 주의할 점이 하나 있습니다. 특정 시간 간격 t에 추가된 잡음의 양은 10의 제곱에서 4를 뺀 값과 0.02 사이의 비율이 아닙니다.

520
00:50:59,020 --> 00:51:04,020
오히려 이는 시간 0부터 시간 t까지의 모든 알파 T의 곱입니다.

521
00:51:06,020 --> 00:51:08,020
이는 확산 커널에서 쉽게 볼 수 있습니다.

522
00:51:10,020 --> 00:51:15,020
따라서 특정 시간 단계에서 추가되는 노이즈의 양은 기하급수적으로 증가합니다.

523
00:51:15,020 --> 00:51:20,020
우리는 추가된 노이즈의 양이 기하급수적으로 증가하도록 베타 T 값을 선택했습니다.

524
00:51:22,020 --> 00:51:28,020
그리고 더 늦은 타임스탬프, 더 높은 타임스탬프에서는 원본 데이터가 기하급수적으로 감소합니다.

525
00:51:33,020 --> 00:51:35,020
이것이 확산 관점입니다.

526
00:51:36,020 --> 00:51:44,020
데이터 분포가 주어지면 정규 분포가 될 만큼 데이터를 교란시키려고 합니다.

527
00:51:45,020 --> 00:51:52,020
x의 데이터 분포 p0가 있습니다. 정규 분포를 얻을 때까지 계속해서 교란합니다.

528
00:51:53,020 --> 00:52:01,020
우리는 일반적으로 이 정규 분포를 x의 파이(pi)라고 부릅니다. 이는 역과정에서 유용하므로 사전 분포라고도 합니다.

529
00:52:05,020 --> 00:52:09,020
이제 우리는 x0이 주어졌을 때 xt의 확률 q를 계산하는 방법을 알았습니다.

530
00:52:10,020 --> 00:52:15,020
하지만 x0에 대한 지식 없이 어떻게 xt의 q만 계산할 수 있을까요?

531
00:52:16,020 --> 00:52:24,020
xt의 q는 xt가 주어지면 x0의 결합 분포 q의 적분으로 작성될 수 있으며 이는 dx0에 대해 적분됩니다.

532
00:52:26,020 --> 00:52:31,020
이것은 x0의 q에 x0이 주어지면 xt의 q를 곱한 것으로 더 세분화될 수 있습니다.

533
00:52:32,020 --> 00:52:41,020
우리는 주어진 x0에서 xt의 q를 계산하는 방법을 알고 있으며 초기 분포인 x0의 q의 분포를 알고 있습니다.

534
00:52:42,020 --> 00:52:53,020
따라서 xt의 q를 사용하여 xt를 샘플링하려면 먼저 x0을 샘플링하여 x0의 q를 얻은 다음 확산 커널을 사용하여 xt를 샘플링해야 합니다.

535
00:52:54,020 --> 00:52:56,020
이를 조상 표본이라고도 합니다.

536
00:52:57,020 --> 00:53:00,020
자, 이제 DDPM의 반대 과정에 대해 이야기해 보겠습니다.

537
00:53:01,020 --> 00:53:04,020
순방향 프로세스에서 xt에서 1을 뺀 값이 주어지면 xt의 q를 계산하는 방법을 살펴보았습니다.

538
00:53:05,020 --> 00:53:10,020
역과정의 경우, 주어진 xt에서 p(xt - 1)를 계산해야 합니다.

539
00:53:11,020 --> 00:53:17,020
우리는 디스플레이 xt의 데이터 샘플이 무엇인지 알고 xt 빼기 1이 무엇인지 계산하려고 합니다.

540
00:53:18,020 --> 00:53:22,020
그러나 xt에서 다른 지점으로 도달할 수 있는 가능성이 너무 많습니다.

541
00:53:23,020 --> 00:53:26,020
따라서 주어진 xt에서 p(xt - 1)를 계산하는 것은 어렵습니다.

542
00:53:28,020 --> 00:53:29,020
어떻게 해야 할까요?

543
00:53:31,020 --> 00:53:37,020
우리는 주어진 xt에서 1을 뺀 xt의 함수 p theta를 추정하는 신경망을 만듭니다.

544
00:53:38,020 --> 00:53:44,020
우리는 이 매개변수 함수를 학습하는 모델을 만들고 세타는 여기에 있는 모델 매개변수입니다.

545
00:53:45,020 --> 00:53:47,020
그럼 노이즈 제거 항목이 어떻게 보이는지 살펴보겠습니다.

546
00:53:48,020 --> 00:53:56,020
우리는 xt 자본 xt의 q에 있고 이 잡음을 제거하고 x0까지 올리기를 원합니다.

547
00:53:57,020 --> 00:54:03,020
이제 xt의 q 값이 정규 분포가 되도록 확산 매개변수가 설계되었습니다.

548
00:54:04,020 --> 00:54:08,020
우리는 xt의 q의 q값이 n0i가 되도록 분산 스케줄러를 선택합니다.

549
00:54:09,020 --> 00:54:15,020
따라서 먼저 정규 분포에서 xt 자본 X 자본 T를 샘플링하는 것부터 시작합니다.

550
00:54:16,020 --> 00:54:20,020
그런 다음 xt에서 주어진 xt에서 1을 뺀 q를 반복적으로 샘플링합니다.

551
00:54:21,020 --> 00:54:23,020
그것이 우리의 발걸음이 되어야 합니다.

552
00:54:24,020 --> 00:54:25,020
그러나 여기에 문제가 있습니다.

553
00:54:26,020 --> 00:54:33,020
계산하기가 매우 어렵고 다루기 어렵기 때문에 모든 단계에 대해 주어진 xt에서 xt - 1의 q를 계산할 수 없습니다.

554
00:54:35,020 --> 00:54:42,020
그러나 주어진 xt에서 xt - 1의 q에서 xt를 샘플링하는 대신 x0에 대해서도 이 확률을 조건으로 지정하면 어떻게 될까요?

555
00:54:43,020 --> 00:54:47,020
이제 우리는 xt 쉼표 x0이 주어지면 xt 빼기 1의 q를 계산해야 합니다.

556
00:54:49,020 --> 00:54:54,020
그리고 이 확률에 베이즈 규칙을 사용하면 xt에서 1쉼표 x0을 뺀 값인 xt의 q를 얻게 됩니다.

557
00:54:55,020 --> 00:54:58,020
xt의 q에서 x0이 주어지면 1을 뺀 값을 x0이 주어지면 xt의 q로 나눈 값을 곱합니다.

558
00:54:59,020 --> 00:55:05,020
주의 깊게 살펴보면 이 세 가지 용어는 모두 확산 커널이며 계산하기 쉽습니다.

559
00:55:06,020 --> 00:55:09,020
확산 커널은 가우스 분포입니다.

560
00:55:09,020 --> 00:55:15,020
따라서 세 개의 확산 커널을 곱하고 나누면 가우스 분포도 생성됩니다.

561
00:55:17,020 --> 00:55:20,020
이 확률 분포의 평균이 누 물결표라고 가정해 보겠습니다.

562
00:55:21,020 --> 00:55:25,020
xt 쉼표 x0에 따라 달라지며 분산은 베타 T 물결표입니다.

563
00:55:26,020 --> 00:55:30,020
뉴틸드의 값은 다음 공식으로 계산됩니다.

564
00:55:31,020 --> 00:55:32,020
계산하는 것은 매우 쉽습니다.

565
00:55:33,020 --> 00:55:36,020
가우스 분포를 곱하고 나누기만 하면 됩니다.

566
00:55:37,020 --> 00:55:45,020
재매개변수적 트릭을 사용하고 이 방정식을 사용하여 x0 값을 대입하면 다음과 같은 틸드를 얻습니다.

567
00:55:46,020 --> 00:55:49,020
이는 더 이상 x0에 의존하지 않고 xt에만 의존한다는 점에 유의하세요.

568
00:55:50,020 --> 00:55:55,020
따라서 더 이상 nu tilde xt comma x0을 쓸 필요가 없습니다. 그냥 nu T tilde로 쓰면 됩니다.

569
00:55:56,020 --> 00:55:59,020
그리고 여기 엡실론 T는 정규 분포에서 샘플링됩니다.

570
00:56:00,020 --> 00:56:10,020
베타 T 물결표의 값은 1 빼기 알파바 T 빼기 1을 1 빼기 알파바 T 곱하기 베타 T 곱하기입니다.

571
00:56:15,020 --> 00:56:19,020
xt 쉼표 x0이 주어지면 xt에서 1을 뺀 q의 값을 계산하는 방법을 살펴보았습니다.

572
00:56:20,020 --> 00:56:22,020
하지만 이것을 사용하여 역방향 프로세스를 계산할 수 있습니까?

573
00:56:23,020 --> 00:56:27,020
대답은 실제로 '아니요'입니다. 추론 단계에서 x0이 무엇인지 모르기 때문입니다.

574
00:56:28,020 --> 00:56:34,020
샘플링하는 동안 정규 분포에서 시작하여 x0까지 가능한 한 노이즈를 제거하려고 합니다.

575
00:56:35,020 --> 00:56:37,020
그러나 우리는 처음부터 x0이 무엇인지 모릅니다.

576
00:56:38,020 --> 00:56:43,020
이 문제를 해결하기 위해 우리는 이 확률 분포를 근사화하는 방법을 학습하는 모델 p theta를 훈련합니다.

577
00:56:44,020 --> 00:56:54,020
x0에서 xt까지의 결합 분포 p theta는 xt의 p에 주어진 xt에서 1을 뺀 xt의 p theta를 곱한 것입니다.

578
00:56:55,020 --> 00:56:56,020
왜 이런가요?

579
00:56:57,020 --> 00:57:04,020
공식 모델이 마르코프 체인이라고 가정했기 때문에 역 프로세스도 마르코프 체인이어야 합니다.

580
00:57:05,020 --> 00:57:07,020
이것은 Markov 모델의 공식일 뿐입니다.

581
00:57:09,020 --> 00:57:14,020
여기에 있는 xt의 p는 n0i인 정규 분포라는 점에 유의하세요.

582
00:57:15,020 --> 00:57:16,020
그래서 우리는 이 값을 알고 있습니다.

583
00:57:17,020 --> 00:57:22,020
주어진 xt에서 xt - 1의 p 세타는 정규 분포로 가정됩니다.

584
00:57:22,020 --> 00:57:28,020
새로운 theta xt comma t를 평균으로 하고 sigma theta xt comma t를 분산으로 사용합니다.

585
00:57:29,020 --> 00:57:31,020
그런데 왜 이것을 가우스 분포라고 가정합니까?

586
00:57:32,020 --> 00:57:39,020
음, 순방향 프로세스가 단지 가우스 분포라고 가정했기 때문에 정규 분포에 따라 노이즈를 추가합니다.

587
00:57:40,020 --> 00:57:44,020
우리는 모델이 반대 프로세스에서도 동일한 프로세스를 학습하기를 원합니다.

588
00:57:47,020 --> 00:57:51,020
따라서 주어진 xt에서 1을 뺀 xt의 pθ를 학습하려면 모델이 필요합니다.

589
00:57:52,020 --> 00:57:53,020
가우스 분포입니다.

590
00:57:54,020 --> 00:57:58,020
즉, 분포의 평균과 분산을 학습하려면 모델이 필요합니다.

591
00:57:59,020 --> 00:58:03,020
우리는 새로운 세타가 새로운 물결표 t를 예측할 수 있도록 모델을 훈련시키고 싶습니다.

592
00:58:05,020 --> 00:58:07,020
그리고 우리는 몇 장의 슬라이드를 통해 새로운 물결표 t를 알게 되었습니다.

593
00:58:08,020 --> 00:58:09,020
이것은 새로운 물결표 t에 대한 방정식입니다.

594
00:58:10,020 --> 00:58:19,020
분산 시그마 세타 xt 콤마 t에 관해서는 시그마 제곱 ti라고 하겠습니다.

595
00:58:20,020 --> 00:58:22,020
그리고 여기 시그마 제곱 t는 학습되지 않습니다.

596
00:58:23,020 --> 00:58:25,020
베타 t 또는 베타 물결표 t로 설정됩니다.

597
00:58:27,020 --> 00:58:35,020
대각선 분산 시그마 세타 xt를 학습하기 때문에 저자에 따라 훈련이 불안정해지고 샘플 품질이 여전히 좋지 않습니다.

598
00:58:36,020 --> 00:58:38,020
이제 모형의 마지막 항을 살펴보겠습니다.

599
00:58:39,020 --> 00:58:42,020
모델에 마지막으로 사용하는 것은 변동 하한입니다.

600
00:58:45,020 --> 00:58:50,020
x naught가 주어지면 q xt의 확률, xt 쉼표 x naught가 주어지면 q xt 빼기 1입니다.

601
00:58:51,020 --> 00:58:57,020
이것들은 순방향 과정의 모든 확률과 xt의 p, xt가 주어지면 xt의 p theta 빼기 1입니다.

602
00:58:58,020 --> 00:59:03,020
이는 모델이 역과정을 통해 학습하는 확률입니다.

603
00:59:04,020 --> 00:59:06,020
우리는 이러한 확률이 가능한 한 서로 가까워지기를 원합니다.

604
00:59:07,020 --> 00:59:09,020
이를 위해 KL divergence를 사용합니다.

605
00:59:13,020 --> 00:59:15,020
우리는 가장 낮은 용어를 세 가지 용어로 분해합니다.

606
00:59:16,020 --> 00:59:19,020
L 대문자 T, L 소문자 t 및 L 없음.

607
00:59:20,020 --> 00:59:25,020
그리고 변동 하한은 이 세 항을 모두 합한 것입니다.

608
00:59:25,020 --> 00:59:42,020
좋습니다. L naught를 제외한 LVLB의 모든 KL 항은 두 개의 가우스 분포를 비교하고 닫힌 형식으로 계산할 수 있습니다.

609
00:59:43,020 --> 00:59:48,020
여기 L 대문자 T 항은 상수이며 훈련 중에 무시할 수 있습니다.

610
00:59:49,020 --> 00:59:56,020
그리고 L naught에 대해서는 이와 같은 정규 분포 모델을 사용하여 별도로 훈련할 수 있습니다.

611
00:59:57,020 --> 00:59:59,020
1과 동일한 타임 스탬프를 제공하십시오.

612
01:00:00,020 --> 01:00:02,020
이것은 학습할 수 없습니다. 이것은 학습 가능합니다.

613
01:00:07,020 --> 01:00:14,020
저자는 분산을 일정하게 유지하므로 분포의 평균만 예측하면 된다고 지적합니다.

614
01:00:14,020 --> 01:00:17,020
더 좋은 점은 노이즈 엡실론만 예측할 수 있다는 것입니다.

615
01:00:18,020 --> 01:00:22,020
이는 정규 분포의 샘플이며 재매개변수화 트랙을 통해 이미지에 추가되었습니다.

616
01:00:23,020 --> 01:00:26,020
저자는 소음 예측이 더 안정적이라는 것을 발견했습니다.

617
01:00:27,020 --> 01:00:34,020
추가된 노이즈만 예측하면 되므로 예측된 ​​노이즈와 이미지에 추가된 실제 노이즈 사이의 MSI 손실을 사용할 수 있습니다.

618
01:00:35,020 --> 01:00:41,020
여기 보시는 것은 LVLB의 두 번째 용어를 단순화한 용어입니다.

619
01:00:42,020 --> 01:00:45,020
이는 MSI 손실과 정확히 유사합니다.

620
01:00:49,020 --> 01:00:57,020
따라서 LVLB를 단순화하면 L 대문자 T, L 소형, L 없음 및 L 소형 t 단순을 얻습니다.

621
01:00:58,020 --> 01:01:00,020
이 항은 일정합니다. 그들은 세타에 의존하지 않습니다.

622
01:01:01,020 --> 01:01:05,020
L t 단순만이 세타에 의존하며 이는 단지 평균 제곱 오류일 뿐입니다.

623
01:01:06,020 --> 01:01:17,020
이제 모델 뒤에 숨은 직관은 무엇이며 변동 하한을 최소화하려는 손실 항을 선택한 이유는 무엇입니까?

624
01:01:18,020 --> 01:01:23,020
손실 항은 모델이 더 높은 t 값을 학습하는 쪽으로 더 편향되는 방식으로 생성됩니다.

625
01:01:24,020 --> 01:01:30,020
기억하신다면 시간이 지남에 따라 선형적으로 증가하도록 베타 t를 선택합니다.

626
01:01:31,020 --> 01:01:37,020
그리고 자본 T에 도달할 때 베타 t의 값은 0.02가 됩니다.

627
01:01:38,020 --> 01:01:48,020
따라서 순방향 확산의 마지막 단계에 추가되는 노이즈의 양은 시작 단계에서 추가되는 노이즈의 양보다 기하급수적으로 높습니다.

628
01:01:49,020 --> 01:01:59,020
이러한 방식으로 분산 스케줄러를 선택하기 때문에 모델은 더 높은 t 값을 학습하는 쪽으로 더 편향되어야 합니다.

629
01:02:01,020 --> 01:02:11,020
따라서 역방향 프로세스 동안 우리 모델은 역방향 프로세스의 시작 시간 단계에 대해 더 많은 양의 노이즈를 예측해야 합니다.

630
01:02:12,020 --> 01:02:18,020
그리고 역과정이 끝날 무렵에는 이미지의 더 세밀한 세부 사항을 학습할 수 있어야 합니다.

631
01:02:19,020 --> 01:02:24,020
물체에 어떤 형태의 질감을 갖도록 만드는 것보다 물체의 주요 모양을 올바르게 만드는 것이 더 중요합니다.

632
01:02:25,020 --> 01:02:27,020
모델은 어떻게 생겼나요?

633
01:02:27,020 --> 01:02:36,020
저자는 단위 모델을 사용했으며 이것이 역과정의 노이즈를 예측하는 효율적인 방법이라고 말했습니다.

634
01:02:37,020 --> 01:02:46,020
시간 단계 t가 주어지면 노이즈 이미지를 입력으로 취하고 이 이미지에서 공제해야 하는 노이즈를 출력합니다.

635
01:02:47,020 --> 01:02:56,020
변환기에서와 마찬가지로 시간 단계 정보도 모델의 각 단계, 모델의 각 레이어에서 제공되어 더욱 정확해집니다.

636
01:02:57,020 --> 01:03:00,020
이는 모델이 확산 과정에서 어디에 있는지 알 수 있도록 도와줍니다.

637
01:03:01,020 --> 01:03:09,020
역과정의 시작이라면 더 많은 노이즈를 예측해야 하고, 마지막이라면 더 세밀한 노이즈를 예측해야 합니다.

638
01:03:10,020 --> 01:03:17,020
지금까지 우리는 잡음 제거의 순방향 확산 과정, 역방향 과정을 살펴보았습니다.

639
01:03:18,020 --> 01:03:24,020
우리는 확산 모델을 훈련하기 위해 어떤 모델을 사용해야 하는지, 손실 함수는 무엇인지 살펴보았습니다.

640
01:03:25,020 --> 01:03:29,020
이제 확산 모델의 더 광범위한 훈련 알고리즘을 살펴보겠습니다.

641
01:03:30,020 --> 01:03:34,020
x0의 Q에 속하는 샘플 x0이 있습니다.

642
01:03:35,020 --> 01:03:39,020
1부터 t까지 균일한 타임스탬프가 있습니다.

643
01:03:40,020 --> 01:03:46,020
우리는 0과 분산 동일성을 의미하는 정규 분포인 노이즈를 샘플링합니다.

644
01:03:48,020 --> 01:03:51,020
그리고 잡음에 대해 경사하강법을 수행합니다.

645
01:03:52,020 --> 01:04:03,020
우리 모델은 엡실론과 세타를 학습하고 MSC 손실 함수를 사용하여 기울기를 예측하며 이 노이즈가 수렴될 때까지 계속 해석합니다.

646
01:04:05,020 --> 01:04:11,020
샘플링 과정은 정규분포에서 최종 타임스냅 x 자본 T를 샘플링합니다.

647
01:04:14,020 --> 01:04:21,020
그리고 역과정의 모든 타임스탬프에 대해 먼저 정규 분포에서 az를 생성합니다.

648
01:04:22,020 --> 01:04:28,020
그런 다음 재매개변수화 트릭을 사용하여 주어진 xt에서 xt - 1을 샘플링합니다.

649
01:04:29,020 --> 01:04:31,020
이것은 우리 모델에서 예측된 소음입니다.

650
01:04:31,020 --> 01:04:35,020
알파 t 값은 알려져 있고, 시그마 t 값도 알려져 있습니다.

651
01:04:36,020 --> 01:04:41,020
이는 시그마 세타 항, 자본 시그마 세타 항의 값입니다.

652
01:04:42,020 --> 01:04:47,020
우리는 xt가 무엇인지 알고 있으며 여기에 샘플 z가 있습니다.

653
01:04:48,020 --> 01:04:50,020
따라서 우리는 이 방정식 4의 모든 것을 알고 있습니다.

654
01:04:51,020 --> 01:04:59,020
그리고 x0을 샘플링하는 1번째 시간까지 갈 때까지 x0을 샘플링하면 이를 반환합니다.

655
01:05:02,020 --> 01:05:05,020
확산의 역과정은 다음과 같습니다.

656
01:05:06,020 --> 01:05:14,020
정규 분포에서 샘플링하고 이미지를 얻을 때까지 t 타임스탬프 동안 계속해서 노이즈를 제거합니다.

657
01:05:18,020 --> 01:05:21,020
DDPM 알고리즘에는 몇 가지 제한 사항이 있습니다.

658
01:05:22,020 --> 01:05:30,020
첫 번째이자 가장 중요한 제한은 분산 스케줄러 베타 t의 초기화가 선형적으로 계속 증가한다는 것입니다.

659
01:05:31,020 --> 01:05:33,020
그러나 그것은 바람직하지 않습니다.

660
01:05:34,020 --> 01:05:42,020
코사인과 같은 더 복잡한 분포를 사용하여 베타 t의 값을 초기화할 수 있습니다.

661
01:05:44,020 --> 01:05:47,020
이는 우리에게 또 다른 한계를 안겨줍니다.

662
01:05:48,020 --> 01:05:56,020
우리가 학습한 모델은 평균값만 예측하고 분포의 분산은 예측하지 않습니다.

663
01:05:56,020 --> 01:06:03,020
분산은 일반적으로 베타 t의 조합에 따라 일정하게 유지됩니다.

664
01:06:04,020 --> 01:06:08,020
저자는 이것이 모델의 안정성을 향상시킨다고 말합니다.

665
01:06:09,020 --> 01:06:17,020
그러나 평균과 분산의 값을 모두 예측하는 방법을 배울 수 있다면 더 바람직합니다.

666
01:06:18,020 --> 01:06:21,020
그리고 DDPM 알고리즘의 마지막이자 가장 중요한 한계입니다.

667
01:06:21,020 --> 01:06:25,020
순방향 확산 프로세스에는 1000개의 타임스탬프가 있습니다.

668
01:06:26,020 --> 01:06:27,020
대문자 t는 일반적으로 1000을 유지합니다.

669
01:06:28,020 --> 01:06:32,020
그리고 역과정의 각 타임스탬프에 대해 모델은 노이즈를 예측하는 방법을 학습합니다.

670
01:06:33,020 --> 01:06:38,020
이는 매우 시간 효율적이고 계산량이 많아 전혀 바람직하지 않습니다.

671
01:06:39,020 --> 01:06:44,020
따라서 이는 확산 암시적 모델을 제거하는 또 다른 알고리즘으로 이어집니다.

672
01:06:45,020 --> 01:06:51,020
DDPM 알고리즘의 주요 가정은 모델이 Markov 체인 모델로 가정된다는 것입니다.

673
01:06:52,020 --> 01:06:56,020
현재 타임스탬프는 이전 타임스탬프에만 의존합니다.

674
01:06:57,020 --> 01:07:00,020
노이즈 제거 확산 암시적 모델 또는 DDIM.

675
01:07:01,020 --> 01:07:06,020
이 모델은 비마코비안 모델로 가정될 수 있다고 말합니다.

676
01:07:08,020 --> 01:07:12,020
이를 통해 잡음 제거 프로세스 중에 타임스탬프를 건너뛸 수 있습니다.

677
01:07:12,020 --> 01:07:16,020
DDPM에서는 전달 프로세스 중에 타임스탬프를 건너뛸 수 있는 방법을 살펴보았습니다.

678
01:07:17,020 --> 01:07:20,020
x0에서 x3의 값을 직접 계산할 수 있습니다.

679
01:07:21,020 --> 01:07:27,020
그러나 역방향 프로세스의 경우 DDPM에서는 x3에서 x2, x1에서 x0으로 이동하는 것이 필수입니다.

680
01:07:28,020 --> 01:07:34,020
그러나 DDIM 논문의 경우 x3에서 x1로 직접 이동할 수 있습니다.

681
01:07:35,020 --> 01:07:36,020
x0 값을 건너뛸 수 있습니다.

682
01:07:36,020 --> 01:07:41,020
그렇다면 DDIM 논문의 새로운 내용은 무엇입니까?

683
01:07:42,020 --> 01:07:45,020
첫째, 그들은 역확산 과정을 재정의합니다.

684
01:07:46,020 --> 01:07:51,020
이는 단일 단계의 역확산 공정에 대해 제공되는 공식입니다.

685
01:07:52,020 --> 01:07:56,020
재구성은 DDPM 논문의 공식화와 동일합니다.

686
01:07:57,020 --> 01:08:00,020
그러나 분산이 베타 t 물결표와 같은 경우에만 해당됩니다.

687
01:08:01,020 --> 01:08:09,020
저자는 여기 시그마의 공식이 단지 베타 물결표 t라고 명시적으로 언급하지 않습니다.

688
01:08:10,020 --> 01:08:13,020
하지만 그녀의 작은 대수학을 통해 우리는 그것이 사실이라는 것을 알 수 있습니다.

689
01:08:19,020 --> 01:08:22,020
시그마 값을 0으로 설정하면 어떻게 될까요?

690
01:08:23,020 --> 01:08:29,020
시그마를 0으로 설정하면 잡음 제거 프로세스가 완전히 결정적이 됩니다.

691
01:08:30,020 --> 01:08:37,020
잡음 제거 과정에서 새로운 잡음이 추가되지 않기 때문에 유일한 잡음은 x0의 원래 잡음입니다.

692
01:08:38,020 --> 01:08:41,020
데이터에는 노이즈가 없습니다.

693
01:08:42,020 --> 01:08:43,020
바로 이 소음입니다.

694
01:08:44,020 --> 01:08:46,020
이것이 DDIM 논문의 비결이다.

695
01:08:47,020 --> 01:08:50,020
프로세스는 완전히 결정론적이며 더 이상 Markov 체인이 없습니다.

696
01:08:51,020 --> 01:08:55,020
Markov 체인은 확률적 프로세스를 위한 것이므로 이는 비마코프 프로세스입니다.

697
01:08:56,020 --> 01:09:03,020
표시된 다이어그램에서는 x2를 건너뛰고 x3에서 x1로 직접 이동할 수 있습니다.

698
01:09:04,020 --> 01:09:11,020
저자는 원래 확산 하위 시퀀스의 하위 집합인 하위 시퀀스 tau로 새로운 확산 과정을 모델링합니다.

699
01:09:12,020 --> 01:09:19,020
예를 들어, 타우의 하위 시퀀스를 얻기 위해 확산 과정의 다른 모든 확산 단계를 샘플링할 수 있습니다.

700
01:09:20,020 --> 01:09:23,020
x2를 건너뛸 수 있고, x4, x6을 건너뛸 수 있습니다.

701
01:09:28,020 --> 01:09:32,020
또한 두 알고리즘인 DDIM과 DDPM 사이를 보간할 수도 있습니다.

702
01:09:33,020 --> 01:09:37,020
0과 1 사이에 있는 새로운 변수 eta를 도입할 수 있습니다.

703
01:09:38,020 --> 01:09:42,020
eta 값을 0으로 유지하면 DDIM이 됩니다.

704
01:09:43,020 --> 01:09:48,020
그리고 eta 값을 1로 유지하면 프로세스는 DDAPM이 됩니다.

705
01:09:49,020 --> 01:09:55,020
그리고 0과 1 사이의 에타는 DDIM과 DDPM 알고리즘 간의 보간일 뿐입니다.

706
01:09:56,020 --> 01:10:00,020
아래 차트는 DDPM과 DDIM을 보여줍니다.

707
01:10:01,020 --> 01:10:05,020
이는 다양성과 이미지 품질에 점수를 매기는 FID 점수, 충실도 점수입니다.

708
01:10:06,020 --> 01:10:10,020
그리고 이는 에타와 0에서 1까지의 보간을 기반으로 합니다.

709
01:10:11,020 --> 01:10:16,020
그리고 10에서 1000까지의 S 타임스탬프에서는

710
01:10:16,020 --> 01:10:23,020
DDPM 알고리즘은 원래 1000개의 타임스탬프에서 최상의 성능을 발휘합니다.

711
01:10:24,020 --> 01:10:29,020
DDIM은 훨씬 적은 생성 단계로 이미지를 생성할 때 밀접하게 따릅니다.

712
01:10:30,020 --> 01:10:35,020
DDIM을 사용할 때 이미지 품질과 생성 시간 사이에는 근본적으로 균형이 있습니다.

713
01:10:36,020 --> 01:10:38,020
원래 DDPM은 제공하지 않았습니다.

714
01:10:39,020 --> 01:10:43,020
이제 우리는 더 적은 단계로 고품질의 이미지를 생성할 수 있습니다.

715
01:10:46,020 --> 01:10:51,020
자, 이것이 DDIM과 DDPM의 역과정의 예입니다.

716
01:10:52,020 --> 01:10:57,020
10개의 타임스탬프 후에 볼 수 있듯이 DDIM은 이미 좋은 이미지를 생성했습니다.

717
01:11:00,020 --> 01:11:06,020
이것이 DDPM 알고리즘인 반면, 여전히 잡음을 예측하고 있습니다.

718
01:11:07,020 --> 01:11:09,020
그리고 1000개의 타임스탬프까지 계속됩니다.

719
01:11:10,020 --> 01:11:14,020
100개의 타임스탬프 이후에는 DDIM이 이미 출력을 제공했음을 알 수 있습니다.

720
01:11:14,020 --> 01:11:16,020
이것은 시간 효율적입니다.

721
01:11:18,020 --> 01:11:24,020
1000개의 타임스탬프 이후 DDPM은 더 나은 품질의 유사한 이미지를 생성할 수 있습니다.

722
01:11:28,020 --> 01:11:33,020
그래서 DDPM과 DDIM을 살펴본 후 이 방법이 어떻게 작동하는지 살펴보았습니다.

723
01:11:33,020 --> 01:11:36,020
지금까지 이미지 생성 및 그 이상의 작업에서 좋은 결과를 얻었습니다.

724
01:11:37,020 --> 01:11:42,020
그러나 이 모델에서 지속되는 한 가지 과제는 계산 강도입니다.

725
01:11:42,020 --> 01:11:47,020
샘플링에 필요한 시간으로 인해 실제 적용이 제한될 수 있습니다.

726
01:11:48,020 --> 01:11:52,020
이제 이 과제를 다루는 다른 논문으로 관심을 돌려보겠습니다.

727
01:11:54,020 --> 01:12:01,020
DDPM 솔버는 확산 모델의 샘플링 프로세스를 크게 가속화하는 새로운 접근 방식입니다.

728
01:12:02,020 --> 01:12:08,020
확산 과정을 최적화함으로써 이전 제품의 고품질 출력을 유지할 뿐만 아니라

729
01:12:08,020 --> 01:12:11,020
뿐만 아니라 생성 프로세스를 훨씬 더 효율적으로 만듭니다.

730
01:12:13,020 --> 01:12:19,020
DPM 솔버가 무엇인지 설명하기 전에 확산 모델을 SD 프레임워크로 요약해 보겠습니다.

731
01:12:22,020 --> 01:12:29,020
순방향 SD에서 순방향 SD는 시간이 지남에 따라 원본 데이터에 노이즈를 추가하는 프로세스를 나타냅니다.

732
01:12:30,020 --> 01:12:36,020
이 방정식에서 DXD는 시간 t에서 데이터 XD의 증분 변화를 나타냅니다.

733
01:12:36,020 --> 01:12:42,020
그리고 FT는 노이즈가 추가되는 방향과 속도를 결정하는 드리프트 계수입니다.

734
01:12:43,020 --> 01:12:47,020
t DWT의 G라는 용어는 프로세스에 확률성을 도입합니다.

735
01:12:48,020 --> 01:12:54,020
여기서, t의 G는 확산계수이고, DWT는 비닐공정을 나타내며,

736
01:12:54,020 --> 01:12:58,020
이는 본질적으로 무작위 동작에 대한 수학적 모델입니다.

737
01:12:59,020 --> 01:13:07,020
이 방정식은 데이터를 시간 T에서 t T의 잡음 밀도 X로 점진적으로 변환합니다.

738
01:13:08,020 --> 01:13:13,020
역방향 프로세스의 경우 역SD는 순방향 프로세스의 역방향이며,

739
01:13:13,020 --> 01:13:16,020
노이즈로부터 원본 데이터를 복구하는 것을 목표로 합니다.

740
01:13:17,020 --> 01:13:24,020
여기서 DXD는 확산을 역전시키려고 시도할 때 시간 t에서 노이즈 데이터 XT의 변화를 나타냅니다.

741
01:13:25,020 --> 01:13:38,020
t XT의 항 F와 G 제곱 t 나누기 시그마 t 엡실론 세타 XT t는 잡음이 있는 데이터에서 빼려고 하는 예상 잡음을 반영합니다.

742
01:13:39,020 --> 01:13:44,020
여기서 t의 엡실론 세타 XT는 세타로 매개변수화된 신경망의 출력입니다.

743
01:13:45,020 --> 01:13:48,020
각 단계에서 추가되는 노이즈를 예측하도록 훈련되었습니다.

744
01:13:49,020 --> 01:13:52,020
네트워크는 예측을 사용하여 반복적으로 데이터의 잡음을 제거합니다.

745
01:13:54,020 --> 01:14:02,020
임의의 점 XT에서 대문자 XT로의 전환은 선형으로 가정되며 가우스 분포를 따릅니다.

746
01:14:03,020 --> 01:14:07,020
DDPM에서 논의한 것처럼 표기법 q naught t XT 주어진 X naught 는 다음과 같습니다.

747
01:14:08,020 --> 01:14:13,020
이는 원래 데이터 X naught에서 잡음이 있는 데이터 XT에 도달할 확률 밀도를 나타냅니다.

748
01:14:13,020 --> 01:14:20,020
이는 평균이 알파 t이고 편차가 시그마 제곱 t i인 가우스 분포가 특징입니다.

749
01:14:20,020 --> 01:14:22,020
죄송합니다. 평균은 alpha t X naught입니다.

750
01:14:25,020 --> 01:14:31,020
이 전이 분포는 중간 단계 t에서 잡음을 정량화하기 때문에 중요합니다.

751
01:14:31,020 --> 01:14:34,020
역확산 경로를 정확하게 모델링할 수 있습니다.

752
01:14:36,020 --> 01:14:38,020
잡음을 예측하는 모델을 훈련시키기 위해,

753
01:14:40,020 --> 01:14:47,020
우리는 실제 잡음과 신경망에서 예측한 잡음 사이의 예상되는 차이를 최소화하는 것을 목표로 하는 손실 함수를 사용합니다.

754
01:14:48,020 --> 01:14:52,020
이것은 여기 적분식에 담겨 있습니다.

755
01:14:55,020 --> 01:15:01,020
여기서 오메가 t라는 용어는 가중치 함수이고 적분은 0에서 t까지입니다.

756
01:15:01,020 --> 01:15:10,020
적분 eq naught X naught 내부의 기대값에 q 엡실론의 기대값을 곱한 값

757
01:15:10,020 --> 01:15:15,020
원본 데이터 X naught 및 노이즈 엡실론의 분포를 인수합니다.

758
01:15:16,020 --> 01:15:21,020
이 항은 본질적으로 예측된 ​​잡음과 순방향 프로세스 중에 추가된 실제 잡음 사이의 평균 제곱 오차입니다.

759
01:15:25,020 --> 01:15:31,020
DDPM의 샘플링은 이 SDE를 이산화하는 것과 유사합니다.

760
01:15:31,020 --> 01:15:36,020
이는 작은 유한 단계를 수행하여 연속 시간 프로세스를 근사화한다는 의미입니다.

761
01:15:37,020 --> 01:15:39,020
따라서 1차 이산화라는 용어가 사용됩니다.

762
01:15:40,020 --> 01:15:44,020
이를 통해 컴퓨터에서 역과정을 단계별로 시뮬레이션할 수 있습니다.

763
01:15:45,020 --> 01:15:48,020
이제 이것을 확산 ODE와 대조해 보세요.

764
01:15:49,020 --> 01:15:52,020
이것이 DDIM 알고리즘의 핵심입니다.

765
01:15:53,020 --> 01:16:00,020
여기에 제공된 방정식은 유사한 구조를 보여 주지만 확률론적 항 GTE DWT가 없음을 알 수 있습니다.

766
01:16:02,020 --> 01:16:08,020
이는 DDIM이 DDPM 고유의 무작위성 없이 결정론적으로 작동함을 의미합니다.

767
01:16:09,020 --> 01:16:14,020
각 단계의 분포에서 샘플링하는 대신 DDIM은 다음 단계를 결정론적으로 계산합니다.

768
01:16:15,020 --> 01:16:19,020
훨씬 더 예측 가능하고 효율적입니다.

769
01:16:20,020 --> 01:16:27,020
이 두 알고리즘인 DDPM과 DDIM은 이러한 방정식으로 정의된 공간을 탐색하기 위한 서로 다른 전략으로 볼 수 있습니다.

770
01:16:28,020 --> 01:16:32,020
확산 과정을 효과적으로 제거하거나 반전시키는 방법을 배우는 것이 최종 목표입니다.

771
01:16:33,020 --> 01:16:38,020
간단히 말해서 확산 확률 모델 또는 DPM의 가장 중요한 문제 중 하나는

772
01:16:39,020 --> 01:16:40,020
느린 샘플링 속도입니다.

773
01:16:41,020 --> 01:16:48,020
일반적으로 고품질 샘플을 생성하려면 이 모델은 소음에서 격리까지 수렴하는 데 최소 100개의 순차적 단계가 필요합니다.

774
01:16:49,020 --> 01:16:55,020
이러한 느린 프로세스는 DPM을 실제로 적용할 때 병목 현상이 될 수 있습니다.

775
01:16:56,020 --> 01:17:00,020
실시간 생성이나 대화형 시스템으로의 통합 등이 있습니다.

776
01:17:01,020 --> 01:17:08,020
이러한 방법의 샘플링에는 확산 SDE 또는 ODE의 이산화가 포함됩니다.

777
01:17:09,020 --> 01:17:13,020
이는 SDE 또는 ODE 솔버를 사용해야 합니다.

778
01:17:14,020 --> 01:17:20,020
일반적으로 ODE 솔버는 결정론적 특성으로 인해 SDE 솔버보다 빠르게 수렴하는 경향이 있지만,

779
01:17:21,020 --> 01:17:24,020
수렴하려면 여전히 약 100개의 순차적 단계가 필요합니다.

780
01:17:26,020 --> 01:17:33,020
확산 모델, 느린 샘플링 속도에 대한 이해를 바탕으로 이제 DPM 솔버인 중추적인 솔루션에 도달했습니다.

781
01:17:34,020 --> 01:17:42,020
이 혁신적인 접근 방식은 생성된 이미지의 품질을 저하시키지 않으면서 샘플링 프로세스를 크게 가속화하는 획기적인 방법입니다.

782
01:17:43,020 --> 01:17:50,020
이미지를 관찰해보면, 초기 DDIM 이미지에서 현저하게 동일한 단계수로,

783
01:17:51,020 --> 01:17:54,020
DPM 솔버는 이미 명확하고 상세한 이미지를 제공합니다.

784
01:17:55,020 --> 01:18:03,020
10단계 또는 10회 함수 평가에서 출력은 DDIM이 100단계에서 달성한 것과 유사합니다.

785
01:18:04,020 --> 01:18:08,020
DPM 솔버의 효율성과 효과를 보여줍니다.

786
01:18:09,020 --> 01:18:19,020
생성 모델에 대한 확산 ODE를 풀기 위해 Ranga-Kutta와 같은 전통적인 방법이 일반적으로 사용됩니다.

787
01:18:20,020 --> 01:18:28,020
그러나 이 방법은 블랙박스로 프로세스를 직선화합니다. 이는 확산 방정식의 특정 구조를 활용하지 않음을 의미합니다.

788
01:18:29,020 --> 01:18:34,020
이러한 무지는 정확한 솔루션 XT로서 비효율성을 초래하는 경우가 많습니다.

789
01:18:34,020 --> 01:18:39,020
주어진 시간 동안 드리프트와 확산 계수를 모두 포함하는 적분에 따라 달라집니다.

790
01:18:41,020 --> 01:18:48,020
기존 RK45 방법에는 한계가 있으며 일반적으로 20단계 미만으로 수렴할 수 없습니다.

791
01:18:49,020 --> 01:18:56,020
이는 고품질 이미지 생성을 유지하는 동시에 프로세스를 가속화하기를 원하기 때문에 확산 모델의 빠른 샘플링에는 문제가 됩니다.

792
01:18:57,020 --> 01:19:12,020
이 슬라이드의 주요 내용은 확산 ODE 특성을 통해 효율적으로 작동하여 더 적은 단계로 신속한 수렴을 가능하게 하는 솔버가 필요하다는 것입니다.

793
01:19:14,020 --> 01:19:18,020
DPM 솔버 논문의 저자는 두 가지 주요 관찰을 했습니다.

794
01:19:19,020 --> 01:19:27,020
첫째, 그들은 확산 ODE가 계산을 간소화하는 데 중추적인 반선형 구조를 가지고 있음을 인식했습니다.

795
01:19:28,020 --> 01:19:41,020
드리프트 계수인 ODE의 선형 부분은 시스템의 예측 가능한 동작을 제어하는 ​​반면, 확산 항은 신경망 잡음 예측을 통해 복잡성을 추가합니다.

796
01:19:42,020 --> 01:19:46,020
그들은 ODE를 풀기 위해 다양한 상수 공식을 사용합니다.

797
01:19:47,020 --> 01:19:58,020
이 접근 방식을 사용하면 선형 부분을 정확하게 계산할 수 있으며, 이는 지수 항에 XS를 곱하여 표현됩니다.

798
01:19:59,020 --> 01:20:06,020
이는 본질적으로 시간에 따른 F 적분의 지수함수로 초기 값 XS를 스케일링하는 것을 의미합니다.

799
01:20:07,020 --> 01:20:13,020
솔루션의 나머지 부분은 비선형 잡음 항을 포함하여 동일한 기간에 걸쳐 이를 통합합니다.

800
01:20:15,020 --> 01:20:25,020
선형 부분과 비선형 부분을 분리함으로써 우리는 언제든지 t에서 XT에 대한 정확한 해를 계산할 수 있는 명확한 경로를 얻습니다.

801
01:20:26,020 --> 01:20:37,020
이러한 정밀도를 통해 rangekutta와 같은 블랙박스 수치 방법의 한계를 피할 수 있어 더 적은 단계로 더 빠르게 수렴할 수 있습니다.

802
01:20:39,020 --> 01:20:47,020
저자가 만든 두 번째 관찰은 SNR 법칙을 사용하여 확산 ODE의 해를 단순화하는 것입니다.

803
01:20:48,020 --> 01:20:58,020
이 기술은 잡음 전이 확률을 정규 분포(평균은 알파 t로 조정되고 분산은 시그마 t 제곱)로 이해하는 방식으로 전환됩니다.

804
01:20:59,020 --> 01:21:11,020
알파 t 제곱을 시그마 t 제곱으로 나눈 비율의 로그로 정의된 로그 SNR은 확산 과정의 복잡한 역학을 보다 다루기 쉬운 형태로 추출하는 데 도움이 됩니다.

805
01:21:12,020 --> 01:21:25,020
람다 t를 로그 SNR의 절반으로 정의함으로써 람다 t의 도함수로 직접 드리프트 및 확산 계수를 우아하게 표현할 수 있습니다.

806
01:21:26,020 --> 01:21:39,020
이는 선형 항의 보다 효율적인 계산으로 이어지며 비선형 항의 적분을 지수 가중 적분으로 변환하여 계산상 처리하기가 더 쉽습니다.

807
01:21:42,020 --> 01:21:54,020
정확한 해 XT는 선형 부분 XT가 정확하게 계산되고 비선형 부분이 지수 가중 적분을 통해 관리되는 이러한 새로운 항으로 표현될 수 있습니다.

808
01:21:55,020 --> 01:22:04,020
이 조작은 계산을 크게 자극하고 확산 ODE 솔루션을 빠르고 정확하게 평가할 수 있게 해줍니다.

809
01:22:05,020 --> 01:22:18,020
이는 마지막 슬라이드에 제시된 것과 동일한 방정식입니다. 첫 번째 항은 정확하게 계산될 수 있습니다. 우리가 해야 할 일은 대략 가중 적분인 두 번째 항을 근사화하는 것뿐입니다.

810
01:22:20,020 --> 01:22:31,020
이전 시점에서 대략적인 해를 가지고 있다고 가정하면, 예측된 잡음을 포함하는 비선형 항에 대해 Taylor-Cillis 전개를 사용하여 현재 시간의 정확한 해를 찾을 수 있습니다.

811
01:22:32,020 --> 01:22:50,020
이것이 의미하는 바는 잡음 예측 항을 계열로 확장해야 한다는 것입니다. 여기서 계열의 각 구성 요소는 이전 단계에서 잡음 예측의 도함수를 사용하여 계산되며 로그 SNR 항의 차이를 다음의 거듭제곱으로 확장합니다. n을 n 계승으로 나눕니다.

812
01:22:51,020 --> 01:22:57,020
그런 다음 이 확장을 통합하여 이전 시간 단계의 솔루션을 현재 단계로 업데이트합니다.

813
01:22:58,020 --> 01:23:04,020
여기 왼쪽은 이전 시간에서 현재 시간으로의 솔루션 전환을 나타냅니다.

814
01:23:05,020 --> 01:23:15,020
알파 t 및 알파 ti 마이너스 1이라는 용어는 이 시점의 노이즈 분산과 관련된 배율 인수이며, 이는 솔루션의 크기를 조정합니다.

815
01:23:16,020 --> 01:23:23,020
이 Taylor 시리즈는 더 많은 용어로 점점 더 정확해지는 근사치를 제공합니다.

816
01:23:24,020 --> 01:23:37,020
그러나 DPM 솔버 알고리즘은 솔루션을 빠르고 높은 정밀도로 계산할 수 있는 중요한 균형을 유지하며 고차 항을 무시할 수 있습니다.

817
01:23:38,020 --> 01:23:45,020
따라서 DPM 솔버 알고리즘은 오류를 최대한 최소화하기 위해 확산 ODE용으로 특별히 제작되었습니다.

818
01:23:46,020 --> 01:23:55,020
이는 부분, 선형 항, 도함수, 계수 및 고차 항으로 분류된 확산 방정식의 구조를 활용하여 수행됩니다.

819
01:23:56,020 --> 01:24:02,020
선형 항은 정확하게 계산됩니다. 즉, 근사 없이 계산하기 위해 정확한 방법을 적용합니다.

820
01:24:03,020 --> 01:24:11,020
반면 도함수는 정확하게 계산하는 것이 계산 집약적일 수 있기 때문에 수치적 방법을 사용하여 근사화됩니다.

821
01:24:13,020 --> 01:24:23,020
여기에 있는 계수는 부분적분을 사용하여 분석적으로 계산할 수 있으며 더 높은 차수의 항은 생략됩니다.

822
01:24:23,020 --> 01:24:33,020
계열에 더 많은 항을 추가하고 계산 효율성을 향상시키기 위해 안전하게 생략할 수 있으므로 무시할 수 있습니다.

823
01:24:35,020 --> 01:24:39,020
앞서 언급했듯이 DDIM은 1차 DPM 솔버입니다.

824
01:24:40,020 --> 01:24:54,020
내가 왜 그런 말을 했나요? DPM 솔버 방정식에 대해 k를 2로 설정하면 DDIM 알고리즘이 사용한 정확한 솔루션을 얻었음을 알 수 있습니다.

825
01:24:55,020 --> 01:25:07,020
따라서 DDIM은 알려진 용어로 분석적으로 계산하는 1차 확산 ODE 솔버이며 이것이 바로 DDIM이 잘 작동하는 이유를 아는 이유입니다.

826
01:25:08,020 --> 01:25:15,020
좋아요, 이제 DPM 솔버가 Runge-Gutta 방법과 비교하여 작동하는 방식을 비교해 보겠습니다.

827
01:25:17,020 --> 01:25:36,020
12개의 함수 평가에 대해서도 DPM 솔버가 다른 두 가지보다 훨씬 우수하며 위의 두 가지 방법도 DPM 솔버를 개선하지만 함수 평가 수가 증가함에 따라 여전히 두 가지보다 더 우수하다는 것을 알 수 있습니다.

828
01:25:38,020 --> 01:25:48,020
이 그래프의 원은 DPM이 거의 15~20단계로 수렴된다는 것을 보여줍니다.

829
01:25:53,020 --> 01:25:59,020
그래서 지금까지 DDPM, DDIM, DPM 솔버라는 세 가지 샘플링 알고리즘에 대해 살펴보았습니다.

830
01:26:00,020 --> 01:26:18,020
DDPM은 1000에 해당하는 각 시간 단계에서 잡음 예측이 필요했습니다. 수렴하는 데 약 200단계가 필요한 반면, DDIM 알고리즘에서는 일부 시간 단계를 건너뛸 수 있었습니다.

831
01:26:19,020 --> 01:26:22,020
수렴하려면 여전히 약 100개의 시간 단계가 필요합니다.

832
01:26:25,020 --> 01:26:31,020
반면에 우리는 DPM 솔버를 보았으며 수렴하는 데 약 20개의 시간 단계만 소요되었습니다.

833
01:26:33,020 --> 01:26:43,020
하지만 모델에서 단 한 번의 정방향 패스만으로 이미지를 생성할 수 있는 방법이 있을까요?

834
01:26:44,020 --> 01:26:46,020
일관성 모델이 작동하는 곳이 바로 여기입니다.

835
01:26:47,020 --> 01:26:50,020
한 번에 이미지를 생성할 수 있습니다.

836
01:26:51,020 --> 01:26:59,020
노이즈 이미지가 주어지면 역 프로세스의 노이즈를 한 번만 전달하면 X0을 생성할 수 있습니다.

837
01:27:01,020 --> 01:27:03,020
이제 일관성 모델에 대해 이야기해 보겠습니다.

838
01:27:04,020 --> 01:27:15,020
일관성 모델은 OpenEI에서 제안되었으며 최근 단일 단계로 이미지를 생성하는 패러다임입니다.

839
01:27:17,020 --> 01:27:30,020
이를 담당하는 연구원들은 확산 모델에서 영감을 얻었으며 그들의 주요 목표는 확산 모델에서 일반적으로 사용되는 반복적 노이즈 감소가 아닌 단일 샷으로 이미지를 생성하는 것입니다.

840
01:27:31,020 --> 01:27:43,020
일관성 모델은 확산 프로세스의 모든 단계에서 노이즈가 있는 이미지를 초기 노이즈 없는 변환으로 매핑하는 새로운 학습 방법을 도입합니다.

841
01:27:44,020 --> 01:27:52,020
방법론은 일반화 가능하며 저자는 모델이 재교육 없이 이미지 편집 유형의 작업을 수행할 수 있다고 주장합니다.

842
01:27:53,020 --> 01:28:03,020
느리고 빠른 샘플링이라는 확산 모델의 한계를 해결하기 위해 일관성 모델이 사용됩니다.

843
01:28:04,020 --> 01:28:18,020
그들의 독특한 제안은 노이즈를 데이터에 직접 매핑하여 고품질 샘플을 생성하고, 반복 샘플링의 품질 균형과 제로 샷 데이터 편집 기능을 유지하면서 빠른 한 단계 생성을 가능하게 하는 것입니다.

844
01:28:19,020 --> 01:28:34,020
일관성 모델의 핵심 개념은 확률 흐름 ODE(간단히 PFODE)에 의해 결정된 데이터 궤적의 모든 지점을 단일 네트워크 평가에서 원점으로 다시 매핑하는 능력에 있습니다.

845
01:28:35,020 --> 01:28:44,020
이 접근 방식은 다른 확산 샘플링 알고리즘의 다단계 생성에 비해 생성 프로세스를 크게 가속화합니다.

846
01:28:45,020 --> 01:28:49,020
배경을 살펴보고 DDPM 알고리즘을 다시 살펴보겠습니다.

847
01:28:50,020 --> 01:28:58,020
입력 이미지가 주어지면 순방향 프로세스는 순수한 노이즈인 X-capitality를 얻을 때까지 계속해서 노이즈를 추가합니다.

848
01:28:59,020 --> 01:29:09,020
이 방정식의 첫 번째 줄은 DDPM의 순방향 프로세스 또는 일반적으로 모든 확산 프로세스를 나타냅니다. 순방향 프로세스는 모든 것에 대해 동일하기 때문입니다.

849
01:29:09,020 --> 01:29:18,020
이 정규 분포를 사용하여 XT-1에서 XT를 생성할 수 있습니다.

850
01:29:19,020 --> 01:29:38,020
평균 0과 분산 동일성을 갖는 정규 분포인 XT를 얻은 후 역과정을 통해 확산 과정의 잡음을 제거할 수 있으며 일반적으로 역과정을 P theta로 표시합니다.

851
01:29:39,020 --> 01:29:58,020
이것은 결합 분포 P 세타 X0에서 T까지입니다. 여기에 있는 타임 스탬프는 역 과정이고 일반적으로 매개 변수 세타에 대해 매개변수화된 신경망을 사용하여 예측되기 때문에 역전됩니다.

852
01:29:59,020 --> 01:30:12,020
이 방정식은 확산 모델의 SDE 공식입니다. 여기서 nu는 드리프트 계수, sigma는 확산 계수, WT는 표준 브라운 운동입니다.

853
01:30:13,020 --> 01:30:20,020
그러나 우리는 일관성 모델이 ODE에서 작동하고 ODE가 SDE보다 빠르게 수렴하는 경향이 있다는 것을 알고 있습니다.

854
01:30:21,020 --> 01:30:32,020
그래서 2021년에는 Song et al. 간단히 말해서 확률 흐름 ODE 또는 PF ODE를 제안했으며 이를 ODE로 제안합니다.

855
01:30:33,020 --> 01:30:44,020
이 공식은 X의 델타 로그 Pt인 점수 함수를 통합하여 결정론적인 방식으로 SDE의 본질을 우아하게 포착합니다.

856
01:30:45,020 --> 01:30:55,020
이는 시간 t에서 데이터의 로그 확률의 기울기입니다. 점수 함수 X는 샘플을 무작위 노이즈에서 인식 가능한 데이터 포인트로 다시 시작하는 가이드입니다.

857
01:30:57,020 --> 01:31:07,020
Keras et al.의 설정을 따릅니다. 드리프트 계수를 0으로 설정하고 확산 계수를 루트 2T 아래로 설정하면

858
01:31:08,020 --> 01:31:18,020
우리는 dt에 대한 Xt의 d가 점수 함수의 마이너스 t배와 같은 경험적 PF ODE를 얻습니다.

859
01:31:19,020 --> 01:31:25,020
우리는 종종 점수 함수를 phi Xt comma t의 S로 씁니다.

860
01:31:26,020 --> 01:31:35,020
그런 다음 Euler 또는 Heuern 솔버와 같은 수치 ODE 솔버를 사용하여 t의 X에 대한 솔루션을 얻을 수 있습니다.

861
01:31:36,020 --> 01:31:41,020
일관성 모델은 앞서 언급했듯이 새로운 유형의 생성 모델입니다.

862
01:31:42,020 --> 01:31:48,020
이는 설계의 핵심에서 단일 단계 생성을 지원합니다. 이는 계산적으로 매우 효율적입니다.

863
01:31:51,020 --> 01:31:57,020
또한 반복 생성도 지원합니다. 여러 단계를 사용하여 이미지를 생성할 수 있습니다.

864
01:31:58,020 --> 01:32:05,020
이는 본질적으로 이미지의 샘플 품질을 향상시키지만 계산 비용이 발생합니다.

865
01:32:06,020 --> 01:32:12,020
컴퓨터 일관성 모델을 훈련하는 데는 두 가지 방법이 있습니다. 첫 번째는 증류 모드입니다.

866
01:32:14,020 --> 01:32:20,020
이는 사전 훈련된 확산 모델의 훈련을 의미하며 두 번째는 격리 모드입니다.

867
01:32:21,020 --> 01:32:23,020
이에 대해서는 이후 슬라이드에서 자세히 설명하겠습니다.

868
01:32:24,020 --> 01:32:36,020
그렇습니다. t가 PF ODE의 대문자 T에 대한 엡실론에 속하는 해 궤적 Xt가 있다고 가정하면,

869
01:32:37,020 --> 01:32:48,020
일관성 모델은 f를 입력 Xt로 취하고 ft를 곱하고 X 엡실론을 출력하는 함수 f로 정의됩니다.

870
01:32:49,020 --> 01:32:57,020
그 출력은 임의의 Xt 쉼표 쌍에 대해 일관됩니다.

871
01:32:58,020 --> 01:33:08,020
이는 동일한 궤적에 있는 모든 점에 대해 항상 동일한 X 엡실론을 출력한다는 것을 의미합니다.

872
01:33:09,020 --> 01:33:22,020
모든 일관성 함수 f에 대해 X 엡실론과 동일한 X 엡실론 콤마 엡실론의 f인 항등 함수가 있습니다.

873
01:33:25,020 --> 01:33:31,020
이 제약 조건을 경계 조건이라고 합니다. 모든 일관성 모델은 이 경계 조건을 충족해야 합니다.

874
01:33:31,020 --> 01:33:36,020
일관성 모델의 성공적인 훈련에 중요한 역할을 하기 때문에,

875
01:33:37,020 --> 01:33:43,020
경계 조건은 일관성 모델에 대한 가장 제한적인 아키텍처 제약이기도 합니다.

876
01:33:45,020 --> 01:33:49,020
이제 일관성 모델의 샘플링 프로세스에 대해 이야기해 보겠습니다.

877
01:33:50,020 --> 01:33:55,020
잘 훈련된 일관성 모델 f theta를 사용하면 샘플링을 통해 샘플을 생성할 수 있습니다.

878
01:33:56,020 --> 01:34:03,020
평균이 0이고 t 제곱에 항등을 곱한 정규 분포의 X 물결표 t

879
01:34:04,020 --> 01:34:09,020
그런 다음 X 엡실론 모자에 대한 일관성 모델을 평가합니다.

880
01:34:11,020 --> 01:34:17,020
여기에는 일관성 모델을 통한 단 한 번의 전달만 포함되므로 단일 단계에서 샘플을 생성합니다.

881
01:34:18,020 --> 01:34:23,020
더 중요한 것은 일관성 모델을 여러 번 평가할 수도 있다는 것입니다.

882
01:34:25,020 --> 01:34:30,020
향상된 샘플 품질을 위해 노이즈 제거 및 노이즈 주입 단계를 번갈아 수행합니다.

883
01:34:33,020 --> 01:34:37,020
일관성 모델의 적용은 제로 짧은 데이터 편집입니다.

884
01:34:38,020 --> 01:34:44,020
일관성 모델은 잡음이 있는 입력 Xt에서 X를 복구하도록 학습되므로,

885
01:34:45,020 --> 01:34:50,020
여기서 t는 엡실론부터 대문자 T까지 엡실론에 속하며,

886
01:34:51,020 --> 01:34:54,020
다양한 소음 수준에서 소음 제거를 수행할 수 있습니다.

887
01:34:55,020 --> 01:34:58,020
단일 단계일 수도 있고 여러 단계로 이루어질 수도 있습니다.

888
01:34:59,020 --> 01:35:05,020
이전 슬라이드의 알고리즘 1에서 논의한 다단계 생성 절차는 다음과 같습니다.

889
01:35:06,020 --> 01:35:09,020
제로 쇼트에서 특정 역 문제를 해결하는 데 유용합니다.

890
01:35:10,020 --> 01:35:15,020
여기에는 확산 모델, 방해, 색상화, 초해상도 등이 포함됩니다.

891
01:35:16,020 --> 01:35:20,020
이제 일관성 모델을 훈련하는 방법에 대해 이야기해 보겠습니다.

892
01:35:21,020 --> 01:35:24,020
앞서 말했듯이 일관성 모델은 두 가지 방법으로 학습할 수 있습니다.

893
01:35:25,020 --> 01:35:28,020
하나는 증류 모드이고 다른 하나는 분리 모드입니다.

894
01:35:29,020 --> 01:35:35,020
증류 모드에서는 이미 훈련된, 즉 사전 훈련된 확산 모델을 사용합니다.

895
01:35:36,020 --> 01:35:40,020
따라서 우리는 이미 S5 X, t라는 사전 훈련된 점수 모델을 가지고 있습니다.

896
01:35:41,020 --> 01:35:44,020
다음 단계는 시간 범위를 이산화하는 것입니다.

897
01:35:45,020 --> 01:35:50,020
엡실론부터 대문자 T, n-1 하위 간격까지의 범위입니다.

898
01:35:52,020 --> 01:35:57,020
여기서 주목해야 할 중요한 점은 이러한 하위 간격이 균일하지 않다는 것입니다.

899
01:35:58,020 --> 01:36:02,020
Kara Settle이 제안한 다음 규칙에 따라 결정됩니다.

900
01:36:02,020 --> 01:36:14,020
ODE 솔버를 사용하면 여기에서 tn의 X hat phi 값과 phi 함수를 얻을 수 있습니다.

901
01:36:15,020 --> 01:36:19,020
이는 ODE 솔버의 단일 단계입니다.

902
01:36:20,020 --> 01:36:30,020
오일러 솔버를 사용하는 경우 PFOD에 대한 오일러 솔버의 솔루션은 점수 모델의 마이너스 t배가 될 것입니다.

903
01:36:31,020 --> 01:36:38,020
점수 모델에 마이너스 t를 곱하면 n의 X와 phi t에 대해 다음과 같은 업데이트 함수를 얻습니다.

904
01:36:40,020 --> 01:36:43,020
X hat phi tn의 값을 얻으면,

905
01:36:44,020 --> 01:36:50,020
X tn + 1 쉼표 X tn hat phi 사이의 차이를 최소화하여 모델을 훈련할 수 있습니다.

906
01:36:52,020 --> 01:36:54,020
그리고 마지막으로 사용되는 함수는 이것이다.

907
01:36:56,020 --> 01:36:58,020
그런데 X tn 더하기 1을 어떻게 얻나요?

908
01:36:59,020 --> 01:37:03,020
따라서 훈련하는 동안 먼저 데이터 분포에서 X를 샘플링합니다.

909
01:37:04,020 --> 01:37:10,020
그리고 확산 과정에 대한 SD 방정식을 사용하여 X tn + 1을 생성합니다.

910
01:37:12,020 --> 01:37:16,020
그런 다음 X tn 더하기 1을 사용하여 이 X 모자 파이 tn을 생성할 수 있습니다.

911
01:37:18,020 --> 01:37:27,020
여기 마지막 기능에서 사용된 매트릭스는 논문에서 사용된 L1, L2 또는 LP IPS입니다.

912
01:37:28,020 --> 01:37:30,020
D는 여기의 미터법 함수입니다.

913
01:37:31,020 --> 01:37:37,020
그리고 실제로는 모델 매개변수 세타에 대한 확률적 경사하강법을 통해 목표를 최소화합니다.

914
01:37:39,020 --> 01:37:43,020
지수 이동 평균으로 세타 마이너스를 업데이트하는 동안.

915
01:37:44,020 --> 01:37:50,020
여기의 세타 마이너스는 최적화 중 과거 세타 값의 실행 평균을 나타냅니다.

916
01:37:52,020 --> 01:37:55,020
이것은 증류를 위한 일관성 모델을 훈련하기 위한 알고리즘입니다.

917
01:37:56,020 --> 01:38:00,020
일관성 증류(Consistency Distillation) 또는 줄여서 CD라고도 합니다.

918
01:38:01,020 --> 01:38:06,020
이에 대한 입력은 D로 표시되는 데이터 세트가 됩니다.

919
01:38:07,020 --> 01:38:09,020
그런 다음 초기 모델 매개변수 세타가 있습니다.

920
01:38:10,020 --> 01:38:14,020
학습률 eta를 초기화하면 ODE 솔버가 있습니다.

921
01:38:15,020 --> 01:38:19,020
오일러, UN 또는 기타 솔버가 될 수 있습니다.

922
01:38:20,020 --> 01:38:25,020
그런 다음 D에서 X를 샘플링하는 루프를 실행합니다.

923
01:38:26,020 --> 01:38:32,020
1 쉼표 n - 1의 균일 분포에서 시간 감각에 대한 값 n을 샘플링합니다.

924
01:38:33,020 --> 01:38:41,020
그런 다음 확산 과정의 SD 방정식을 사용하여 n + 1의 X t를 샘플링합니다.

925
01:38:42,020 --> 01:38:44,020
이것이 해당 방정식의 전이 분포입니다.

926
01:38:45,020 --> 01:38:48,020
우리는 이 분포에서 X tn + 1을 샘플링합니다.

927
01:38:49,020 --> 01:38:56,020
그런 다음 X tn + 1 및 ODE 솔버를 사용하여 tn으로 X 모자를 얻습니다.

928
01:38:57,020 --> 01:39:03,020
그런 다음 손실을 계산하고 세타를 업데이트하고 세타 마이너스도 업데이트합니다.

929
01:39:04,020 --> 01:39:07,020
그리고 수렴이 될 때까지 이 루프를 실행합니다.

930
01:39:08,020 --> 01:39:11,020
일관성 모델을 훈련하는 두 번째 방법은 격리된 것입니다.

931
01:39:12,020 --> 01:39:16,020
여기서는 이미 사전 훈련된 점수 모델을 사용하지 않습니다.

932
01:39:16,020 --> 01:39:19,020
우리는 사전 훈련된 확산 모델에 의존하지 않습니다.

933
01:39:22,020 --> 01:39:30,020
마지막 슬라이드에서 호출한 것처럼 이 elation 설정에서는 사전 훈련된 점수 모델인 X comma t의 S5를 사용합니다.

934
01:39:31,020 --> 01:39:33,020
점수 함수에 대한 지상 경로를 대략적으로 계산합니다.

935
01:39:34,020 --> 01:39:43,020
하지만 그것을 사용하는 대신 여기에 제공된 기대 공식을 직접 사용할 수 있습니다.

936
01:39:43,020 --> 01:39:50,020
이는 기대값 X t 마이너스 X를 X t가 주어지면 t 제곱으로 나눈 값의 음수입니다.

937
01:39:51,020 --> 01:39:58,020
저자는 이것을 이미 사전 훈련된 점수 함수 대신 점수 함수로 사용한다고 주장합니다.

938
01:39:59,020 --> 01:40:05,020
오일러 방법을 사용할 때 일관성 증류에서 사전 훈련된 확산 모델을 대체하는 것으로 충분합니다.

939
01:40:06,020 --> 01:40:07,020
이것은 오일러 방법에 대한 것입니다.

940
01:40:08,020 --> 01:40:15,020
이는 고립된 일관성 모델을 위한 알고리즘입니다.

941
01:40:16,020 --> 01:40:20,020
일관성 훈련(Consistency training), 줄여서 CT라고도 합니다.

942
01:40:21,020 --> 01:40:25,020
데이터세트 D, 초기 모델 매개변수 theta, 학습률 eta가 제공됩니다.

943
01:40:26,020 --> 01:40:28,020
그런 다음 단계 일정 N이 있습니다.

944
01:40:29,020 --> 01:40:37,020
그리고 EMA Decay Rate Schedule, 새로운 D 매트릭스 및 람다가 있습니다.

945
01:40:40,020 --> 01:40:45,020
Theta 마이너스는 초기에 theta로 초기화되고 k는 먼저 0으로 초기화됩니다.

946
01:40:46,020 --> 01:40:49,020
그리고 수렴할 때까지 for 루프를 실행합니다.

947
01:40:50,020 --> 01:40:52,020
먼저 증류 모드에서처럼 X를 샘플링합니다.

948
01:40:53,020 --> 01:40:55,020
그런 다음 증류 모드에서와 마찬가지로 N을 샘플링합니다.

949
01:40:56,020 --> 01:41:01,020
우리는 평균 동일 분산이 0인 정규 분포에서 Z를 샘플링합니다.

950
01:41:02,020 --> 01:41:03,020
손실함수를 계산합니다.

951
01:41:04,020 --> 01:41:07,020
이는 증류 모드에서 사용한 것과 동일한 손실 함수입니다.

952
01:41:09,020 --> 01:41:15,020
이 경사하강법 공식을 사용하여 세타를 업데이트합니다.

953
01:41:16,020 --> 01:41:21,020
그리고 세타 빼기 1도 stop grad를 사용하여 업그레이드됩니다.

954
01:41:22,020 --> 01:41:27,020
여기서 유일한 차이점은 단계 일정입니다.

955
01:41:28,020 --> 01:41:38,020
그리고 프리텐트 점수 모델 대신 점수 함수에 대한 기대 공식을 사용합니다.

956
01:41:41,020 --> 01:41:46,020
실험에 있어서 논문에서는 다음과 같은 데이터 세트를 사용했습니다.

957
01:41:47,020 --> 01:41:58,020
논문에서 사용된 매트릭스는 FID, Inception Score, Precision, Recall이다.

958
01:41:59,020 --> 01:42:02,020
훈련을 위해 그들은 Euler와 Heuensor D 솔버를 사용합니다.

959
01:42:03,020 --> 01:42:10,020
그리고 손실 함수에 대한 D 행렬은 L2, L1 및 LBI를 사용했습니다.

960
01:42:11,020 --> 01:42:13,020
결과는 다음과 같습니다.

961
01:42:17,020 --> 01:42:24,020
이것으로 특히 점수 기반 생성 모델 및 확산 모델에 대한 전체 프레젠테이션을 마칩니다.

962
01:42:25,020 --> 01:42:29,020
궁금하신 점이나 궁금한 점은 댓글로 편하게 문의해주세요.

963
01:42:30,020 --> 01:42:31,020
우리는 그들에게 대답하려고 노력할 것입니다.

964
01:42:32,020 --> 01:42:33,020
감사합니다.