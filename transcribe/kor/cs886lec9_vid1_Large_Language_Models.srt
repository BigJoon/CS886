1
00:00:00,000 --> 00:00:10,800
안녕하세요. 그리고 저랑 좀 동갑인 제리예요. 우리는 대규모에 대해 이야기 할 것입니다

2
00:00:10,800 --> 00:00:20,240
CEF 886 강의 9의 언어 모델 기초 모델에 대한 최근 분석. 큰 것은 무엇입니까?

3
00:00:20,240 --> 00:00:29,720
언어 모델? 이제 오늘의 의제를 다루기 위해 몇 가지 사항에 중점을 둘 것입니다.

4
00:00:29,720 --> 00:00:36,200
아키텍처 측면에서 다양한 유형의 대규모 언어 모델. 우리는 집중할 것입니다

5
00:00:36,200 --> 00:00:45,080
DPT3, T5, Codex, Lama2 등에 있습니다. 또한 지도 학습에 중점을 두고 비교합니다.

6
00:00:45,080 --> 00:00:52,200
다른 유형의 학습에. 언제든지 잠시 멈춰 질문을 하셔도 좋습니다. 우리

7
00:00:52,200 --> 00:00:56,920
이 세션이 끝나면 해당 토론에 대한 일련의 질문이 있습니다.

8
00:00:57,720 --> 00:01:05,800
이제는 대형 모델의 경우 정말 자연어인 딥러닝에 중점을 두고 있습니다.

9
00:01:05,800 --> 00:01:13,000
긴급한 작업. 대규모 언어 모델은 다음과 같은 능력을 갖춘 계산 모델입니다.

10
00:01:13,000 --> 00:01:17,400
인간 모델을 이해하고 생성하는 능력. 대규모 언어 모델

11
00:01:20,120 --> 00:01:25,160
작업 순서 또는 텍스트 도중의 가능성을 예측하는 전달 능력이 있습니다.

12
00:01:25,160 --> 00:01:30,680
주어진 입력을 기반으로 합니다. 과거에 Ngram 모델에서 이것이 어떻게 수행되었는지 보여주는 예는 다음과 같습니다.

13
00:01:30,680 --> 00:01:37,480
FKM은 아마도 실제로 전통적인 텍스트를 기반으로 올바른 것을 추정하려고 노력한다고 가르칠 것입니다.

14
00:01:39,640 --> 00:01:45,400
단어 확률. 그들은 일반적으로 방대한 양의 공공 의료 법률 데이터에 대한 교육을 받습니다.

15
00:01:46,360 --> 00:01:50,520
대규모 언어 모델은 작업 순서의 가능성을 예측하는 전송성을 갖습니다.

16
00:01:50,600 --> 00:01:55,400
주어진 입력을 기반으로 한 텍스트입니다. 다중 매개변수를 갖춘 고급 프로그래밍 모델입니다.

17
00:01:56,040 --> 00:02:01,880
그리고 뛰어난 학습 능력. 변압기의 분리 모델은 기본 역할을 합니다.

18
00:02:01,880 --> 00:02:07,880
대규모 언어 모델 작업을 위한 빌딩 블록입니다. Transmortem에는

19
00:02:07,880 --> 00:02:14,120
순차 데이터를 효율적으로 처리하고 병렬화를 위해 정렬하는 기능을 갖춘 최종 필드

20
00:02:14,120 --> 00:02:22,040
언어, 성기, 텍스트를 캡처합니다. 동료 학습자의 주요 특징 중 하나는 접촉입니다.

21
00:02:22,040 --> 00:02:26,760
학습에 대해서는 나중에 이야기하겠습니다. 이제 우리는 큰 제품을 비교하고 싶습니다.

22
00:02:26,760 --> 00:02:33,480
기계 학습 및 딥 러닝에 대한 딥 러닝과 언어 모델을 비교합니다. 와 함께

23
00:02:36,760 --> 00:02:42,200
대규모 언어 모델의 경우 일반적으로 훈련 데이터는 다음 순서로 매우 큽니다.

24
00:02:42,840 --> 00:02:51,960
기본적으로는 테라바이트입니다. 어떤 특징이나 변수도 직접 식별할 필요가 없습니다.

25
00:02:51,960 --> 00:02:56,920
자동으로 됩니다. 그리고 모델은 매우 복잡한 경향이 있습니다. 그들은

26
00:02:59,240 --> 00:03:04,200
왜냐하면 그들이 다루고 있는 모든 것이 정말 복잡한 문제이기 때문입니다. 이제 문제 중 하나는

27
00:03:04,200 --> 00:03:09,960
하지만 해석하기가 쉽지 않습니다. 해석이 더 어렵네요

28
00:03:09,960 --> 00:03:16,280
그들이 가지고 있는 결론. 이것이 대규모 언어 모델의 개념입니다.

29
00:03:16,280 --> 00:03:21,000
그건 나중에. 또한 매우 높은 플랫폼을 갖추고 있으며 엄청난 양의 컴퓨팅 성능이 필요합니다.

30
00:03:21,000 --> 00:03:28,200
달려가라고 명령한다. 실제로 여기서는 하루에 초당 또 다른 페타플로트에 대해 이야기하고 있습니다.

31
00:03:29,080 --> 00:03:34,760
그러기 위해서는 많은 돈이 필요하다. 이제 자연어 현재 작업은 다음과 같은 경향이 있습니다.

32
00:03:35,560 --> 00:03:45,000
추론을 이해하고 새로운 자료를 생성하는 세 가지 주요 영역에서.

33
00:03:45,000 --> 00:03:52,520
4가지 주요 영역을 이해하면서 감정 분석을 살펴보겠습니다.

34
00:03:52,520 --> 00:03:59,640
여기서는 단락이나 텍스트 본문을 가져와 해석하여 결정합니다.

35
00:03:59,640 --> 00:04:05,960
감정적 상태. 따라서 이것은 일반적으로 이진수 또는 삼중수였습니다. 그럴 수도 있지, 아, 그래,

36
00:04:05,960 --> 00:04:12,840
이것은 예언의 절반입니다. 그리고 그것은 이것 또는 부정적인 감정 또는 중립을 의미했습니다.

37
00:04:13,560 --> 00:04:21,480
또한 텍스트 분류를 처리할 수도 있습니다. 그러니까 감정분석과 비슷하지만,

38
00:04:21,480 --> 00:04:28,280
해당 텍스트에 대한 명확한 분류가 필요합니다. 그리고 그것이 할 수 있는 일 중 하나는

39
00:04:28,280 --> 00:04:34,280
이것을 주든 항의하든 주어진 것의 종결인 자연어 추론

40
00:04:35,000 --> 00:04:39,720
그들이 다루고 있는 텍스트의 주어진 전제에 기초한 후속 조치.

41
00:04:40,840 --> 00:04:46,120
네, 물론 이해해줄 수도 있습니다. 그리고 추론의 관점에서 볼 때, 이것은 실제로

42
00:04:47,160 --> 00:04:52,120
모델은 제공된 정보를 이해할 수 있어야 합니다.

43
00:04:52,520 --> 00:04:57,480
적어도 내년에 내가 확인한 답을 추론하기 위해 추론을 활용하십시오.

44
00:04:57,480 --> 00:05:02,360
그런 다음 텍스트를 생성할 수 있습니다. 그래서 그들은 요약을 할 수 있습니다. 아시다시피 그들은 전체를 가져갈 수 있습니다

45
00:05:02,360 --> 00:05:09,720
간결하게, 그들은 많은 양의 텍스트에서 간결한 초록을 생성할 수 있고 질문을 할 수 있습니다.

46
00:05:09,720 --> 00:05:18,360
응답. 그래서 여기서 이야기할 첫 번째 모델은 P5입니다. P5는 텍스트에서 텍스트로의 전송을 의미합니다.

47
00:05:18,440 --> 00:05:24,840
변신 로봇. 따라서 번역, 질의 응답, 분류,

48
00:05:24,840 --> 00:05:30,840
서명 점수 또는 요약. 이제 문제에 대한 통일된 접근 방식을 갖게 되었습니다. 그것은 기본적으로

49
00:05:30,840 --> 00:05:36,520
모든 것을 텍스트로 생성한 다음 텍스트로도 출력합니다. 무엇이 가능하다고 생각하는가?

50
00:05:37,400 --> 00:05:43,400
P5의 연구원을 사용하여 동일한 모델, 동일한 사후 기능을 사용하는 방법,

51
00:05:43,400 --> 00:05:49,960
다양한 작업 세트에 걸쳐 홉업 매개변수, 레이어, SSTURA. 그래서 그들은 모든 텍스트를 다룹니다.

52
00:05:50,520 --> 00:05:55,960
텍스트에 문제가 있고 그들이 말하는 내용을 사용합니다. SSTURA 표현은 무엇입니까?

53
00:05:55,960 --> 00:06:00,920
이는 일반적으로 숫자입니다. 그리고 입력은 다음을 생성하는 공통 핵심 프로젝트입니다.

54
00:06:01,560 --> 00:06:06,600
매달 웹 가장자리에서 실제로 20테라바이트의 텍스트가 추가됩니다. 그들은 그것을 만들기 위해 그것을 청소합니다

55
00:06:06,600 --> 00:06:12,840
그 프로세스를 사용할 수 있습니다. 모델 자체는 데이터가 풍부한 작업에서 먼저 묘사된 후

56
00:06:12,840 --> 00:06:19,160
사실에 맞춰 조정되거나 다운스트림 작업에 있습니다. 그리고 빌딩 블록은 안전한 관심입니다. 예를 들어,

57
00:06:19,160 --> 00:06:26,040
여기 다이어그램에 있는 내용을 보면 왼쪽 첫 번째 상단 문장에 접두사가 있습니다.

58
00:06:26,040 --> 00:06:30,760
이것을 독일어로 번역하면 좋습니다. 그리고 그것은 변압기와

59
00:06:31,560 --> 00:06:40,120
올바른 독일어 응답 쉼표, 좋습니다. 이제 이 T5의 아키텍처에 대해 이야기해 보겠습니다.

60
00:06:40,840 --> 00:06:48,440
그래서 터미널에 처음으로 확인박람회가 도입됐고, 37명이 전화를 걸었다.

61
00:06:48,440 --> 00:06:54,440
그 안에 모든 것이 있다는 것을 보여주세요. 한 분석가가 그랬습니다. 사용하는 획기적인 건축물이었습니다.

62
00:06:54,440 --> 00:07:02,440
데이터에 컨텍스트를 추가하는 데 주의를 기울이십시오. 이 경우 인코딩에는 인코딩 구성 요소가 있습니다.

63
00:07:03,160 --> 00:07:08,040
및 디코딩 구성요소. 따라서 인코딩 구성요소는 입력 시퀀스와 맵을 허용합니다.

64
00:07:08,200 --> 00:07:12,360
입력에 대한 모든 학습 기능을 유지하는 지속적인 반복 후에.

65
00:07:13,000 --> 00:07:17,160
그런 다음 디코딩 구성 요소는 토큰의 연속성을 취한 다음 순차적으로

66
00:07:17,160 --> 00:07:23,720
이전 출력을 공급받는 동시에 출력을 생성합니다. 따라서 인코딩 구성 요소는 모든 것을 허용합니다.

67
00:07:23,720 --> 00:07:27,640
입력 시퀀스의 벡터를 동시에 입력하지만 함수 인코딩의 경우

68
00:07:27,640 --> 00:07:35,480
입력 순서 내에서 입력 순서. 그런 다음 추가 벡터를 추가하여 이를 수행합니다.

69
00:07:35,480 --> 00:07:41,880
각 입력을 벡터 내에 삽입합니다. 그런 다음 시퀀스 내의 모든 홀수 입력에 대해

70
00:07:41,880 --> 00:07:48,440
코사인 함수로 생성된 벡터를 추가하고 모든 짝수에 대해 사인으로 생성된 벡터를 추가합니다.

71
00:07:48,440 --> 00:07:55,160
기능. 이제 오른쪽 하단의 다이어그램에서 볼 수 있듯이 선형 레이어가 있습니다.

72
00:07:55,160 --> 00:07:59,720
이 레이어에는 벡터를 제공하고 벡터를 투영하는 신경망이 있습니다.

73
00:07:59,720 --> 00:08:05,720
구성 요소를 논리 벡터라고 하는 훨씬 더 큰 벡터로 디코딩하여 생성됩니다. 지금,

74
00:08:05,720 --> 00:08:10,760
논리 벡터 크기는 모델 어휘의 고유 단어 수에 따라 결정됩니다.

75
00:08:10,760 --> 00:08:16,200
그래서 오른쪽 하단의 출력 전 마지막인 소프트박스 레이어의 작업은,

76
00:08:17,320 --> 00:08:20,920
논리 점수를 확률로 변환하는 것입니다. 그래서 그 말은

77
00:08:22,120 --> 00:08:26,440
또는 가장 높은 확률을 갖는 출력 시퀀스를 갖는 이 입력 시퀀스

78
00:08:26,440 --> 00:08:30,840
모델 어휘가 선택된 다음 이 시간 단계 동안 출력으로 예측됩니다.

79
00:08:31,400 --> 00:08:36,680
그런 다음 출력은 디코딩 구성 요소로 다시 피드백되어 컨텍스트를 알리거나 제공하는 데 도움이 됩니다.

80
00:08:36,680 --> 00:08:46,200
다음 레이어에 대한 각 예측에 적용됩니다. 이를 자동 회귀라고 합니다. 그것을 입력으로 알아두세요

81
00:08:46,200 --> 00:08:52,600
한 인코더에서 다음 인코더로 흐름이 전달되면 다음 인코더도 스택에 배치됩니다. 그것은

82
00:08:52,600 --> 00:09:00,200
단순히 디코더 스택에서 일어나는 일입니다. 이제 인코딩에 대해 자세히 살펴보겠습니다.

83
00:09:00,200 --> 00:09:05,160
디코딩 계층. 따라서 인코더 계층 내에는 안전 주의라고 부르는 것이 있습니다. 이것

84
00:09:05,160 --> 00:09:10,920
메커니즘을 통해 서로 상호작용할 수 있습니다.

85
00:09:10,920 --> 00:09:17,160
어떤 단어에 더 주의를 기울여야 하는지 알아보세요. 인코더 디코더 주의

86
00:09:18,120 --> 00:09:22,840
디코딩 구성요소 내에 있는 레이어, 해당 레이어의 목표는 다음을 돕는 것입니다.

87
00:09:24,280 --> 00:09:27,800
모델은 입력 시퀀스의 단어를 출력 시퀀스의 단어와 정렬합니다.

88
00:09:28,440 --> 00:09:34,600
그리고 신경망 계층인 선형 계층은 신경망입니다. 하지만

89
00:09:34,600 --> 00:09:40,200
해당 프로젝트에서 디코딩 구성요소에 의해 생성된 벡터는 훨씬 더 큰 크기로 변환됩니다.

90
00:09:40,200 --> 00:09:45,320
논리라고 불리는 벡터. 그리고 앞서 언급한 것처럼 논리의 크기는 물론

91
00:09:45,320 --> 00:09:51,160
는 단어나 어휘에서 고유한 단어는 아니지만 뭔가입니다. 의 개발

92
00:09:51,160 --> 00:10:00,200
상위 모델은 로지스틱 확률을 제공하는 것입니다. 그리고 그것은 실제로 일어나는 일입니다.

93
00:10:00,200 --> 00:10:08,520
데이터 양식 모델. 자, 여러분은 이전에 이것을 보셨을 것입니다. 이것은 표준 변압기 모델 아키텍처입니다.

94
00:10:08,520 --> 00:10:18,120
우리가 이전 강의에서 들었던 내용입니다. 따라서 저는 이것이 어떻게 이루어지는지에 대해 개별적으로 자세히 설명하지 않겠습니다.

95
00:10:18,120 --> 00:10:26,840
공장. 이제 우리가 언급한 것처럼 두 인코더로 구성됩니다.

96
00:10:26,840 --> 00:10:32,200
디코더 아키텍처에서는 인코더와 인코더의 크기가 실제로 비슷합니다. 그들은 각각

97
00:10:32,200 --> 00:10:37,160
각각 12개의 블록으로 구성됩니다. 그리고 각 블록은 안전한 주의, 선택적 인코더로 구성됩니다.

98
00:10:37,160 --> 00:10:45,000
디코더 주의 및 피드 포워드 네트워크. 그리고 이것은 표준 변압기입니다.

99
00:10:45,000 --> 00:10:53,960
건축학. 이제 T5 트랜스포머 내에서 관심은 정말 독특한 방식으로 처리됩니다.

100
00:10:53,960 --> 00:10:58,760
따라서 모델 프로세스, 입력 시퀀스의 각 입력, 각 토큰 입력 시퀀스 및

101
00:10:58,760 --> 00:11:03,000
안전한 순서에 따라 다른 토큰에 서로 다른 주의 점수를 할당합니다. 이제 이것이 호출됩니다.

102
00:11:03,000 --> 00:11:08,280
모델의 컨텍스트 이해에 대한 각 토큰의 기여 패턴을 결정합니다.

103
00:11:08,280 --> 00:11:15,160
그리고 인코더 디코더 주의 내에서 이것에 대해 이야기해 봅시다. 그럼 무슨 일이 일어나나요?

104
00:11:15,160 --> 00:11:18,920
쿼리는 이전 디코더 레이어에서 나온 다음 메모리와 키는 출력에서 ​​나옵니다.

105
00:11:18,920 --> 00:11:23,240
인코더의. 그리고 모든 질문 인코더가

106
00:11:23,240 --> 00:11:27,480
입력 순서. 이제 이는 입력 시퀀스의 세계를 텍스트의 단어와 정렬하는 데 도움이 됩니다.

107
00:11:27,560 --> 00:11:36,440
입력 순서. 그리고 엔코더에도 안전주의 사항이 담겨 있습니다. 그리고 다른 부분은,

108
00:11:36,440 --> 00:11:42,760
이는 디코더에 표시된 안전 주의입니다. T5 아키텍처에는 차이가 있을 수 있습니다.

109
00:11:42,760 --> 00:11:50,280
그래서 그들은 사람들이 이야기했던 약간 다른 세 가지 변종입니다.

110
00:11:50,280 --> 00:11:55,560
이 내용이 기반이 되기를 원하는 사람들을 모르시나요? 이제 사실은 정말

111
00:11:56,920 --> 00:12:03,320
이 구별 요소는 실제로 모드에서 다른 주의 메커니즘에 의해 사용되어야 한다는 것입니다.

112
00:12:05,000 --> 00:12:11,720
자, 이것을 보시면 어두운 색상과 밝은 색상이 있습니다. 그렇죠? 그래서,

113
00:12:12,520 --> 00:12:19,320
다른 색상은 다른 성능을 나타냅니다. 어두운 회색 선은

114
00:12:19,400 --> 00:12:25,240
완전히 보이는 마스킹과 밝은 회색 선은 캐주얼 마스킹에 해당합니다. 그래서 우리는

115
00:12:25,240 --> 00:12:31,160
해당 다이어그램에서 볼 수 있는 점은 다음을 나타내는 시퀀스 토큰의 특수한 끝을 나타냅니다.

116
00:12:31,160 --> 00:12:36,760
예측 끝. 입력과 출력은 각각 x와 y로 표시됩니다. 왼쪽에

117
00:12:37,320 --> 00:12:42,200
왼쪽에 있는 첫 번째 모델인 측면에는 표준 인코더만 있고

118
00:12:42,200 --> 00:12:46,920
디코더 아키텍처에서는 일반적으로 완전히 보이는 마스킹 인코더와 인코더라는 것을 알 수 있습니다.

119
00:12:47,800 --> 00:12:53,400
연한 회색 선인 디코더에 세심하게 표시한 디코더 특성화입니다.

120
00:12:53,400 --> 00:12:58,200
중간에는 단일 변환기 레이어 스택으로 구성된 언어 모델이 있습니다.

121
00:13:00,600 --> 00:13:06,600
이는 자동차 롤을 사용하여 입력과 대상 교차의 연결을 확산시키는 것입니다.

122
00:13:07,960 --> 00:13:14,440
전체적으로 인과적인 마스크. 오른쪽에는 접두사 언어 모델이 있습니다. 이것은

123
00:13:14,760 --> 00:13:19,800
입력 위에 눈에 보이는 마스킹이 있는 줄에 해당하는 접두사 언어 모델입니다.

124
00:13:21,000 --> 00:13:26,040
그래서 주의는 여러분이 가질 수 있는 다양한 주의 마스크 패턴을 가지고 있습니다. 그만큼

125
00:13:26,040 --> 00:13:31,480
주의 마스크 패턴은 대규모 언어 모델 자체에서 메커니즘으로 중요한 구성 요소입니다.

126
00:13:31,480 --> 00:13:38,120
학습 중에 모델이 주의를 기울여야 하는 입력 시퀀스 부분을 제어합니다.

127
00:13:38,120 --> 00:13:45,560
또는 추론 과정. 따라서 주의 마스크에는 네 가지 유형이 있을 수 있습니다. 당신은 우리가 부르는 것을 가지고 있습니다

128
00:13:45,560 --> 00:13:52,600
완전한 관심. 따라서 일부 모델에서는 모든 토큰이 다른 모든 토큰 입력에 할당됩니다.

129
00:13:53,560 --> 00:13:59,000
이는 완전 주의(full attention)로 알려져 있으며 소형 모델에 자주 사용됩니다. 체중계가 있는 경우

130
00:13:59,720 --> 00:14:04,920
완성도를 더욱 효율적으로 만들기 위해 내적 주의를 기울이고, 대형 모델은 일반적으로 규모를 사용합니다.

131
00:14:05,480 --> 00:14:10,200
도트 주목, 스케일 도트 제품 주목. 이는 토큰이 다른 토큰에만 참석한다는 것을 의미합니다.

132
00:14:10,200 --> 00:14:15,800
특정 거리 내에 있는 토큰과 그 거리는 고정된 창 크기에 따라 결정됩니다.

133
00:14:15,800 --> 00:14:22,120
맥락 길이와 우리가 가면 주의(masked attention)라고 부르는 것이 있습니다. 이 경우 모델은 다음과 같이 해야 합니다.

134
00:14:22,120 --> 00:14:27,960
훈련 중 시간 누출을 피하기 위해 토큰을 두는 경향이 없으며 삼각주의

135
00:14:27,960 --> 00:14:32,840
마스크가 사용됩니다. 이 표시는 각 토큰이 시퀀스의 이전 토큰에만 참여할 수 있음을 보여줍니다.

136
00:14:32,840 --> 00:14:37,800
그리고 당신은 관심을 끄는 경우를 가질 수 있습니다. 따라서 GPT 3.5와 같은 대규모 언어 모델은

137
00:14:38,520 --> 00:14:42,760
직원의 다재다능한 머리, 각 머리는 모델에 따라 서로 다른 주의 패턴을 나타냅니다.

138
00:14:42,760 --> 00:14:47,480
데이터 내의 다양한 정보를 캡처합니다. 이제 다음과 같은 몇 가지 다른 측면이 있습니다.

139
00:14:47,480 --> 00:14:56,360
사상가, 의미론, 감정. 여기 보여드린 다이어그램에서 어두운 세포는

140
00:14:57,240 --> 00:15:05,080
i행과 j열에서 두 번째 세미콜론의 경우 참석을 허용합니다.

141
00:15:05,800 --> 00:15:13,720
시간 단계 i에서 요소 j를 입력합니다. 예를 들어 y1에 x1을 입력해야 합니다.

142
00:15:14,760 --> 00:15:21,480
이제 다양한 모델의 성능을 살펴보면 다음과 같은 점을 알 수 있습니다.

143
00:15:22,120 --> 00:15:31,480
인코더, 인코더 아키텍처는 이전 아키텍처를 참조합니다.

144
00:15:31,480 --> 00:15:36,360
내가 설명할 변종. P는 12층의 매개변수 수를 나타냅니다.

145
00:15:37,240 --> 00:15:44,360
기본 변압기 스택 및 M은 전체 전력, 필요한 자속을 나타냅니다.

146
00:15:45,240 --> 00:15:51,240
인코더-디코더 모델을 사용하는 시퀀스를 처리합니다. 그래서 우리는 각 배우를 평가합니다.

147
00:15:51,240 --> 00:15:55,640
노이즈 제거 목표를 사용한 변형과 ​​일반적으로 사용되는 자동 회귀

148
00:15:56,440 --> 00:16:01,320
객체 사이. 우리는 노이즈 제거 기능이 있는 인코더-디코더 텍스처를 고려합니다. 노이즈 제거는 감소에 도움이 됩니다.

149
00:16:01,320 --> 00:16:06,360
무작위성과 해당 입력 데이터. 재미로 거기는 어때요? 이제 여기서 소음이 보이면

150
00:16:06,360 --> 00:16:13,320
우리가 언급하는 노이즈는 능력을 방해하는 무작위 또는 예측할 수 없는 플럭스 데이터를 의미합니다.

151
00:16:14,120 --> 00:16:20,440
경로 전송 유형을 식별합니다. 그래서 시스템에서 소음을 관찰해야 할 때,

152
00:16:20,440 --> 00:16:27,880
이로 인해 정확도가 감소하고 모터 보호 또는 출력이 재발하게 됩니다.

153
00:16:28,920 --> 00:16:35,160
이제 T5가 사용하는 데이터 측면에서 우리가 Closer, Clean, Crawl, Couples라고 부르는 것을 사용합니다.

154
00:16:36,120 --> 00:16:40,440
내가 이것의 시작 부분에서 훨씬 일찍 언급했던 것입니다. 정말 세트네요

155
00:16:40,840 --> 00:16:49,560
웹에 추가되는 텍스트 데이터를 통한 우정. 그리고 정리할 숫자입니다. 그것은 사용한다

156
00:16:50,120 --> 00:16:56,040
보일러 텍스트 위치를 제거하고, 라인을 복제하고, 동의하고, 유지하는 간단한 경험적 연산자입니다.

157
00:16:56,040 --> 00:17:00,840
각 줄은 최소 5단어로 이어져야 합니다. 그리고 그것은 다음과 같은 모든 페이지에 대해 논의합니다.

158
00:17:00,840 --> 00:17:06,840
세 문장으로 오른쪽으로 이동한 다음 항목이 포함될 수 있는 모든 페이지를 제거합니다.

159
00:17:07,800 --> 00:17:13,800
음란하거나 최악의 나쁜 단어가 아닌 더러운 목록입니다. 물론, 이는 또한

160
00:17:13,800 --> 00:17:21,480
데이터 복제. 이제 T5가 다운스트림 형태로 수행하는 작업 유형은 무엇입니까? 제 생각에는

161
00:17:21,480 --> 00:17:27,320
그들은 실제로 봉사하지 않습니다. 일반적인 언어와 능력을 측정하는 데 사용할 수 있습니다. 당신은 할 수 있습니다

162
00:17:28,120 --> 00:17:31,640
주제판단, 다양한 평가분석 등의 문장을 확인해보세요.

163
00:17:32,200 --> 00:17:35,640
문장을 바꾸어 표현하거나 문장 사이에 있는 이야기를 찾는 데 사용할 수 있습니다.

164
00:17:36,760 --> 00:17:42,200
또한 자연어 추론을 통해 내부에서 무슨 일이 일어나고 있는지 파악할 수도 있습니다.

165
00:17:42,200 --> 00:17:48,760
특정 문장. 그런 다음 문장 완성이나 핵심 참조 해결 등을 할 수 있습니다.

166
00:17:48,760 --> 00:17:51,720
질문 끝에 말합니다. 또한 질문에 답하는 데 도움이 됩니다.

167
00:17:52,040 --> 00:18:02,920
모델을 훈련하기 위해 기본적으로 다음과 같은 매우 간단한 텍스트를 따릅니다. 그것은 계속되고

168
00:18:03,640 --> 00:18:14,520
2단계를 사용하여 19단계 또는 524,000단계의 다양한 단계를 수행하는 척합니다. 그리고

169
00:18:15,320 --> 00:18:26,680
처음 10에서 4 또는 10,000단계까지의 선형 비율은 0.01입니다. 그러다가 줄어들어요

170
00:18:26,680 --> 00:18:33,480
가리키는 경우 선형 비율은 0.01입니다. T5가 할 수 있는 일 중 하나는

171
00:18:33,480 --> 00:18:41,880
진행 목표. 모델이 얻을 수 있는 일종의 메커니즘이라는 것을 알 수 있습니다.

172
00:18:41,880 --> 00:18:47,800
다운스트림 단계에 적용할 범용 지식입니다. 일련의 토큰 아이디어만 볼 수 있습니다.

173
00:18:47,800 --> 00:18:55,320
빌드 텍스트 데이터에서만 토큰화된 텍스트에 해당하고 이를 사용할 수 있습니다.

174
00:18:55,320 --> 00:19:01,080
처리할 토큰 시퀀스, 교정기 입력 시퀀스와 해당하는 시퀀스 모두 생성

175
00:19:01,080 --> 00:19:07,560
산출. 그런 다음 문장 부분을 사용하여 토큰의 텍스트를 인코딩합니다. 그래서 실제로는

176
00:19:07,560 --> 00:19:18,120
그 일을 꽤 잘합니다. 그리고 제품이 감독 대상에 있는 방식과 유사하게,

177
00:19:18,120 --> 00:19:24,440
사전 평가 데이터 세트는 전이 학습 파이프라인의 중요한 구성 요소입니다. 그리고 나서 다음과 같이

178
00:19:24,440 --> 00:19:29,320
8Mark의 목표, 일반적으로 묻지 말아야 할 새로운 사전 훈련 데이터입니다.

179
00:19:30,280 --> 00:19:36,600
하지만 이 네 가지 T5는 다음과 같은 경우 높은 수준의 접근 방식을 사용합니다.

180
00:19:37,160 --> 00:19:42,120
밖으로 나가서 요리를 하고 모델에 로그인하세요. 그런 다음 다양한 부패 전략을 사용합니다.

181
00:19:42,760 --> 00:19:51,240
그리고 데이터의 손상 순서가 무엇인지 파악하려고 합니다. 이제 공연을 위해,

182
00:19:52,840 --> 00:19:57,240
이는 다양한 데이터 세트에 대한 사전 학습으로 인한 성능입니다. 그래서 첫 번째

183
00:19:57,880 --> 00:20:04,600
공개 이벤트는 새로운 C4 데이터베이스를 기반으로 합니다. 데이터 세트와 최고의 성능은 실제에서 나옵니다.

184
00:20:07,000 --> 00:20:10,920
뉴스는 데이터 세트와 비슷하지만 규모가 가장 크지는 않았습니다. 이제 이것은 놀라운 일입니다. 왜냐하면 우리는

185
00:20:12,360 --> 00:20:17,320
데이터가 클수록 최상의 성능을 제공할 것으로 예상하지만 그렇지 않습니다.

186
00:20:18,280 --> 00:20:24,440
가설은 실제 뉴스 데이터가 훨씬 더 무작위적이라는 것입니다.

187
00:20:25,080 --> 00:20:36,600
실제 생활을 훨씬 더 많이 반영합니다. 따라서 사전 훈련 손실에서 우리는 실제로

188
00:20:36,600 --> 00:20:41,320
여기에 있는 다이어그램을 보면 다음과 같은 단계를 거치게 됩니다.

189
00:20:41,320 --> 00:20:48,520
100보든 300보든, 걸음 수가 많을수록 훈련 손실이 적어지고,

190
00:20:49,640 --> 00:21:00,760
기본적으로 좋아집니다. 따라서 C4 데이터 세트의 사전 훈련 손실은 다음과 같습니다.

191
00:21:00,760 --> 00:21:05,240
4개의 연결 가능한 비유 데이터 버전입니다. 위 사람 상태의 사이즈

192
00:21:05,240 --> 00:21:12,600
각 데이터 세트에 보관합니다. 첫 번째는 64에서 4000 사이의 데이터 세트에 해당합니다.

193
00:21:12,600 --> 00:21:19,320
4k배, 훈련 손실이 더 작기 때문에 더 작은 데이터 세트를 사용합니다. 그래서

194
00:21:20,200 --> 00:21:24,040
데이터 세트가 클수록 데이터 손실도 커집니다.

195
00:21:24,040 --> 00:21:35,000
G5 스케일링. 따라서 G5 스케일링은

196
00:21:39,320 --> 00:21:49,720
모델을 실제로 유지하고 실행하기 위한 비용으로 일반 비용을 지출합니다. 그들은 크고,

197
00:21:49,720 --> 00:21:55,080
매우 비싸며 일반적으로 컴퓨팅 성능을 높이면 성능이 좋아집니다.

198
00:21:55,080 --> 00:22:03,400
성능. 따라서 신경망의 경우 일반적으로 전력이 클수록

199
00:22:03,400 --> 00:22:08,520
컴퓨팅이 많을수록 좋습니다. 마이크로소프트 보면 13달러 정도 투자했는데

200
00:22:08,520 --> 00:22:16,520
민감성으로 인해 OpenAI의 10억 달러에 해당하는 자금 중 상당 부분이 클라우드에 투자되었습니다.

201
00:22:16,600 --> 00:22:25,560
직접적인 현금 주입 대신 컴퓨팅 파워를 제공합니다. 그래서 G5에 대한 반성. 텍스트 대 텍스트입니다.

202
00:22:27,640 --> 00:22:31,880
정말 간단하고 높습니다. 그것은 그것이하는 일을하고 정말 잘합니다. 그것은 가지고있다

203
00:22:31,880 --> 00:22:36,920
사용자, 원래의 에콰도르 디코더, 개인 아키텍처는 정말 잘 작동합니다.

204
00:22:37,720 --> 00:22:43,640
그런 모델에서는 에콰도르보다 두 배나 많은 매개변수를 사용합니다.

205
00:22:43,640 --> 00:22:51,720
감독 대상. 그럼 이제 접촉 학습에 대해 이야기해 보겠습니다. 이제 대형 언어 방식으로

206
00:22:51,720 --> 00:22:57,240
모델은 내부에 제시된 작은 예시 세트에서 새로운 작업을 수행할 수 있다는 사실을 학습합니다.

207
00:22:57,240 --> 00:23:06,360
맥락과 아이디어는 실제로 그들이 비유를 통해 배울 수 있다는 것입니다. 그러니 갖고 싶은 것이 있다면

208
00:23:06,360 --> 00:23:11,320
가능한 모든 작업에 대해 매우 큰 데이터 세트가 있지만 실용적이지 않기 때문에 실제로 적용할 수 없습니다.

209
00:23:11,320 --> 00:23:19,320
당신은 그 모든 것을 가질 수 없습니다. 따라서 필요한 것은 모델이 학습할 수 있는 방법입니다.

210
00:23:19,320 --> 00:23:24,920
현재 하고 있는 일을 통해 이를 개선하는 방법을 알 수 있습니다. 그리고 그것이 원하는 방식은 실제로

211
00:23:25,480 --> 00:23:30,040
훈련 데이터에 심각한 상관관계가 있는지 파악하여

212
00:23:31,560 --> 00:23:36,600
그렇게. 이제 인간의 경우 대부분의 작업을 학습하기 위해 대규모 데이터 세트가 실제로 필요하지 않습니다. 그래서

213
00:23:36,600 --> 00:23:41,640
우리는 실제로 배울 수 있습니다. 그리고 실제로 메타 선형 또는 무공유 양도의 아이디어는 다음과 같습니다.

214
00:23:41,640 --> 00:23:49,640
특정 능력의 광범위한 기술 세트를 개발하여 이를 알아낼 수 있는 모델

215
00:23:49,640 --> 00:23:59,480
좋은 시간에 일을. 따라서 메타 학습에서 우리가 배우는 몇 가지 항목의 예를 들면,

216
00:24:00,200 --> 00:24:12,520
기본적으로 확률론적 경사하강법을 통해 학습하는 모델이 있습니다.

217
00:24:13,560 --> 00:24:18,680
생존 사전 훈련을 개발합니다. 폭넓은 기술을 개발할 수 있고 우리의 허가를 받을 수 있습니다.

218
00:24:18,680 --> 00:24:25,720
이 능력을 관심 시간으로 사용하여 새로운 작업의 데이터를 처리합니다. 정말 그렇군요. 그렇다면

219
00:24:25,720 --> 00:24:32,520
다이어그램에서 이것을 보세요. 학습은 왼쪽에서 오른쪽으로 진행됩니다.

220
00:24:32,520 --> 00:24:39,880
후유증을 통해 다양한 노력 범위를 가질 수 있습니다. 루프에서 수행 방법을 알고 있다면

221
00:24:39,880 --> 00:24:45,320
5 더하기 80 더하기 13, 7 더하기 3 더하기 9의 예를 보여주면, 알아내야 한다면

222
00:24:45,320 --> 00:24:53,640
1 더하기 0은 1과 같거나 3 더하기 4는 7과 같습니다. 이것이 바로 우리가 알고 있는 상황 내 학습입니다.

223
00:24:53,640 --> 00:25:00,600
여기를 참고로. 상황 내 학습에 더 적합한 다양한 언어가 있습니다. 그래서

224
00:25:02,760 --> 00:25:07,640
예를 들어, 사용된 작업 중 하나는 임의의 기호를 제거하는 방법을 알아내는 것입니다.

225
00:25:07,640 --> 00:25:14,440
그러면 상황에 맞는 정보를 효과적으로 활용하는 대규모 모델을 가질 수 있습니다.

226
00:25:14,440 --> 00:25:22,520
실제로 이곳을 보면 GA3에 대한 이야기를 하고 있는데,

227
00:25:22,520 --> 00:25:33,160
15억 개의 매개변수가 있는 매개변수에는 몇 번의 샷만 필요합니다. 실제로 촬영 횟수가 적고 프롬프트가 표시되지 않음

228
00:25:35,720 --> 00:25:43,960
심지어 잘 작동하는 경향이 있습니다. 비록 당신이 가지고 있지 않더라도 몇 번의 샷은 항상 것보다 약간 더 낫습니다.

229
00:25:43,960 --> 00:25:51,160
여기에 있는 원샷 접근 방식입니다. 프롬프트가 표시되지 않으면 결국 일치합니다.

230
00:25:52,120 --> 00:25:59,400
가져온 예가 없기 때문에 결국 몇 장의 샷도 일치합니다. 그럼 얘기해보자

231
00:25:59,400 --> 00:26:12,600
제가 이야기하고 싶은 마지막 모델 세트인 GP3입니다. 우리는 GP3가

232
00:26:12,600 --> 00:26:18,200
변환기 아키텍처를 기반으로 하는 이는 실제로 디코더 전용 신경망입니다. 임베딩 기능이 있습니다

233
00:26:18,200 --> 00:26:23,320
정말로 입력을 받을 수 있도록 말이죠. 모든 것을 네트워크에 전달하고 전달하지만

234
00:26:23,320 --> 00:26:30,440
기존 인코더 디코더 변환기 레이어에는 인코더가 없습니다. 그래서 목표는 정말

235
00:26:30,440 --> 00:26:35,720
GP3의 경우 이전의 모든 테스트를 바탕으로 다음 테스트를 예측할 수 있습니다. 그리고 그것은 매우,

236
00:26:35,720 --> 00:26:41,000
그것은 매우 큰 자동 회귀 언어입니다. 몇 가지 짧은 예측에 사용할 수 있습니다. 그러니까 너만

237
00:26:41,000 --> 00:26:47,400
소수의 데이터 세트에 대한 소유권을 주장해야 하며 무엇을 해야 할지 정확히 알고 있습니다. 그래서 도표를 보면

238
00:26:47,400 --> 00:26:55,800
여기에 있는 것은 T5에서 보여준 것과 매우 유사합니다. 유일한 차이점은

239
00:26:56,680 --> 00:27:01,240
인코더가 없습니다. 따라서 변압기 블록을 선택한 다음 변압기를 사용하면

240
00:27:01,240 --> 00:27:10,280
오른쪽 아래로 날아가는 블록에는 정규화 레이어가 있는 것을 볼 수 있습니다.

241
00:27:10,360 --> 00:27:16,600
다중 주의 머리를 사용하면 여러분이 가지고 있는 모델을 통과하게 되는데, 이는 실제로

242
00:27:17,400 --> 00:27:26,280
측정항목은 제외하고 마스킹, 소프트 드롭박스는 선형 레이어로 이동한 다음

243
00:27:26,920 --> 00:27:32,680
터널 레이어에서 모든 작업을 수행한 다음 나가서 다른 레이어를 전달합니다. 그래서 그것은,

244
00:27:33,800 --> 00:27:40,040
이것이 우리가 가지고 있는 구조입니다. 이제 GP3 훈련 레이어의 관점에서 보면,

245
00:27:40,040 --> 00:27:46,680
우리는 여기에서 볼 수 있습니다. 제게는 아주 짧은 것이 하나도 없고, 하나도 짧을 수 있습니다.

246
00:27:47,320 --> 00:27:55,080
또는 몇 가지 짧지만 다른 레이어인 GP3는 전통적인 방식을 사용합니다.

247
00:27:55,080 --> 00:28:02,760
GP3에서는 일반적으로 사용되지 않는 전통적인 미세 조정을 사용합니다. 그것은 기본적으로,

248
00:28:03,400 --> 00:28:07,000
즉, 모델 자체는 큰 패턴을 사용하여 이것의 반복적인 기울기로 훈련됩니다.

249
00:28:07,720 --> 00:28:09,960
데이터를 제어하는 ​​데 사용됩니다.

250
00:28:13,160 --> 00:28:17,000
교육 데이터 세트는 유사하며 일반적인 크롤링을 기반으로 합니다.

251
00:28:18,120 --> 00:28:25,560
주장하는 것의 1테라바이트를 사용하면 효과적인 것입니다. 그래서 내가 하는 훈련은

252
00:28:25,560 --> 00:28:30,520
GP3에는 소규모, 대규모, 중간 규모,

253
00:28:31,240 --> 00:28:37,000
가장 잘 알려진 것은 GP3일 수 있습니다. 50억 달러에 무엇이 들어있나요?

254
00:28:38,040 --> 00:28:43,480
거기에 매개변수가 있습니다. 따라서 거기에 있는 열의 경우 숫자 매개변수, 레이어 수,

255
00:28:43,480 --> 00:28:48,440
특정 계층에 얼마나 많은 뉴런이 있는지 보여주는 모델의 차원

256
00:28:48,440 --> 00:28:53,240
그런 다음 헤드 수, 헤드 크기, 배치 크기,

257
00:28:53,880 --> 00:28:57,080
이것이 데이터 처리에 대한 이야기가 시작된 방법입니다.

258
00:28:59,160 --> 00:29:03,800
그리고 여기 있는 모든 모델이 총 2,000억 개의 토큰에 대해 훈련되었다는 것을 알아냈습니다.

259
00:29:06,200 --> 00:29:12,520
컴퓨팅 소비 측면에서 볼 때 확장 법칙은 다음과 같습니다.

260
00:29:13,640 --> 00:29:22,360
훨씬 더 큰 모델에 대한 학습에서는 더 적은 토큰에 대한 것보다 더 많은 것을 사용한다는 것을 보여줍니다.

261
00:29:22,440 --> 00:29:31,080
CPU 용어. 따라서 GP3가 GP3보다 거의 3배, 즉 10배 더 크더라도

262
00:29:31,080 --> 00:29:37,960
Roberta, 다이어그램에서 보여드리겠습니다. 두 모델 모두 하루에 대략 58pF를 사용했습니다.

263
00:29:37,960 --> 00:29:42,840
훈련 중 하루 컴퓨팅의 초당 pF입니다.

264
00:29:43,000 --> 00:29:53,880
GP3는 더 크지만 3개, 30억 개의 매개변수를 갖고 있습니다.

265
00:29:53,880 --> 00:30:03,480
로베르타의 경우 3억 5500만 달러. 그래서 제가 여기서 마지막으로 이야기하고 싶은 것은 실제로 한계에 관한 것입니다.

266
00:30:03,480 --> 00:30:11,240
GP3에 대한 정보입니다. GP3는 훌륭하지만 여전히 제한이 없습니다. 그것은

267
00:30:15,640 --> 00:30:23,720
기능이 매우 훌륭하고 텍스트 합성 기능이 있으며 텍스트 품질이 높습니다.

268
00:30:23,720 --> 00:30:26,760
하지만 때로는 자기 자신이라면 그렇게 합니다.

269
00:30:27,480 --> 00:30:37,800
인간의 관점에서 본문을 실제로 이해하지 못하기 때문입니다.

270
00:30:37,800 --> 00:30:43,000
이 과정. 때로는 문서 수준에서 의미론적으로 반복되기도 합니다. 그것은 또한 할 수 있다

271
00:30:43,000 --> 00:30:49,640
때때로 충분히 크고 긴 구절에서 일관성을 잃습니다. 그리고 어떤 경우에는 그럴 수 있습니다.

272
00:30:49,640 --> 00:30:55,560
그 자체로 모순된다. 따라서 때로는 비동등한 합성이나 단락이 포함될 수 있습니다.

273
00:30:56,680 --> 00:31:00,520
예를 들어, 하늘색은 하늘색이고 태양은 빛나고 있는데, 아이는 우유를 마시지 않았습니다.

274
00:31:01,080 --> 00:31:06,040
그 문장은 디지털과는 아무 관련이 없습니다. 첫 번째 문장은 하늘색이고 태양이 빛나고,

275
00:31:06,040 --> 00:31:10,840
그렇군요. 그런데 아이가 우유를 마시지 않았다는 건 첫 번째 문장과 아무 관련이 없습니다.

276
00:31:11,800 --> 00:31:17,800
해석력이 부족하다는 문제도 있습니다. 그건 남다른 문제가 아니고,

277
00:31:18,600 --> 00:31:23,880
이는 모든 대규모 언어 모델에 공통적으로 나타나는 문제입니다.

278
00:31:25,480 --> 00:31:31,640
쉽게 이해되지 않거나 해석이 잘 안 되기 때문이다. 이제는 작동하지 않을 수도 있습니다

279
00:31:31,640 --> 00:31:38,680
새로운 입력에 기반을 두고 있기 때문에 주입된 내용에 따라 해결됩니다.

280
00:31:38,680 --> 00:31:43,080
이는 거래된 데이터의 편견을 유지합니다. 그리고 그것은 실제로 아는 것이 매우 중요합니다.

281
00:31:44,040 --> 00:31:49,400
모델의 주요 관심사 중 하나는

282
00:31:50,280 --> 00:31:56,200
실제 세계와 마찬가지로 대규모 언어 모델에 대한 편견. 그리고 우리가 큰 것을 신뢰하기 시작하면

283
00:31:56,200 --> 00:32:02,920
질문 없이 언어 모델을 사용하면 우리는 그 편견을 편견으로 만들고 있습니다.

284
00:32:03,640 --> 00:32:10,680
큰 언어 모델에 대한 고정관념. 그리고 그것은 사회의 특별한 관심사입니다.

285
00:32:11,240 --> 00:32:17,400
관점. 따라서 GP3에 너무 많이 의존하면 의존할 때 주의해야 합니다.

286
00:32:17,400 --> 00:32:24,520
GPT 및 대규모 언어 모델에 대한 작업이 전반적으로 계속 개선됨에 따라 아무 생각 없이

287
00:32:25,640 --> 00:32:29,160
내 믿음은 이러한 문제 중 일부가 미래에는 더 이상 존재하지 않을 수도 있다는 것입니다.

288
00:32:29,160 --> 00:32:34,200
결과적으로 사람들은 이러한 문제를 해결하는 방법을 알아낼 것입니다.

289
00:32:35,160 --> 00:32:40,440
아시다시피 일부 문제는 실제로 사전 훈련 중 샘플 효율성이 좋지 않기 때문에 발생합니다.

290
00:32:40,440 --> 00:32:45,400
대표 데이터가 없으면 대표 데이터가 있을 것이라는 보장도 없습니다.

291
00:32:45,400 --> 00:32:53,240
사회에 동등하게 봉사할 수 있는 대표 모델. 그리고 저는 데이터의 영속성에 대해 이야기한 적이 있습니다.

292
00:32:53,240 --> 00:33:00,520
그리고 증폭된 공생. 이제 또 다른 문제가 있는데, 이는 여전히 다국어입니다.

293
00:33:00,520 --> 00:33:07,160
대부분의 언어 모델 연구자는 영어로 수행됩니다. 그래서 신체의 대부분이 거기에 있어요.

294
00:33:07,160 --> 00:33:15,960
텍스트의 이미지와 지식체의 목적이 그것이다. 이제 내 말은, 우리가

295
00:33:15,960 --> 00:33:20,840
영어가 아닌 언어를 처리하려고 하면 지원이 충분하지 않고 충분하지 않습니다.

296
00:33:22,280 --> 00:33:29,560
데이터를 활용하면 좋은 결과를 얻을 수 있습니다. 감사합니다. 이제 Jerry에게 넘겨 계속 진행하겠습니다. 감사합니다.

297
00:33:30,760 --> 00:33:38,200
VPT-3는 프로그램을 생성할 수 있는 것으로 밝혀졌습니다.

298
00:33:38,200 --> 00:33:45,000
코드에 대해 명시적으로 교육을 받았습니다. 그러나 인간 평가 벤치마크로 평가해보면,

299
00:33:45,000 --> 00:33:51,400
나중에 논의하겠지만 합격률은 0에 가까웠습니다. 그리고 이것은 질문을 던집니다.

300
00:33:51,960 --> 00:33:58,120
프로그램 생성을 전문으로 하는 언어 모델이 있을 수 있나요?

301
00:33:58,760 --> 00:34:05,160
그리고 이를 위해 최근에는 언어로부터 프로그램을 생성하는 데 많은 진전이 있었습니다.

302
00:34:05,160 --> 00:34:11,800
모델. 그리고 그러한 모델 중 하나가 CodeX라고 불리며, 이는 코드에 대해 훈련된 특수 GPT 모델입니다.

303
00:34:13,160 --> 00:34:23,480
이제 생성 모델의 성능을 평가하는 방법에는 여러 가지가 있습니다. 그리고

304
00:34:24,440 --> 00:34:34,200
일반적으로 이를 평가하는 측정항목을 일치 기반 측정항목이라고 하며, 이는 출력을 비교합니다.

305
00:34:35,320 --> 00:34:45,240
참조 솔루션으로 이동합니다. 그러나 이는 코드를 생성하는 모델에서는 실행 가능하지 않을 수 있습니다.

306
00:34:45,240 --> 00:34:51,000
기능적으로 동일하지만 가능한 출력 프로그램이 너무 많을 수 있기 때문입니다.

307
00:34:51,000 --> 00:34:58,200
이 측정항목을 설명하기 위한 참조 솔루션에 연결하세요. 예를 들어, 기능적으로

308
00:34:58,840 --> 00:35:05,400
동등한 코드는 문제를 해결하기 위해 다른 방법을 사용할 수 있습니다. 예를 들어 정렬을 위해

309
00:35:05,400 --> 00:35:12,200
알고리즘을 구현하는 방법에는 여러 가지가 있습니다. 예를 들어

310
00:35:12,840 --> 00:35:22,840
딥 정렬, 병합 정렬, 퀵 정렬 등은 모두 동일한 결과를 얻지만 코드는 다음과 같습니다.

311
00:35:22,840 --> 00:35:31,480
완전히 다릅니다. 따라서 일치 기반 지표는 매우 높아야 함에도 불구하고 낮을 것입니다.

312
00:35:31,480 --> 00:35:37,480
그리고 실제로 블루 스코어라고 불리는 일치 기반 지표 중 하나가 다음과 같은 것으로 밝혀졌습니다.

313
00:35:37,480 --> 00:35:44,040
신뢰할 수 없는. 따라서 대안적인 방법은 기능적 정확성을 대신 사용하는 것입니다.

314
00:35:44,040 --> 00:35:51,080
성능을 측정하기 위해 테스트 케이스에서 출력 코드를 실행합니다. 그리고 바람직하다

315
00:35:52,680 --> 00:36:01,080
인간이 코드를 판단하는 방식과 비슷하기 때문입니다. 예를 들어, 코드는 일반적으로 다음을 기준으로 평가됩니다.

316
00:36:01,080 --> 00:36:09,880
예를 들어 코딩 콘테스트에서 솔루션 코드와 비교하는 대신 통과된 테스트 사례에 대해

317
00:36:09,880 --> 00:36:15,880
예를 들어 CS 과정의 코딩 과제 등이 있습니다.

318
00:36:18,360 --> 00:36:24,120
기능적 정확성을 평가하는 한 가지 방법은 K 메트릭에서 통과를 사용하는 것입니다.

319
00:36:24,120 --> 00:36:29,480
K개의 샘플 코드 중 적어도 하나가 생성되도록 문제의 비율을 계산합니다.

320
00:36:29,480 --> 00:36:35,960
해당 문제에 대한 모든 테스트 케이스를 통과했습니다. 그리고 이것은 K에서의 통과가 1 마이너스와 같다고 공식화될 수 있습니다.

321
00:36:35,960 --> 00:36:42,440
그런 다음 1에서 1 마이너스 패스를 K의 거듭제곱으로 묶습니다. 여기서 1에서 1 마이너스 패스는

322
00:36:42,440 --> 00:36:48,760
출력 코드가 하나 이상의 테스트 케이스에 실패할 확률. 그리고 이는 다음과 같이 해석될 수 있다.

323
00:36:48,760 --> 00:36:56,360
K개의 샘플 중에서 가장 좋은 것을 평가한 결과입니다. 이제 K 결과에서 합격을 직접 계산합니다.

324
00:36:56,360 --> 00:37:03,720
큰 차이로. 따라서 대신 K보다 크거나 같은 N개의 샘플 코드가 생성됩니다.

325
00:37:04,600 --> 00:37:11,400
그리고 과거 코드 C의 개수를 카운트한다. 그리고 추정기 1 마이너스 및 마이너스 C를 선택합니다.

326
00:37:11,400 --> 00:37:19,480
K를 N으로 나누어 K를 선택하면 각 문제별로 계산되어 평균이 계산됩니다. 이제 이 추정기는

327
00:37:19,480 --> 00:37:26,680
K개의 실패 코드를 선택하는 총 방법 수를 1에서 뺀 것으로 해석될 수 있으며,

328
00:37:27,320 --> 00:37:34,520
K 코드를 선택하는 총 방법 수로 나눕니다. 그리고

329
00:37:37,800 --> 00:37:43,880
이는 해당 추정기가 편견이 없다는 직관을 제공합니다. 그러나 이를 엄격하게 증명할 수 있습니다.

330
00:37:43,880 --> 00:37:51,320
C가 N번의 시행과 확률을 갖는 이항 분포로 분포된다는 점을 고려하여

331
00:37:51,320 --> 00:38:02,680
한 번에 합격하세요. 그런 다음 C에 대한 기대값을 합으로 확장하여 다음을 얻을 수 있습니다.

332
00:38:03,400 --> 00:38:13,480
위에 표시된 공식. 이제 해당 추정기가 편향되지 않더라도

333
00:38:14,760 --> 00:38:21,400
1에서의 통과에 대한 경험적 추정을 K에서의 통과에 대한 공식에 직접 연결하면 됩니다.

334
00:38:22,120 --> 00:38:32,440
특히 추정치가 K에서 통과하는 경우 편향된 추정기로 이어질 것입니다.

335
00:38:32,440 --> 00:38:39,720
취하면 오른쪽으로 더 치우치고 지수는 1보다 큽니다. 하지만 그 모드는

336
00:38:39,720 --> 00:38:50,200
여전히 K의 거듭제곱이므로 그 평균은 그보다 클 것입니다. 164개의 문제로 구성된 세트

337
00:38:50,200 --> 00:38:57,080
Human eval이라는 이름이 생성되었으며, 각각에는 함수 서명, 문서 문자열, 본문 및 평균이 포함되어 있습니다.

338
00:38:57,080 --> 00:39:04,200
7.7 단위 테스트 중. 그리고 이러한 내용은 다음에서 발견된 잠재적인 솔루션에 대한 교육을 피하기 위해 손으로 작성되었습니다.

339
00:39:04,200 --> 00:39:18,520
훈련 데이터 세트. 이제 훈련에는 최대 120억 개의 GPT 모델을 미세 조정하는 작업이 포함됩니다.

340
00:39:18,600 --> 00:39:27,800
코드에 대한 매개 변수를 지정하고 GitHub에 있는 고유한 Python 파일의 159GB 데이터 세트에 대해 교육합니다.

341
00:39:28,520 --> 00:39:37,880
그리고 학습률은 175단계의 해당 GPT 모델과 동일하게 사용되었습니다.

342
00:39:37,880 --> 00:39:45,160
선형 상처 및 코사인 학습 붕괴를 통해 총 1000억 개의 토큰에 대해 교육을 받았습니다.

343
00:39:45,720 --> 00:39:54,920
Atom은 가중치 감소가 있는 최적화 프로그램을 선택합니다. 그리고 그 결과, 교차엔트로피는 다음과 같은 것으로 나타났다.

344
00:39:54,920 --> 00:40:05,320
보류된 검증 세트의 테스트 손실은 원활한 멱함수 법칙을 형성합니다. 그리고 하나의 샘플만 추출할 수 있는 경우

345
00:40:05,320 --> 00:40:13,000
평가 결과, 평가할 샘플을 무작위로 선택하는 것보다

346
00:40:13,080 --> 00:40:21,640
더 나은 성능을 발휘하므로 평균 로그 확률이 ​​가장 높은 것을 선택하십시오. 하지만 다음과 같은 것을 선택하면

347
00:40:21,640 --> 00:40:30,520
가장 높은 합계 로그 확률은 무작위 선택보다 성능이 약간 나쁩니다. 그리고 줄거리

348
00:40:30,520 --> 00:40:41,720
왼쪽에는 K 대 K에서의 통과와 온도가 표시됩니다. 그리고 샘플링을 한 것으로 밝혀졌습니다.

349
00:40:41,720 --> 00:40:48,360
K에서 통과를 최대화하는 온도는 샘플 K의 수에 따라 증가합니다. 그리고 이는

350
00:40:48,360 --> 00:40:55,240
K에서의 통과는 하나의 샘플이 통과하고 샘플링 온도를 제어하는지에만 관심이 있기 때문입니다.

351
00:40:55,240 --> 00:41:03,800
생성 모델의 맥락에서 샘플링 시 무작위성은 다음을 생성합니다.

352
00:41:03,800 --> 00:41:13,240
정규화되지 않은 토큰 점수인 로짓의 소프트맥스 분포에서 나온 토큰

353
00:41:13,240 --> 00:41:26,680
온도로 나누어집니다. 따라서 이 경우 K에서 가장 높은 통과는 최상의 온도입니다.

354
00:41:26,680 --> 00:41:36,760
1 통과의 경우 0.2이고 100 통과의 최고 값은 0.8입니다. 그리고 이것들은 다음의 음모에 사용되었습니다.

355
00:41:36,760 --> 00:41:44,040
오른쪽 플롯에 표시된 대로 합격률과 모델 크기를 플롯할 수 있습니다.

356
00:41:44,040 --> 00:41:58,760
이제 Codex는 GPT 모델과 가장 큰 무료 모델을 포함한 다른 모델과 비교되었습니다.

357
00:41:58,760 --> 00:42:07,480
탭 9. 그리고 이는 0.2의 온도에서 인간 평가로 모든 항목을 평가하여 수행되었습니다.

358
00:42:07,560 --> 00:42:15,640
0.4 또는 0.8. 그리고 이 세 가지 온도 중에서 가장 좋은 점수를 받은 온도가 선택되었습니다.

359
00:42:18,840 --> 00:42:29,720
그러다가 GPT-Neal과 GPT-J만이 합격률을 가진 유일한 GPT 모델이라는 것을 알게 되었습니다.

360
00:42:29,800 --> 00:42:38,360
그것은 0에 가깝지 않습니다. 그리고 이 모델은 Codex와 유사하며 더미에서 훈련되었습니다.

361
00:42:38,360 --> 00:42:47,880
8% GitHub 코드가 포함된 데이터 세트입니다. 그리고 왼쪽 표와 같이,

362
00:42:48,600 --> 00:42:59,240
Codex 300M L은 매개변수가 20배 적음에도 불구하고 GPT-J 6B를 수행합니다.

363
00:43:02,440 --> 00:43:09,000
이제 자연어를 데이터 세트의 코드로 번역하는 것과 관련 없는 코드가 있을 수 있습니다.

364
00:43:09,960 --> 00:43:17,560
예를 들어 스크립트나 클래스 구현 등이 있을 수 있습니다. 그리고 이것들은 아마도

365
00:43:17,560 --> 00:43:26,040
성능을 낮추세요. 그래서 관련 코드에서 일련의 훈련 문제를 얻었습니다.

366
00:43:26,040 --> 00:43:32,360
두 가지 소스, 경쟁력 있는 프로그래밍 웹사이트와 지속적인 통합을 갖춘 저장소입니다.

367
00:43:33,240 --> 00:43:42,600
그리고 이것들은 CodexS라는 버전을 만들기 위해 Codex에서 감독된 미세 조정을 수행하는 데 사용되었습니다.

368
00:43:43,560 --> 00:43:54,600
성능이 향상된 것으로 나타났습니다. 그리고 조금 더 높게 선호하는 것으로 나타났습니다.

369
00:43:54,600 --> 00:44:05,480
최소한 K가 1보다 큰 경우 Codex보다 샘플링 온도가 낮습니다.

370
00:44:06,440 --> 00:44:15,720
분포가 더 좁습니다. 또한 1회 통과 시 Codex를 6.5% 능가하는 것으로 나타났습니다.

371
00:44:15,720 --> 00:44:25,640
100에서 합격 시 15.1%. 이는 왼쪽 그림에 표시됩니다. 이제 오른쪽 플롯의 경우,

372
00:44:26,360 --> 00:44:35,640
CodexS도 Codex보다 성능이 훨씬 뛰어난 것으로 나타났습니다.

373
00:44:36,680 --> 00:44:46,200
단일 샘플만 평가할 수 있는 경우. 그리고 무작위 표본이 선택되거나 평균이

374
00:44:46,200 --> 00:44:56,040
로그가 선택되고 이론적 합격률도 파란색 덩굴로 표시됩니다.

375
00:44:58,600 --> 00:45:06,040
지금까지 CodexX, Codex가 문서 문자열에서 코드를 생성하는 방법에 대해 논의했습니다.

376
00:45:06,040 --> 00:45:13,880
하지만 그 반대는 어떻습니까? 그리고 이를 위해 CodexD가 만들어졌고, 이는 CodexD의 버전입니다.

377
00:45:13,880 --> 00:45:21,960
코드에서 문서 문자열을 생성하는 CodexX입니다. 그리고 각 훈련 문제에는 다음 함수가 포함되어 있습니다.

378
00:45:21,960 --> 00:45:29,080
서명, 참조 솔루션 및 문서 문자열. 그리고 기능적 정확성을 측정할 방법이 없습니다.

379
00:45:29,080 --> 00:45:41,000
문서 문자열의 경우. 그래서 대신 그들은 1,640개의 문제 각각에 대해 10개의 샘플을 수동으로 채점했습니다.

380
00:45:41,560 --> 00:45:46,760
시간이 오래 걸리기 때문에 각 문제에 대해 10개의 샘플만 채점되었습니다.

381
00:45:47,320 --> 00:45:59,720
그리고 1번 통과와 10번 통과가 각각 20.3%, 46.5%인 것으로 나타났다.

382
00:45:59,720 --> 00:46:08,600
이는 각각 CodexS보다 약간 낮습니다. Codex의 일부 제한 사항

383
00:46:08,600 --> 00:46:17,000
훈련 데이터가 수백 개에 달하므로 훈련하기에 충분하지 않거나 효율적인 샘플이 포함되어 있지 않습니다.

384
00:46:17,000 --> 00:46:25,160
수백만 줄의 코드. 또한 문서 문자열 길이에 따라 성능이 기하급수적으로 감소합니다.

385
00:46:25,800 --> 00:46:31,800
따라서 결정론적으로 13개의 빌딩 블록을 조립하여 생성된 합성 문제는 다음과 같습니다.

386
00:46:31,800 --> 00:46:40,920
문자열 입력을 수정합니다. 예를 들어 소문자로 변환하거나 세 번째 문자를 모두 제거하세요.

387
00:46:42,680 --> 00:46:54,840
이것들은 만들어졌고, 이 건물의 체인 구성 요소 수가 많아지면

388
00:46:54,840 --> 00:47:05,880
블록이 증가하면 플롯에 표시된 대로 통과율이 감소합니다. 그리고 마지막으로 실수를 할 수도 있습니다

389
00:47:05,880 --> 00:47:13,640
특히 변수가 많은 경우 변수를 작업에 바인딩합니다. 다음 모델은 제가

390
00:47:13,640 --> 00:47:22,040
지금 논의 중인 것은 Llama2입니다. 이제 Llama2는 수십억 달러 규모의 사전 교육을 받고 미세 조정된 LLM 제품군입니다.

391
00:47:22,040 --> 00:47:29,720
매개변수. 그리고 다른 오픈 소스 LLM보다 성능이 뛰어나며 일부 폐쇄 소스와 동등할 수 있습니다.

392
00:47:29,720 --> 00:47:40,200
LLM. 이제 사전 훈련 아키텍처와 하이퍼베너는 대부분 Llama1에서 채택되었습니다.

393
00:47:40,200 --> 00:47:48,760
예를 들어, 재정규화가 적용된 표준 변환기 아키텍처가 있습니다.

394
00:47:49,720 --> 00:47:56,120
출력 대신 각 하위 계층의 입력이 정규화되었습니다. 그리고 이는 개선되는 것으로 나타났습니다.

395
00:47:56,120 --> 00:48:07,720
훈련 안정성은 GPT3에서 영감을 얻었습니다. 그리고 swiglu 활성화 함수도,

396
00:48:07,720 --> 00:48:16,440
swish 함수를 사용한 것입니다. 그리고 더 많은 유연성과

397
00:48:16,440 --> 00:48:23,240
피드 포워드 레이어의 표현력이 향상되어 트랜스포머의 성능이 향상됩니다.

398
00:48:23,240 --> 00:48:30,680
Rilu와 같은 표준 활성화 모델과 비교한 모델입니다. 그리고 마지막으로 절대 위치 대신

399
00:48:30,680 --> 00:48:39,720
임베딩에서는 회전식 위치 임베딩을 사용합니다. 이는 단순히 회전 행렬을 사용하는 대신

400
00:48:40,680 --> 00:48:48,440
위치 임베딩에 대한 각 토큰의 벡터입니다. 그리고 이것은 상대적인 위치를 보여줍니다.

401
00:48:48,440 --> 00:48:54,360
토큰을 사용하고 모델이 종속성을 캡처할 수 있도록 합니다. 그리고 이것은 성능을 향상시킬 수 있습니다

402
00:48:54,360 --> 00:48:58,120
문장에서 단어의 위치를 ​​바꾸면 의미가 바뀔 수 있기 때문에

403
00:48:58,280 --> 00:49:15,160
특히 그들의 상대적 위치. 이제 70억, 130억, 34억, 700억 개의 매개변수가 있습니다.

404
00:49:16,200 --> 00:49:23,960
모델군에 사용되었습니다. 그리고 컨텍스트 길이는 텍스트의 양입니다.

405
00:49:24,040 --> 00:49:34,120
한 번에 처리할 수 있으며 Lama 1에서 두 배로 늘어났습니다. 이제 4K입니다. 그리고 학습률은

406
00:49:35,720 --> 00:49:45,560
소규모 모델의 경우 0.0003, 그룹 쿼리 주의가 있는 대규모 모델의 경우 0.00015를 사용했습니다.

407
00:49:45,640 --> 00:49:54,440
이는 대형 모델의 성능을 안정화하기 위한 방법입니다.

408
00:49:55,240 --> 00:50:03,720
또한 코사인 학습률 일정과 함께 가중치 감소 기능이 있는 원자 최적화 프로그램을 사용하여 훈련되었습니다.

409
00:50:03,720 --> 00:50:10,120
Lama 1보다 40% 더 많은 2조 토큰의 데이터를 학습했습니다.

410
00:50:10,520 --> 00:50:21,800
이제 Lama 1 및 2 기본 모델은 다음과 같은 다른 오픈 소스 모델과 함께 제공됩니다.

411
00:50:23,080 --> 00:50:32,760
MPT와 Falcon은 비교를 위해 여러 벤치마크에서 평가되었습니다. 따라서 코드의 경우

412
00:50:32,760 --> 00:50:40,120
인간 EFL의 평균 합격 점수와 MBPP라는 또 다른 데이터 세트가 보고됩니다.

413
00:50:40,840 --> 00:50:45,880
그리고 상식추론, 세계지식, 독해, 독해, 수학을 위해서는

414
00:50:46,600 --> 00:50:53,560
다양한 방법의 평균 점수가 보고되었습니다. 그리고 마지막으로,

415
00:50:55,160 --> 00:51:01,960
다양한 작업을 평가하는 대규모 멀티태스킹 언어 이해,

416
00:51:02,840 --> 00:51:12,040
다양한 작업을 평가하는 빅 벤치 작업의 하위 집합을 평가하는 빅 벤치 하드

417
00:51:12,040 --> 00:51:17,160
현재 언어 모델의 기능을 넘어서는 것으로 밝혀진 작업입니다.

418
00:51:18,920 --> 00:51:27,080
또한, 다음을 기반으로 모델을 평가하는 인공 일반 지능 평가도 있습니다.

419
00:51:27,080 --> 00:51:32,440
인간 중심 표준화 시험에서의 성적도 보고되었습니다.

420
00:51:34,840 --> 00:51:45,560
그리고 이 표에는 앞서 논의한 결과가 요약되어 있습니다. 그리고 나타난 바와 같이,

421
00:51:45,560 --> 00:51:54,600
일반적으로 라마 27억이 가장 성능이 좋습니다.

422
00:51:57,960 --> 00:52:07,400
이제 Lama 2.Chat은 정렬 기술을 통해 감독된 미세 조정 기능을 갖춘 Lama 2 버전입니다.

423
00:52:08,040 --> 00:52:17,080
공개적으로 사용 가능한 명령어 미세 조정 데이터를 사용하여 미세 조정을 감독합니다.

424
00:52:18,120 --> 00:52:27,560
적은 양, 즉 수백만 개가 아닌 수천 개를 사용하므로 품질이 필요한 전부라는 사실이 밝혀졌습니다.

425
00:52:27,560 --> 00:52:36,040
그러나 더 높은 품질의 사례에서는 결과가 개선된 것으로 나타났습니다. 그리고 RLHF,

426
00:52:36,120 --> 00:52:41,560
인간의 피드백을 이용한 강화학습인 Fine-tuning을 거쳐 적용됩니다.

427
00:52:41,560 --> 00:52:47,560
모델은 사용자의 의도를 이해하여 인간의 선호도에 맞춰 모델을 추가로 조정할 수 있습니다.

428
00:52:49,880 --> 00:52:57,400
이제 인간의 피드백을 통해 얻은 인간의 선호도 데이터를 수집하고

429
00:52:58,680 --> 00:53:05,720
수집된 프롬프트의 다양성을 높이기 위해 이진 비교 프로토콜을 사용하여 수집했습니다.

430
00:53:05,720 --> 00:53:11,080
피드백. 따라서 주석자는 모델에 대한 프롬프트를 작성한 다음 각 프롬프트에 대해 다음을 작성합니다.

431
00:53:11,080 --> 00:53:17,080
그들은 모델의 다양한 변형에서 두 가지 응답 중 하나를 선택합니다. 예를 들어,

432
00:53:17,080 --> 00:53:26,840
제공된 기준에 따라 온도를 다르게 설정합니다. 이 경우 건강 상태 또는

433
00:53:26,840 --> 00:53:32,840
안전을 고려한 다음 선택한 응답이 얼마나 나은지 4점 척도로 순위를 매깁니다.

434
00:53:33,080 --> 00:53:45,720
그리고 방금 말씀드린 것처럼 건강과 안전을 우선으로 두었습니다.

435
00:53:46,440 --> 00:53:54,200
이 데이터는 시간이 지남에 따라 일괄적으로 수신되었으므로 시간이 지남에 따라 보상 모델이 개선되었습니다.

436
00:53:54,760 --> 00:54:01,960
이제 인간의 선호도 데이터를 사용하여 보상 모델을 훈련시켰습니다.

437
00:54:03,800 --> 00:54:10,040
내부 텍스트 분포를 변경하여 기본 설정의 패턴을 학습할 수 있도록

438
00:54:10,040 --> 00:54:17,320
기본 모델을 기반으로 모델의 품질 예측을 바탕으로 점수를 출력합니다.

439
00:54:17,320 --> 00:54:24,200
즉각적이고 모델적인 반응이 주어진 인간의 선호도에 대해, 이 점수는 다음에 대한 보상으로 사용되었습니다.

440
00:54:24,840 --> 00:54:34,920
RLHF 및 보상 모델은 다음과 같은 상황을 피하기 위해 사전 훈련된 모델에서 초기화되었습니다.

441
00:54:34,920 --> 00:54:45,880
모델은 결국 환각을 선호하게 됩니다. 즉, 잘못된 정보를 부정확하거나 오해하게 만드는 것입니다.

442
00:54:45,880 --> 00:54:54,360
동일한 아키텍처와 하이퍼파라미터도 사용되었지만

443
00:54:54,360 --> 00:55:00,760
보상이 실제이기 때문에 분류 헤드 대신 보상을 출력하기 위한 회귀 헤드

444
00:55:00,760 --> 00:55:11,320
숫자와 두 개의 RMS가 사용되었습니다. 하나는 건강을 위한 것이고 다른 하나는 안전을 위한 것입니다.

445
00:55:11,320 --> 00:55:22,040
하나 대신 두 개가 사용되는 이유에 대해 논의하므로 마진 구성 요소가 있는 이진 순위 손실이 발생했습니다.

446
00:55:22,040 --> 00:55:33,080
여기에서 마진 구성요소는 선호도 등급의 함수입니다.

447
00:55:33,080 --> 00:55:39,960
각 보상 모델은 보상 모델이 더 다양한 항목에 대해 더 뚜렷한 점수를 제공하는 데 도움이 됩니다.

448
00:55:39,960 --> 00:55:46,840
오픈소스와의 결합으로 선호도 데이터가 증가하였고,

449
00:55:49,720 --> 00:55:57,480
기본 모델과 동일한 매개변수로 훈련되었지만 이전과 마찬가지로 한 시대만 실행했습니다.

450
00:55:58,280 --> 00:56:08,040
연구에 따르면 하나 이상의 에포크가 실행되면 과적합될 수 있으며 약간 더 낮을 수도 있습니다.

451
00:56:08,120 --> 00:56:22,760
학습률을 사용하였고 채팅 보상 모델링 결과는 다음과 같습니다.

452
00:56:22,760 --> 00:56:33,800
여러 인간 선호도에 따라 STEAM SHP XL 개방형 도우미 및 GPT-4를 수행하는 데 도움이 되는 모델이 발견되었습니다.

453
00:56:33,800 --> 00:56:44,040
벤치마크, 구체적으로 유용성 보상 모델과 안전 보상 모델

454
00:56:44,040 --> 00:56:53,080
예를 들어 유용성 보상 모델은 자신의 영역에서 가장 잘 수행되었습니다.

455
00:56:53,640 --> 00:57:02,840
메타에 도움이 되는 데이터, 메타에 무해한 데이터에서 가장 좋은 성능을 발휘하는 안전 보상 모델 등

456
00:57:03,480 --> 00:57:10,600
때로는 충돌이 발생할 수 있으므로 이는 의미가 있습니다. 예를 들어 사용자가

457
00:57:12,040 --> 00:57:21,800
유대감을 형성하는 방법을 묻는 질문에 도움이 되는 답변을 받는 것은 불가능합니다.

458
00:57:21,800 --> 00:57:31,240
동시에 안전하며 두 가지 목표를 모두 갖춘 하나의 보상 모델을 최적화하면

459
00:57:31,240 --> 00:57:35,800
이 경우 모델이 혼란스러워서 제대로 수행되지 않습니다.

460
00:57:40,280 --> 00:57:48,760
이제 더 많은 인간 선호도 데이터 배치가 추가됨에 따라 RLHF의 연속 버전이 훈련되었습니다.

461
00:57:48,760 --> 00:58:00,840
수신되었으며 v1에서 v5로 라벨이 지정되었으며 RLHF 미세 조정은 두 가지 알고리즘으로 탐색되었습니다.

462
00:58:00,840 --> 00:58:09,000
첫 번째는 거부 샘플링 미세 조정이므로 각 반복마다 k개의 샘플이 생성됩니다.

463
00:58:09,000 --> 00:58:15,400
모델을 선택한 다음 보상 모델을 사용하여 가장 좋은 샘플을 선택했습니다.

464
00:58:15,400 --> 00:58:23,800
다음 반복을 위해 모델을 조정하기 위한 그래디언트 업데이트에 사용되었으며 이는 다음에만 적용되었습니다.

465
00:58:23,800 --> 00:58:32,520
7b 모델은 7b 모델의 거부 샘플 데이터를 바탕으로 더 작은 모델을 미세 조정한 반면,

466
00:58:33,320 --> 00:58:40,120
이후 버전에는 이전 모델뿐만 아니라 모든 이전 모델의 최고의 샘플이 포함되어 있습니다.

467
00:58:40,120 --> 00:58:46,920
예를 들어 v3는 v2의 샘플만 사용하여 훈련되었기 때문에

468
00:58:46,920 --> 00:58:53,640
특정 작업에서 성능이 저하되었으며, 각 작업마다 샘플링 온도도 조정되었습니다.

469
00:58:53,640 --> 00:58:59,320
반복을 통해 최적의 값이 크게 변경되었기 때문입니다.

470
00:59:01,800 --> 00:59:08,840
두 번째 방법은 강화학습의 표준 방법인 근접 정책(Proximal Policy)입니다.

471
00:59:08,840 --> 00:59:18,920
정책을 업데이트하기 위해 정책 그라디언트 업데이트를 사용하는 정책 방법에 관한 최적화,

472
00:59:19,720 --> 00:59:26,440
보상 함수의 추정치로 보상 모델을 사용하고, 언어 모델을 사용합니다.

473
00:59:26,440 --> 00:59:33,240
최적화할 정책으로 선정되었으며, 다음의 프롬프트를 샘플링하여 정책을 반복적으로 개선했습니다.

474
00:59:33,240 --> 00:59:43,960
정책의 데이터 세트 및 세대, 정책, 근접 정책 최적화가 적용됩니다.

475
00:59:46,680 --> 00:59:54,760
고스트 어텐션(Ghost Attention) 또는 GAT라는 논문의 새로운 기술이 도입되었습니다.

476
00:59:55,720 --> 01:00:01,320
여러 차례에 걸쳐 대화 흐름을 제어하는 ​​데 도움이 됩니다.

477
01:00:02,920 --> 01:00:09,240
따라서 처음에 RLHF 모델은 몇 차례 턴 후에 대화의 지시 사항을 잊어버리는 경우가 있습니다.

478
01:00:09,960 --> 01:00:16,600
예를 들어, 첫 번째 메시지가 이모티콘만으로 답변하는 것이라면,

479
01:00:17,320 --> 01:00:26,600
모델은 처음 몇 개의 프롬프트에서는 이를 수행할 수 있지만 나중에는 이를 잊어버리고 다음과 같이 응답합니다.

480
01:00:27,160 --> 01:00:39,960
실제 단어이며, 이 문제는 GAT로 수정될 수 있으며 RLHF 버전 3 이후에 적용되었습니다.

481
01:00:40,760 --> 01:00:47,880
이 방법은 명령을 사용자 메시지에 종합적으로 연결하여 작동합니다.

482
01:00:47,880 --> 01:00:57,160
일단 정의되면 문맥에 따라 최대 20회까지 일관성이 있는 것으로 확인되었습니다.

483
01:00:57,160 --> 01:01:07,960
길이. 이제 각 프롬프트와 유용성과 안전성에 대한 테스트 세트에 대해

484
01:01:08,680 --> 01:01:15,720
3명의 주석자가 7점 척도로 품질을 판단하며, 아래 그림은 그 품질을 보여줍니다.

485
01:01:15,720 --> 01:01:24,360
감독 중 Lama 2 채팅의 다양한 버전에 대해 GPT-4에 대한 회색 백분율

486
01:01:24,360 --> 01:01:34,040
미세 조정 및 RLHF. 따라서 왼쪽의 플롯은 메타 보상 모델을 사용할 때

487
01:01:34,040 --> 01:01:43,000
RLHF v3 및 이후 버전 L이 무해성과 유용성에 대해 GPT-4를 수행한다고 판단합니다.

488
01:01:43,640 --> 01:01:49,080
다만 라마2와 같은 회사에서 심사를 했기 때문에 불공평할 수도 있지만,

489
01:01:49,800 --> 01:02:03,080
그래서 오른쪽의 플롯은 GPT-4 심사위원을 사용했을 때의 결과를 보여주며,

490
01:02:03,080 --> 01:02:14,120
여전히 RLHF v5는 근위 정책 최적화가 없고 L이 GPT-4를 수행합니다.

491
01:02:14,120 --> 01:02:22,920
무해성과 유용성에 대해. 이제 Lama 2 채팅도 다른 여러 모델과 비교되었습니다.

492
01:02:22,920 --> 01:02:29,000
4,000개 이상의 다양한 프롬프트와 다중 턴 프롬프트를 통해 인간 평가에 대해

493
01:02:29,000 --> 01:02:35,240
Lama 2는 GPT와 채팅하고 각 프롬프트에 대해 3명의 주석 작성자가 얼마나 더 나은지 평가합니다.

494
01:02:35,240 --> 01:02:43,880
7점 척도에서 한 모델이 다른 모델보다 더 나쁩니다. 이는 아래 그래프에 나와 있습니다.

495
01:02:44,520 --> 01:02:57,160
그리고 여기에 표시된 다른 모델과 비교했을 때 Lama 2 채팅이 더 높은 것으로 나타났습니다.

496
01:02:57,160 --> 01:03:08,920
승률과 손실률. 이제 안전을 위해 사전 훈련 중에 유해한 데이터가 필터링되었으며

497
01:03:08,920 --> 01:03:17,400
미세조정을 하였으며, 미세조정 전과 비교하여 라마2 채팅의 진실성이 크게 향상되었습니다.

498
01:03:17,400 --> 01:03:30,040
진실한 QA 및 독성에 대한 점수가 향상되었으며 독성에 대한 점수도 향상되었습니다.

499
01:03:30,040 --> 01:03:38,360
또한 편향이 낮아진 것을 보여주고 공격자에 대한 견고성을 테스트하기 위해 개선되었습니다.

500
01:03:38,360 --> 01:03:50,280
다양한 인구통계와 분야의 300명 이상의 사람들이 레드팀을 이루었고,

501
01:03:51,080 --> 01:03:58,680
시뮬레이션된 프롬프트를 통해 다양한 불안전한 상황에서 모델을 조사했습니다.

502
01:03:58,680 --> 01:04:03,480
이러한 통찰력은 미세 조정 및 피드백 훈련에 사용되어

503
01:04:03,480 --> 01:04:10,280
응답을 위반합니다. 예를 들어 7B 모델의 경우 속도가 4배 낮아졌습니다.

504
01:04:11,960 --> 01:04:22,200
전반적으로 인간 기반의 유용성과 안전성 측면에서 다른 많은 모델보다 뛰어납니다.

505
01:04:22,200 --> 01:04:29,320
평가하는 학년. 그러나 제한 사항은 이러한 안전 튜닝 접근 방식이 대부분 수정되었지만

506
01:04:29,320 --> 01:04:36,600
안전 문제는 어떤 경우에는 너무 멀리 진행되어 모델이 지나치게 조심스러워질 수 있습니다.

507
01:04:36,600 --> 01:04:43,320
거짓 거부가 발생하지만 이는 유용성 데이터에서 0.05%의 확률로 발생합니다.

508
01:04:45,320 --> 01:04:53,080
다음으로 소개해드릴 모델은 전문가들의 혼합훈련입니다. 이제 혼합 드릴을 8번 7B

509
01:04:53,080 --> 01:04:57,080
뛰어난 성능을 발휘할 수 있는 전문가 모델의 희소 혼합 드릴입니다.

510
01:04:57,080 --> 01:05:06,840
수학, 수학, 콜드 생성 및 다국어 작업과 같은 대부분의 벤치마크에서 mama270B 및 GPT 3.5,

511
01:05:07,560 --> 01:05:17,320
모델은 기본적으로 각 토큰에 대한 매개변수의 하위 집합을 사용하고 토큰의 크기를 변경할 수 있습니다.

512
01:05:18,280 --> 01:05:27,560
추론 속도를 높이거나 처리량을 높이기 위한 활성 매개변수

513
01:05:28,440 --> 01:05:34,920
이 이미지는 나중에 논의할 전문가 혼합 레이어를 보여줍니다.

514
01:05:35,880 --> 01:05:49,000
그러니까 미스트랄 7B는 마마와 비슷한 구조를 가지고 있는 믹스드 드릴의 초기 버전인데,

515
01:05:49,960 --> 01:05:58,520
또한 각 토큰이 처리할 수 있는 토큰의 양을 제한하는 슬라이딩 윈도우 어텐션도 있습니다.

516
01:05:58,520 --> 01:06:07,000
창 크기 W로 계산 및 메모리를 절약하며 이는 다른 두 가지로 가능합니다.

517
01:06:07,000 --> 01:06:15,640
롤링 버퍼 캐시, 미리 채우기 및 청킹이라는 방법이 사용되었으며 이는 아래 이미지에 설명되어 있습니다.

518
01:06:15,800 --> 01:06:30,200
이제 혼합 드릴도 Mistral과 동일한 아키텍처와 매개변수를 갖습니다.

519
01:06:30,200 --> 01:06:38,920
컨텍스트 길이는 Mistral에서 32K로 4배 증가하고 피드 포워드 블록은 다음으로 대체됩니다.

520
01:06:38,920 --> 01:06:46,440
전문가 레이어와 전문가의 8가지 혼합 드릴은 개별 피드포워드 네트워크입니다.

521
01:06:47,960 --> 01:06:56,040
일반적으로 전문가의 혼합 훈련은 전문가의 최고 제품 중 일부입니다.

522
01:06:56,040 --> 01:06:59,080
각 전문가의 눈에 대한 게이팅 네트워크입니다.

523
01:07:01,800 --> 01:07:07,880
따라서 Mistral의 게이팅 이벤트 네트워크는 선형 레이어의 최대 K개 로짓을 제거합니다.

524
01:07:09,880 --> 01:07:15,800
그러면 총 희소 매개변수 수는 활성화된 동안 플레어 수에 따라 증가할 수 있습니다.

525
01:07:15,800 --> 01:07:21,960
토큰 처리에 사용되는 매개변수 수는 K와 혼합 드릴에서만 증가합니다.

526
01:07:21,960 --> 01:07:30,200
사용된 전문가는 swiglu 활성화 함수이고 K는 2이므로 이는 다음과 같이 설명됩니다.

527
01:07:31,080 --> 01:07:42,360
라우터가 입력을 받아 8개 중 2개에만 전달하는 이미지가 여기에 나와 있습니다.

528
01:07:42,360 --> 01:07:53,400
가장 높은 로짓을 가진 전문가이므로 활성 매개변수는

529
01:07:53,400 --> 01:07:59,240
이 두 전문가와 그 결과는 그 두 전문가에 의해서만 좌우될 것입니다.

530
01:08:00,520 --> 01:08:08,280
이제 혼합 드릴은 다음과 유사한 여러 벤치마크에서 평가하여 라마와 비교되었습니다.

531
01:08:08,280 --> 01:08:16,120
Lama2의 논문에서 결과는 아래 표와 컬럼에 나와 있습니다.

532
01:08:16,120 --> 01:08:26,600
아크 챌린지까지의 heliswag는 상식 추론과 자연스러운 질문을 나타냅니다.

533
01:08:26,600 --> 01:08:35,160
퀴즈 qa는 인간과 동등한 세계 지식을 나타냅니다. mvpp는 코드를 나타내고 마지막으로 수학 및 gsmak를 나타냅니다.

534
01:08:35,720 --> 01:08:46,760
수학을 나타내며 이 표에서는 혼합 드릴아웃이 Lama2 70b를 수행함을 보여줍니다.

535
01:08:48,200 --> 01:08:59,320
전반적으로 활성 매개변수가 5배 이상 적음에도 불구하고 Lama2보다 성능이 뛰어납니다.

536
01:08:59,960 --> 01:09:09,800
음 그리고 이전 버전에 비해 혼합 드릴에는 혼합 드릴이 있었습니다.

537
01:09:10,440 --> 01:09:16,120
다국어 데이터가 크게 샘플링되어 다국어 데이터에서 좋은 성능을 발휘할 수 있었습니다.

538
01:09:16,120 --> 01:09:24,200
특히 네 가지 언어에 대한 벤치마크 어 프랑스어 독일어 스페인어 및 이탈리아어

539
01:09:24,280 --> 01:09:33,480
이러한 각 언어에 대해 um arcs c Challenge heliswag 및 mmlu 벤치마크는 다음과 같습니다.

540
01:09:33,480 --> 01:09:43,960
보고된 바에 따르면 혼합 드릴이 모든 면에서 Lama2보다 더 나은 성능을 발휘하는 것으로 나타났습니다.

541
01:09:44,440 --> 01:09:46,440
하나

542
01:09:48,040 --> 01:09:54,440
장거리 성능에 관해서는 음 혼합 드릴이 장거리 성능이 좋습니다.

543
01:09:55,000 --> 01:10:01,480
모델의 능력을 측정하는 Pasky 검색 작업의 검색 정확도 100%

544
01:10:01,480 --> 01:10:07,880
긴 프롬프트에 무작위로 삽입된 파스키를 꺼내기 위해 당황함 uh

545
01:10:08,600 --> 01:10:17,960
컨텍스트 길이가 증가함에 따라 감소하는 것은 당혹감이 얼마나 음, 음, 그게 무엇인지입니다.

546
01:10:17,960 --> 01:10:31,160
기본적으로 어떻게 음 어떻게 음 어 모델 출력을 예측할 수 있을 가능성이 얼마나 낮습니까?

547
01:10:31,960 --> 01:10:42,760
그리고 음 그리고 음 바이어스 벤치마크 측면에서도 어 혼합 드릴을 사용해서 Lama2 70b를 수행합니다 어

548
01:10:42,760 --> 01:10:51,000
qa에 대한 편향 벤치마크와 개방형 언어 생성 데이터 세트의 편향 uh

549
01:10:51,640 --> 01:10:58,440
Lama2에 비해 전반적으로 더 높은 점수를 얻었으며 이는 사회적 편견이 적음을 나타냅니다.

550
01:10:58,760 --> 01:11:05,640
이제 uh 혼합 드릴 지침은 감독된 미세 조정이 가능한 uh 혼합 드릴 버전입니다.

551
01:11:05,640 --> 01:11:13,240
명령 데이터 세트에 이어 직접적인 성능 최적화가 이루어지며 음

552
01:11:13,240 --> 01:11:22,840
이것은 음 사용자가 할 수 있는 대규모 모델 시스템 챗봇 경기장을 사용하여 평가되었습니다.

553
01:11:23,080 --> 01:11:33,400
uh 두 모델에 메시지를 보낸 다음 어느 모델을 선택할지 선택하겠습니다.

554
01:11:33,960 --> 01:11:41,880
그들은 응답을 기반으로 선호하며 승리한 모델은 패배하는 동안 더 높은 elo를 얻게 됩니다.

555
01:11:42,440 --> 01:11:52,600
모델은 더 낮은 elo를 얻을 것이고 이것은 음 이 elo는 음 성능을 측정하는 데 사용됩니다.

556
01:11:53,080 --> 01:12:01,960
모델 또는 모델의 성능을 측정하는 한 가지 방법 및 음 2023년 12월 현재

557
01:12:02,600 --> 01:12:09,640
혼합 드릴 지시 L은 도전적인 세트인 MT 벤치에서 다른 오픈 웨이트 모델을 수행합니다.

558
01:12:09,640 --> 01:12:19,800
다단계 질문 음 사용자는 어디에서 음 대화를 나누나요 음

559
01:12:22,920 --> 01:12:32,120
어 모델을 사용하면 음 여러 프롬프트가 포함되고 음 혼합 드릴 지시도 있었습니다

560
01:12:32,120 --> 01:12:41,000
어 경기장 엘로에서 6위를 차지했으며 이는 200,000명의 인간 선호도 투표를 기준으로 한 것입니다.

561
01:12:43,320 --> 01:12:51,960
이제 우리는 라우터를 분석합니다. 음 그래서 선택된 전문가의 분포는

562
01:12:51,960 --> 01:13:01,000
파일 데이터 세트는 첫 번째 중간 및 마지막 레이어에 대해 측정되고 보고되었습니다. 음 그리고 어 이것은

563
01:13:01,080 --> 01:13:11,880
이것은 왼쪽의 음 그래프에 표시되어 있습니다. 어 그리고 우리가 볼 수 있듯이 어 오직 DM 수학만 있습니다

564
01:13:12,520 --> 01:13:19,320
파일 데이터 세트에서 음은 상당히 다른 분포를 가지고 있었고 음 이것은 가능합니다

565
01:13:19,960 --> 01:13:27,000
이는 아마도 자연어의 제한된 적용 범위와 음의 합성 특성 때문일 수 있습니다.

566
01:13:27,080 --> 01:13:34,600
데이터 세트와 음 또한 첫 번째와 마지막 레이어의 분포가 다음과 같은 것으로 나타났습니다.

567
01:13:34,600 --> 01:13:41,720
라우터가 가지고 있음을 시사하는 입력 및 출력 및 침구와 각각 매우 유사합니다.

568
01:13:41,720 --> 01:13:49,320
구조화된 구문 동작은 오른쪽 이미지에도 표시되어 있습니다.

569
01:13:49,320 --> 01:13:57,320
음 비슷한 단어는 색상도 같고 들여쓰기의 들여쓰기도 비슷할 것 같아요

570
01:13:57,320 --> 01:14:07,640
일반적으로 색상이 같고 기호 그룹도 비슷합니다. 비슷한 기호 그룹입니다.

571
01:14:07,640 --> 01:14:17,800
같은 색상을 가지고 있습니다. 음 제가 논의할 최종 모델은 음 Pathways를 뜻하는 POM입니다.

572
01:14:17,800 --> 01:14:29,560
언어 모델 어 그리고 음 그것은 매우 큰 음 5,400억 개의 매개변수 모델입니다 어 그 어 음

573
01:14:30,280 --> 01:14:41,160
통로 시스템 그리고 음 그것은 어 밀도있게 활성화된 변환기 언어 모델입니다.

574
01:14:41,160 --> 01:14:55,720
음 google의 uh tpu v4 uh 칩의 6144 칩으로 훈련되었으며 음 그래서 그것이 가지고 있는 몇 가지 기능은 다음과 같습니다.

575
01:14:55,720 --> 01:15:04,840
그것은 음, 수천 개의 가속기 칩에 걸쳐 매우 잘 확장되는 만큼 효율적인 확장입니다.

576
01:15:04,920 --> 01:15:13,080
매우 효율적인 방식이며 음 확장을 통해 지속적인 개선을 보여주었습니다.

577
01:15:14,520 --> 01:15:23,720
음 5,400억 개의 매개변수를 가진 아주 큰 모델인데 음

578
01:15:24,680 --> 01:15:33,080
그거 성능이야 uh 역시 uh 그 크기로 커졌지 um so um

579
01:15:35,720 --> 01:15:45,880
그래서 다단계 수학 및 기타 획기적인 기능을 통해 추론 작업을 수행할 수 있습니다.

580
01:15:45,960 --> 01:15:55,080
그리고 사실 그것은 실제로 음 실제로는 어 올 때 정확도가 극적으로 향상됩니다.

581
01:15:56,280 --> 01:16:03,320
POM의 620억 uh 매개변수 버전에서 음과 음 비교

582
01:16:05,000 --> 01:16:11,080
매개변수의 정확도가 80억에서 620억으로 증가하여 불연속적인 결과가 발생합니다.

583
01:16:11,160 --> 01:16:21,800
개선 음 확장 동작이 있는 곳은 음 음 개선 및 성능이 있는 곳은 어디입니까?

584
01:16:21,800 --> 01:16:32,760
비선형이고 음 그래서 모델이 충분한 규모를 달성하면 새로운 기능이 나타납니다.

585
01:16:32,760 --> 01:16:41,880
그리고 음, 다국어 이해가 가능합니다. 음 어 이전 모델보다 작업이 더 철저해요.

586
01:16:43,160 --> 01:16:52,760
번역 같은 것도 음, 성별이나 직업 편향에 대한 정확도는 향상됐지만

587
01:16:52,760 --> 01:17:03,240
여전히 음 다른 편견에 문제가 있습니다. 음, 예를 들어 이슬람교도를 테러리즘과 연관시킵니다.

588
01:17:03,240 --> 01:17:14,680
극단주의와 폭력 그리고 이것은 진행 중인 작업입니다. 음 아키텍처는 표준을 사용합니다.

589
01:17:15,240 --> 01:17:23,880
디코더만 설정되어 있고 각 타임스탬프는 그 자체에만 주의를 기울일 수 있는 변환기 모델

590
01:17:23,880 --> 01:17:32,680
그리고 시간 단계를 전달합니다. 음, 앞서 설명한 것처럼 swigloo 활성화 함수도 사용합니다.

591
01:17:32,680 --> 01:17:43,800
음 변압기의 성능을 향상시키는 데 도움이 되고 음 또한 음 평행 레이어가 있어서 각

592
01:17:43,800 --> 01:17:51,720
변압기 블록은 병렬이고 공식은 음, 병렬 공식은 다음과 같습니다.

593
01:17:52,280 --> 01:17:58,680
표준 공식과 유사하지만 주의 용어가 외부로 이동되었습니다.

594
01:17:58,760 --> 01:18:00,200
다층 퍼셉트론

595
01:18:04,600 --> 01:18:15,880
음 어 그럼 세 가지 다른 모델 어 저울을 비교했는데 어 그럼 5400억 620억과 80억

596
01:18:16,600 --> 01:18:22,040
토큰당 플롭 수는 매개변수 수와 거의 같습니다.

597
01:18:22,920 --> 01:18:29,880
어 그리고 음 모델은 모두 동일하게 훈련되었습니다.

598
01:18:31,880 --> 01:18:40,360
아래 표에 표시된 하이퍼 매개변수는 uh 레이어 수를 보여줍니다. uh

599
01:18:40,360 --> 01:18:47,480
어텐션 헤드 음 그리고 각 레이어의 뉴런 수를 나타내는 모델의 차원

600
01:18:48,040 --> 01:18:53,400
네트워크, 매개변수 수, 배치 크기 um

601
01:18:57,720 --> 01:19:05,320
따라서 훈련 데이터 세트는 7,800억 개의 토큰으로 구성된 고품질 코퍼스로 구성됩니다.

602
01:19:05,880 --> 01:19:13,240
광범위한 자연어 사용 사례를 나타내며 훈련에 사용되는 데이터 세트를 기반으로 합니다.

603
01:19:13,240 --> 01:19:22,840
람다 모델이므로 아래 표는 각 데이터 소스에 대한 데이터 um의 비율을 보여줍니다.

604
01:19:23,480 --> 01:19:33,480
그리고 음, 다국어 코퍼스에는 100개 이상의 언어로 된 텍스트가 포함되어 있습니다. 음 그리고 또한 음 5%는

605
01:19:33,480 --> 01:19:40,760
이는 github 코드에서 나온 것이므로 github에 코드를 게시한 적이 있다면 신경망 작성자

606
01:19:40,760 --> 01:19:45,720
여러 모델의 훈련에 기여해 주셔서 감사할 것 같습니다.

607
01:19:47,400 --> 01:19:56,200
음 이제 여기에서는 모든 모델이 TPU v4 포드에서 훈련되는 훈련 인프라를 보여줍니다.

608
01:19:56,920 --> 01:20:04,920
그리고 음 훈련 및 평가 코드 베이스는 jax와 t5x를 기반으로 하고 음

609
01:20:04,920 --> 01:20:14,120
음 모든 모델은 손바닥 540b가 두 개에 대해 훈련되는 TPU v4 포드에서 훈련됩니다. 어 그 중 두 개

610
01:20:14,120 --> 01:20:22,040
모델과 데이터 병렬성의 조합을 사용하여 포드와 데이터 센터 네트워크를 통해

611
01:20:22,680 --> 01:20:32,360
그리고 음, 768개의 호스트에 연결된 각 포드에서 음 3072 TPU v4 칩을 사용합니다.

612
01:20:35,480 --> 01:20:45,960
음 29개 벤치마크에서 Palm 540b 모델로 얻은 결과는 다음과 같습니다.

613
01:20:46,760 --> 01:20:55,480
그리고 어 그리고 어 이전 기술과 비교하면 표에서 s sota로 축약됩니다.

614
01:20:56,200 --> 01:21:05,240
그리고 음 이것은 음 제로 샷 한 샷과 몇 샷에 대해 수행되었습니다. 음 몇 샷의 경우 숫자는

615
01:21:05,240 --> 01:21:12,440
각 작업에 대한 샷 수는 괄호 안에 언급되어 있으므로 이 표에서는 음

616
01:21:13,560 --> 01:21:19,080
일반적으로 손바닥은 이전 기술 수준보다 더 나은 성능을 발휘합니다.

617
01:21:19,080 --> 01:21:33,640
음 이제 음 빅 벤치라고 불리는 또 다른 벤치마크는 음 여기에는 150개 이상의 작업이 포함되어 있습니다.

618
01:21:33,640 --> 01:21:39,400
논리적 추론 번역을 포함한 다양한 언어 모델링 작업을 다룹니다.

619
01:21:40,040 --> 01:21:50,840
질문 답변 수학 등 그리고 음 어 왼쪽에 있는 것은 손바닥에 대한 평가를 보여줍니다.

620
01:21:52,120 --> 01:22:03,560
gp3 고퍼 친칠라와 음 그리고 평균적인 인간 측정 기준이 있는 인간과 비교해 보세요.

621
01:22:03,560 --> 01:22:15,000
150 최고의 인간은 약 100을 하고 음 손바닥 5번 샷 음 어디에서 5가 표시되었습니까?

622
01:22:15,000 --> 01:22:22,760
훈련의 예 uh 10에서 11 모델 사이에서 평균적인 인간보다 더 나은 성능을 발휘합니다.

623
01:22:22,760 --> 01:22:38,120
매개변수는 추론을 평가하기 위해 음 산술 추론은 어 종종 초등학교 수준을 사용합니다

624
01:22:38,120 --> 01:22:45,320
다단계 논리적 추론이 필요한 자연어 수학 문제는 수학 자체가

625
01:22:45,320 --> 01:22:51,800
사소합니다. 음 어려운 부분은 자연 언어를 수학 방정식으로 변환하는 것입니다.

626
01:22:52,360 --> 01:22:59,160
상식적 추론의 경우에는 강력한 요구 사항에 답하는 질문이 포함됩니다.

627
01:22:59,160 --> 01:23:05,000
세계 지식은 단순히 사실에 기반한 질문 답변이 아니며 연결이 필요합니다.

628
01:23:05,000 --> 01:23:09,960
세계에 대한 전 세계의 다양한 논리적 추론

629
01:23:10,120 --> 01:23:19,480
그리고 생각의 연쇄를 유도하기 위해 음 이건 음 보여졌죠 어

630
01:23:22,520 --> 01:23:30,280
help llm이 훨씬 더 높은 음 정확도 음 개선을 달성하도록 도와주세요.

631
01:23:30,840 --> 01:23:37,720
최종 단계를 생성하기 전에 몇 번의 샷으로 중간 추론 단계를 생성합니다.

632
01:23:37,720 --> 01:23:44,120
이러한 중간 추론 단계를 설정하는 것은 몇 번의 샷에 대해 처음으로 수동으로 작성됩니다.

633
01:23:44,120 --> 01:23:51,480
예 음 모델은 테스트 예에 대한 자체적인 사고 체인을 생성하고

634
01:23:52,200 --> 01:24:00,600
최종 답만 사용하고 어, 최종 답만 생성된 결과를 평가하는 데 사용됩니다.

635
01:24:01,160 --> 01:24:09,720
어 생성된 생각의 사슬은 음 분석 및 모델 해석에 유용할 수 있습니다.

636
01:24:10,520 --> 01:24:18,280
이는 LLM의 주요 장애 중 하나이며 음 사고 유도 체인은 언어를 허용합니다.

637
01:24:18,280 --> 01:24:24,840
그림과 같이 수학 문제와 같은 다단계 추론 작업을 더 잘 수행하기 위한 모델

638
01:24:24,840 --> 01:24:35,320
여기 이 이미지는 두 번째 질문이 음 표준에 대해 잘못된 출력을 제공하는 곳입니다.

639
01:24:35,320 --> 01:24:40,440
촉발하지만 어 촉발하는 생각의 연쇄에 맞네요 um

640
01:24:45,480 --> 01:24:54,600
그래서 어 일련의 생각으로 인해 음 다양한 산수 및 수학 분야에서 강력한 성과를 달성하게 되었습니다.

641
01:24:55,000 --> 01:24:57,640
상식추론 과제 음

642
01:25:01,880 --> 01:25:11,400
그리고 어 코드 작업에 관해서는 음 어 폭탄은 두 가지 주요 유형의 코드 작업에 사용될 수 있습니다.

643
01:25:11,400 --> 01:25:19,880
하나는 uh 자연어 설명에서 코드를 생성하는 것과 관련된 텍스트 대 코드입니다.

644
01:25:19,880 --> 01:25:27,720
두 번째는 특히 번역 작업을 포함하는 코드 간 코드입니다.

645
01:25:28,440 --> 01:25:37,880
c 또는 c 플러스 플러스 프로그램 파이썬 음 음 음 현재 전문 지식 수준은

646
01:25:38,600 --> 01:25:47,400
설명에서 Python 함수의 Python 생성이 가능하지만 어, 하지만 현재는 할 수 없습니다.

647
01:25:47,400 --> 01:25:55,560
전체 프로그램을 생성하는 것은 어 그런데 이것은 매우 유망한 연구 분야입니다 음 그리고 어

648
01:25:57,640 --> 01:26:04,840
트랜스코더 데이터는 github에서 다운로드되며 교육을 제공하기 위한 몇 가지 샷 예제를 제공합니다.

649
01:26:04,840 --> 01:26:14,280
폭탄 모델 어 그리고 폭탄 색상 540b 모델의 예가 여기 이미지에 표시되어 있습니다.

650
01:26:14,920 --> 01:26:23,560
아니면 왼쪽 상단에 gsm이 표시됩니다. 열려 있는 상태에서 변환된 gsm 8k Python 질문이 표시됩니다.

651
01:26:23,560 --> 01:26:31,160
왼쪽 하단에 설정된 ai GSM 8k 수학 데이터는 간단한 텍스트를 번역하는 트랜스코더 예를 보여줍니다.

652
01:26:31,160 --> 01:26:37,720
C + +에서 Python으로의 함수와 오른쪽에는 변환된 인간 평가 예제가 표시됩니다.

653
01:26:38,680 --> 01:26:45,880
Bomb의 훈련 세트에는 github 코드가 포함되어 있으며 총 390억 개의 코드 토큰이 사용되었습니다.

654
01:26:45,880 --> 01:26:53,000
사전 훈련 데이터 세트에서 uh 폭탄은 java html javascript와 같은 추가 언어를 지원합니다.

655
01:26:53,000 --> 01:27:01,960
python c php c Sharp 및 c plus plus 이제 이것을 사용할 때의 주요 위험은 생성된 코드가

656
01:27:01,960 --> 01:27:12,360
여러 가지 버그가 있을 수 있으니 틀릴 수도 있습니다 음 번역은 어 이 작업 이 작업

657
01:27:12,360 --> 01:27:18,920
하나의 인간 언어 어 하나의 인간 언어를 다른 언어로 다시 작성하는 동시에

658
01:27:18,920 --> 01:27:27,640
콘텐츠 의미와 입력 스타일 중 하나는 음 음 영어 중심을 사용하는 것입니다.

659
01:27:27,640 --> 01:27:34,680
과거 모델의 전통적인 초점이었으며 영어를 소스로 사용하는 언어 쌍

660
01:27:34,680 --> 01:27:41,000
또는 대상 언어(예: 영어에서 프랑스어로 또는 영어에서 독일어로 번역)

661
01:27:41,000 --> 01:27:49,800
또는 그 반대의 경우도 마찬가지입니다. 음 또 다른 방법은 음 직접적인 언어 쌍을 사용하는 것입니다.

662
01:27:49,800 --> 01:27:55,480
예를 들어 영어를 사용하지 않고 언어 쌍을 직접 번역합니다.

663
01:27:56,200 --> 01:28:00,520
프랑스어에서 영어로 이동하는 대신 프랑스어에서 독일어로 직접 번역하고

664
01:28:00,520 --> 01:28:13,400
그런 다음 독일어로 그리고 음 어 일부가 있습니다 음 리소스가 매우 부족합니다

665
01:28:13,400 --> 01:28:20,040
어떤 경우에는 언어 중 하나에 다음과 같은 단일 언어 데이터가 거의 없기 때문에 언어 쌍

666
01:28:20,040 --> 01:28:26,040
casak 예를 들어 프랑스와 독일의 훈련 세트에는 약 240억 및 260억 개의 토큰이 있습니다.

667
01:28:26,040 --> 01:28:38,680
Casak에는 약 1억 3,400만 개의 토큰만 있는데 음 이건 어 이 표에 결과가 나와 있습니다 uh

668
01:28:38,680 --> 01:28:44,920
전통적인 WMT 언어 쌍의 번역 파란색 점수와 음

669
01:28:45,160 --> 01:28:53,800
음 어 사용 샷 평가는 손바닥에 대한 5개의 샷에 해당하며 제로 샷 프롬프트에 유의하세요.

670
01:28:53,800 --> 01:28:59,240
프롬프트에 소스 및 대상 언어 이름이 포함되지만 한 장면과 몇 장면은 포함되지 않습니다.

671
01:28:59,240 --> 01:29:05,880
따라서 언어는 강력한 제로 샷을 설명할 수 있는 예시에서 추론되어야 합니다.

672
01:29:05,880 --> 01:29:15,720
일부 언어 쌍 번역의 성능 음 일부 언어 쌍의 음 및 어 번역

673
01:29:15,720 --> 01:29:23,240
영어로 번역하는 것보다 영어로 번역할 때 품질이 더 좋습니다 음 그리고 어 프롬프트는 가능합니다

674
01:29:23,240 --> 01:29:30,280
단일 사례와 자기 자신에만 의존하는 일반 모델보다 훨씬 더 많은 가치를 제공합니다.

675
01:29:30,280 --> 01:29:38,840
감독은 더 작은 규모의 전문 모델과 일치시킬 수 있으며 음 마침내 어 우리는 할 것입니다

676
01:29:38,840 --> 01:29:48,600
palm의 한계에 대해 논의하고 있는데 음, 그래서 한계 중 하나는 손바닥에 다음과 같은 내용이 포함되어 있다는 것입니다.

677
01:29:49,160 --> 01:29:56,680
기본 데이터에 증폭된 편향이 포함될 수 있지만 어 이 제한은 팜에만 국한되지 않습니다.

678
01:29:56,680 --> 01:30:07,640
하지만 어 일반적으로 다른 작품에는 음 일반적인 직업 편견이 있고 음

679
01:30:09,720 --> 01:30:19,240
또한 음 어 이슬람과 관련된 단어가 있는 것과 같은 독성 독성과 편견도 있습니다.

680
01:30:19,800 --> 01:30:28,760
매우 폭력적인 용어와 테러리스트의 폭력적, 과격함과 같은 유형은 없습니다. 그리고 음 어

681
01:30:29,720 --> 01:30:37,320
음의 함수로서 지속의 독성 확률

682
01:30:37,320 --> 01:30:48,040
프롬프트 음은 음 이 그래프에 표시되어 있고 인간 기준선은 독성을 나타냅니다.

683
01:30:48,040 --> 01:31:00,520
원래 문장이 계속될 확률과 음 음 음 독성 확률

684
01:31:00,520 --> 01:31:07,560
지속 또는 tpc는 프롬프트의 독성 확률과 더 일치합니다.

685
01:31:07,560 --> 01:31:16,120
또는 tpp는 인간의 tpc보다 높으며 이는 모델이 크게 영향을 받는다는 것을 의미합니다.

686
01:31:16,120 --> 01:31:23,480
프롬프트 스타일로 손바닥이 620억 540이라는 메모를 좋아하는 것처럼 반응할 가능성이 높습니다.

687
01:31:23,480 --> 01:31:37,480
10억 개의 모델은 매우 유사한 독성 확률을 가지고 있습니다. 음, 이제 우리는 어, 이제 보여드리겠습니다.

688
01:31:37,560 --> 01:31:51,160
음 이 프레젠테이션에서 논의된 모든 작품을 비교하는 표는 다음과 같습니다.

689
01:31:53,800 --> 01:32:02,040
각 작품에는 다양한 버전이나 설정이 있으므로 가장 일반적인 버전이나 설정만 사용합니다.

690
01:32:02,040 --> 01:32:10,600
각각에 대해 가장 큰 것이 선택됩니다 uh uh 모두 포함하면 페이지에 맞지 않기 때문입니다 um

691
01:32:12,520 --> 01:32:23,880
그리고 마지막으로 어 토론을 위한 질문이 6개나 있을 테니 첫 번째 질문을 할게요

692
01:32:24,680 --> 01:32:29,560
비지도 학습 또는 인간 피드백을 통한 강화 학습이 바람직합니다.

693
01:32:30,200 --> 01:32:37,000
질문 2 무엇이 큰 언어 모델을 크게 만드는가 질문 3 어 언어 모델이 가능할까요?

694
01:32:37,000 --> 01:32:46,760
악의적으로 사용된 어 그리고 어떻게 음 4번 질문 음 오용으로 인한 사회적 피해를 줄일 수 있는 방법은 무엇입니까?

695
01:32:46,760 --> 01:32:55,560
언어 모델 어 질문 5 어 우리는 어떻게 사회적 암묵적 편견을 제거하나요?

696
01:32:55,560 --> 01:33:02,680
기본 모델의 일부이며 마지막으로 여섯 번째 질문은 무엇이 작품에서 관찰되는 창발적 능력으로 이어졌는가입니다.

697
01:33:04,680 --> 01:33:10,280
프레젠테이션에 사용된 참고자료는 다음과 같습니다. 시청해 주셔서 감사합니다.