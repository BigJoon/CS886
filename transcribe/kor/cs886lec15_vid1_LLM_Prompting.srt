1
00:00:00,000 --> 00:00:06,000
여러분, 안녕하세요. 오늘 우리의 주제는 대규모 언어 모델 프롬프트입니다. 그럼 시작해 보겠습니다.

2
00:00:10,000 --> 00:00:16,000
그렇다면 큰 언어 프롬프트는 무엇입니까? 따라서 이는 기본적으로 엔지니어링을 촉진하는 것과 같습니다.

3
00:00:16,000 --> 00:00:24,000
그리고 대규모 언어 모델과 효과적으로 의사소통하는 것이 중요하며 이는 디자인에 관한 것입니다.

4
00:00:24,000 --> 00:00:31,000
그리고 사람들이 대규모 언어 모델에서 원하는 답변을 얻기 위해 적절한 질문을 생각해내는 방법입니다.

5
00:00:31,000 --> 00:00:36,000
그리고 오늘 프레젠테이션에서는 몇 가지 실용적인 프롬프트 엔지니어링 기술에 대해 논의해 보겠습니다.

6
00:00:36,000 --> 00:00:40,000
좋아요, 그럼 바로 들어가 보겠습니다.

7
00:00:40,000 --> 00:00:45,000
그럼 먼저 생각의 흐름에 대해 이야기해 봅시다.

8
00:00:45,000 --> 00:00:51,000
일련의 사고 유도는 가장 일반적으로 사용되며 중요한 유도 방법입니다.

9
00:00:51,000 --> 00:00:58,000
그리고 오늘 우리가 다룬 모든 후속 프롬프트 방법은 실제로 일련의 사고 프롬프트에 기반을 두고 있습니다.

10
00:00:58,000 --> 00:01:01,000
그렇다면 일련의 생각이 자극하는 것은 무엇입니까?

11
00:01:01,000 --> 00:01:11,000
산술추론, 상식추론, 상징추론에서 언어모델의 공명성을 향상시키기 위한 접근방식이다.

12
00:01:11,000 --> 00:01:19,000
따라서 생각을 불러일으키는 일련의 사고는 당신에게 매우 구조화된 답변과 실제로는 단계적인 답변을 제공할 것입니다.

13
00:01:19,000 --> 00:01:26,000
그리고 당신은 이러한 모든 생각의 흐름을 따르고 이해하는 것이 매우 쉽다는 것을 알게 될 것입니다.

14
00:01:26,000 --> 00:01:31,000
인간의 관점에서 보면 이는 인간이 실제로 생각하는 방식이므로 매우 직관적입니다.

15
00:01:31,000 --> 00:01:39,000
그러니까 질문을 할 때 처음부터 직접 최종 답변에 도달할 수는 없잖아요?

16
00:01:39,000 --> 00:01:52,000
대신에 인간이 실제로 하는 일은 사고 절차를 반복하고 하나의 주요 문제를 몇 가지 하위 문제로 분해하여 하나씩 해결하는 것입니다.

17
00:01:52,000 --> 00:01:59,000
여기 보시다시피 전통적인 프롬프트 표준이 있습니다.

18
00:01:59,000 --> 00:02:06,000
전통적인 프롬팅에서는 여기에 있는 예시가 여기에서 볼 수 있지만 그 내용만 포함되어 있습니다.

19
00:02:06,000 --> 00:02:13,000
여기에는 최종 답변이 포함되어 있습니다. 여기에 하나의 질문이 있으며 최종 답변은 여기에 있습니다.

20
00:02:13,000 --> 00:02:20,000
글쎄, 그들은 이와 같은 추론 능력이 필요한 작업에서는 제대로 수행되지 않습니다.

21
00:02:20,000 --> 00:02:26,000
그것은 단지 임의의 숫자에서 나온 잘못된 대답을 제공하는 것입니다.

22
00:02:26,000 --> 00:02:33,000
또는 여기에서 일련의 사고 유도와 마찬가지로 예시 자체와 몇 가지 중간 단계가 포함되어 있음을 볼 수 있습니다.

23
00:02:33,000 --> 00:02:42,000
먼저 하위 문제를 풀고 하위 문제를 결합하면 정답을 얻을 수 있겠죠?

24
00:02:42,000 --> 00:02:54,000
실제로 볼 수 있듯이 문제는 꽤 괜찮은 방법으로 해결됩니다. 정답입니다. 정답입니다.

25
00:02:54,000 --> 00:03:00,000
그래서 여기서 나는 여러분에게 생각을 불러일으키는 몇 가지 원칙을 제시하겠습니다.

26
00:03:00,000 --> 00:03:04,000
생각의 기차는 당신이 가진 모든 문제에 적합하지 않습니다.

27
00:03:04,000 --> 00:03:11,000
일종의 단계별 사고를 통해 문제를 해결할 가능성이 더 높습니다.

28
00:03:11,000 --> 00:03:16,000
보면 쉽게 알아볼 수 있을 것 같아요.

29
00:03:16,000 --> 00:03:21,000
생각의 기차 전략은 간단하고, 나누고, 동의합니다.

30
00:03:21,000 --> 00:03:28,000
큰 작업을 여러 하위 작업으로 나누고 하나씩 완료합니다.

31
00:03:28,000 --> 00:03:38,000
다음은 chatGBT 또는 클라우드 언어 모델과 통신할 때 사용할 수 있는 몇 가지 사고 유도 원리 또는 기술입니다.

32
00:03:38,000 --> 00:03:43,000
여기 아주 간단한 프롬프트가 있습니다. 단계별로 해봅시다.

33
00:03:43,000 --> 00:03:47,000
따라서 질문 끝에 이 문자열을 연결하면 됩니다.

34
00:03:47,000 --> 00:03:53,000
그리고 이 문장은 언어 모델이 문제를 단계별로 해결하도록 강제합니다.

35
00:03:53,000 --> 00:03:57,000
두 번째는 명시적 추론 열차입니다.

36
00:03:57,000 --> 00:04:09,000
따라서 번개의 위험을 고려한 다음 실내를 거쳐 실외에 있는 것의 안전성을 평가해 봅시다.

37
00:04:09,000 --> 00:04:13,000
가장 안전한 옵션으로 마무리하세요.

38
00:04:13,000 --> 00:04:26,000
귀하의 예에는 이러한 명시적 추론 체인이 포함되어 있으며 이는 언어 모델의 추론 능력을 향상시키는 데 도움이 될 것입니다.

39
00:04:26,000 --> 00:04:29,000
여기에서 몇 가지 예를 사용할 수도 있습니다.

40
00:04:29,000 --> 00:04:36,000
부등식에서 이행 법칙을 사용하려고 한다고 가정해 보겠습니다.

41
00:04:36,000 --> 00:04:41,000
세 개의 변수 A, B, C가 있습니다. 이들은 서로 다른 숫자를 나타냅니다.

42
00:04:41,000 --> 00:04:44,000
A가 가장 큽니다.

43
00:04:44,000 --> 00:04:49,000
A는 기본적으로 B보다 크고 B는 C보다 큽니다.

44
00:04:49,000 --> 00:04:51,000
따라서 전이 법칙에 따르면 이것이 가장 크다.

45
00:04:51,000 --> 00:04:53,000
그래서 이런 예가 있습니다.

46
00:04:53,000 --> 00:04:57,000
또는 여기에서 반복적 개선을 사용할 수 있습니다.

47
00:04:57,000 --> 00:05:00,000
이 작업은 또한 세 가지 다른 변수를 비교하는 것입니다.

48
00:05:00,000 --> 00:05:06,000
그러나 언어 모델이 쌍으로 비교하도록 강제합니다.

49
00:05:06,000 --> 00:05:10,000
A와 B는 A와 C, B와 C를 하나씩 비교합니다.

50
00:05:10,000 --> 00:05:18,000
그러면 이 세 변수 사이의 최종 관계를 얻을 수 있습니다.

51
00:05:18,000 --> 00:05:22,000
여기 사고열의 정말 매력적인 특성이 있습니다.

52
00:05:22,000 --> 00:05:26,000
그리고 사람들이 그것을 사용하는 것을 좋아하는 몇 가지 이유가 있습니다.

53
00:05:26,000 --> 00:05:32,000
첫 번째는 어려운 문제를 더 간단한 문제로 분해한다는 것입니다.

54
00:05:32,000 --> 00:05:37,000
그리고 이러한 간단한 질문은 더 직관적인 경향이 있습니다.

55
00:05:37,000 --> 00:05:40,000
하위 문제는 해결하기 쉽습니다.

56
00:05:40,000 --> 00:05:51,000
둘째, 사고의 흐름은 실제로 언어 모델 추론 경로에 대한 어느 정도의 해석을 제공합니다.

57
00:05:51,000 --> 00:06:02,000
단지 답변이 어떻게 요청되었는지, 중간 단계가 어떻게 도출되었는지 파생될 뿐입니다.

58
00:06:02,000 --> 00:06:06,000
그리고 추론 경로가 잘못되었을 때 디버깅하는 것도 쉽습니다.

59
00:06:06,000 --> 00:06:15,000
문제가 발생했다는 첫 번째 추론 단계가 어느 단계인지 명확하게 알 수 있습니다.

60
00:06:15,000 --> 00:06:21,000
셋째, 다양한 추론 작업에 매우 광범위하게 적용 가능합니다.

61
00:06:21,000 --> 00:06:27,000
따라서 이론적으로는 모든 언어 문제 해결에 적용할 수 있습니다.

62
00:06:27,000 --> 00:06:30,000
마지막 이유는 매우 간단하고 기성품이기 때문입니다.

63
00:06:30,000 --> 00:06:34,000
추가 교육이나 미세 조정이 필요하지 않습니다.

64
00:06:34,000 --> 00:06:45,000
GPT 세션의 게이지 내에서 여러 가지 프롬프트를 통해 일련의 사고 기술을 적용할 수 있습니다.

65
00:06:45,000 --> 00:06:52,000
그래서 앞서 논의한 것처럼 사고열차 접근법은 주로 세 가지 영역의 추론 능력을 향상시키는 데 중점을 둡니다.

66
00:06:52,000 --> 00:06:56,000
산술추론, 상식추론, 상징추론이 그것이다.

67
00:06:57,000 --> 00:07:06,000
그래서 평가 부분에서는 이 세 가지 영역 모두에서 일종의 생각이 가져온 개선 사항을 하나씩 논의해 보겠습니다.

68
00:07:06,000 --> 00:07:08,000
첫 번째는 산술 추론입니다.

69
00:07:08,000 --> 00:07:16,000
그들이 사용하는 기준 작성자는 여기에 몇 가지 상황에 맞는 예가 포함된 표준 프롬프트입니다.

70
00:07:16,000 --> 00:07:22,000
일련의 사고 방식은 8개의 뷰 샷 예시를 통해 각 입력을 강화합니다.

71
00:07:22,000 --> 00:07:28,000
그리고 우리가 여기서 보는 것처럼 이것은 단지 하나의 예일 뿐입니다.

72
00:07:28,000 --> 00:07:31,000
이 논문에서 저자는 8가지 사례를 사용하고 있습니다.

73
00:07:31,000 --> 00:07:39,000
그리고 우리가 사용하는 벤치마크는 GSM 8K, VA, MP 등 5가지 수학 문제입니다.

74
00:07:39,000 --> 00:07:43,000
GSM 8K 데이터 세트의 한 예는 다음과 같습니다.

75
00:07:44,000 --> 00:07:51,000
나는 이것을 읽지 않을 것이지만 당신은 수학 문제를 풀어야 할 것입니다.

76
00:07:51,000 --> 00:08:02,000
그리고 여기서 사용하는 언어 모델은 GPT-3, 람다, 팜, UL220bn, 코덱스 이렇게 5가지 모델입니다.

77
00:08:02,000 --> 00:08:06,000
여기에서 평가 결과를 볼 수 있습니다.

78
00:08:06,000 --> 00:08:13,000
y축은 문제 해결률을 나타내고 x축은 모델 규모를 나타냅니다.

79
00:08:13,000 --> 00:08:16,000
먼저 여기에 몇 가지 결론이 있습니다.

80
00:08:16,000 --> 00:08:21,000
그러나 먼저 생각의 흐름은 작은 모델의 성능을 향상시키지 않습니다.

81
00:08:21,000 --> 00:08:27,000
여기에서 볼 수 있듯이 파란색 선과 검은색 선 사이의 간격이 매우 작습니다.

82
00:08:28,000 --> 00:08:34,000
생각의 흐름은 1,000억 개가 넘는 매개변수에 사용될 때만 성능 향상을 얻을 수 있습니다.

83
00:08:34,000 --> 00:08:40,000
이 수준에서 시작되는 것을 볼 수 있습니다. 이 수준에서는 격차가 더 큽니다.

84
00:08:40,000 --> 00:08:45,000
따라서 표준 프롬프트인 기본 모델과 비교하여 개선 사항이 있음을 알 수 있습니다.

85
00:08:45,000 --> 00:08:53,000
둘째, 일련의 사고 프롬프트는 더 복잡한 문제에 대해 더 큰 성능 향상을 제공합니다.

86
00:08:53,000 --> 00:09:01,000
복잡한 문제가 있다는 것은 GSM 8K가 모든 벤치마크 중에서 가장 어려운 데이터 세트라는 것입니다.

87
00:09:01,000 --> 00:09:08,000
그러면 표준 입력과 생각의 흐름 사이의 간격이 상당히 크다는 것을 알 수 있습니다. 그렇죠?

88
00:09:08,000 --> 00:09:17,000
또한 모델이 잘못된 답을 제공한 50개의 예를 무작위로 조사했습니다.

89
00:09:17,000 --> 00:09:28,000
그래서 오류 분석을 하고 있는데 그 중 46%가 계산기 오류, 기호 매핑 오류, 추론 단계 누락 등 사소한 오류였습니다.

90
00:09:28,000 --> 00:09:31,000
그냥 사소한 오류일 뿐이죠, 그렇죠?

91
00:09:31,000 --> 00:09:38,000
그리고 54%의 오류는 주요 오류이며 의미론적 오류이고 오해입니다.

92
00:09:38,000 --> 00:09:50,000
따라서 POM 모델을 620억에서 5,400억으로 확장하면 의미론적 이해 오류의 상당 부분이 수정됩니다.

93
00:09:50,000 --> 00:09:59,000
이전에 논의한 것처럼 이 54%의 의미론적 오답 오류는 주요 오류이자 더 큰 실수입니다.

94
00:09:59,000 --> 00:10:14,000
그리고 POM 모델에서 볼 수 있듯이 모델 규모를 620억에서 5400억으로 늘리면 실제로 문제가 해결됩니다.

95
00:10:14,000 --> 00:10:21,000
성능은 이전에 감독된 최고 수준과 매우 유사합니다.

96
00:10:21,000 --> 00:10:25,000
상식적인 추론이 두 번째 과제이다.

97
00:10:25,000 --> 00:10:32,000
우리는 5가지 상식 추론 데이터 세트를 사용하고 있으며, 모두 싱크대와 물 한 쌍에 대해 예 또는 아니오라는 질문을 포함하고 있습니다.

98
00:10:32,000 --> 00:10:34,000
이것은 단지 예일 뿐입니다.

99
00:10:34,000 --> 00:10:41,000
우리는 산술추론 평가와 마찬가지로 생각을 유도하는 일련의 사고방식을 사용하고 있습니다.

100
00:10:41,000 --> 00:10:53,000
우리는 몇 가지 중간 단계를 통해 입력 질문을 촉발하고, 언어 모델이 명시적인 추론 단계를 제공하도록 강제합니다.

101
00:10:53,000 --> 00:11:02,000
쌍의 밀도는 무엇이 물보다 작느냐에 관한 것이므로 쌍은 뜨게 되므로 대답은 '예'입니다.

102
00:11:02,000 --> 00:11:18,000
결과에서 볼 수 있듯이 사고열차 프롬프트와 함께 POM의 성능은 이전 감독된 최첨단 기술보다 훨씬 뛰어납니다.

103
00:11:18,000 --> 00:11:28,000
따라서 우리는 상징적 추론 작업에 대한 사고열의 성능도 평가합니다.

104
00:11:28,000 --> 00:11:30,000
여기에는 두 가지 종류의 작업이 있습니다.

105
00:11:30,000 --> 00:11:33,000
첫 번째는 마지막 문자 연결입니다.

106
00:11:33,000 --> 00:11:43,000
Amy Brown이라는 문자열이 주어졌고 원하는 경우 각 단어의 마지막 문자를 연결하는 것이 작업이라고 가정해 보겠습니다.

107
00:11:43,000 --> 00:11:46,000
따라서 출력은 y이고 이것을 결합합니다.

108
00:11:46,000 --> 00:11:49,000
그리고 두 번째 과제는 콘 뒤집기입니다.

109
00:11:49,000 --> 00:11:57,000
원뿔이 올라갔습니다. 한 사람은 원뿔을 뒤집었지만 다른 사람은 원뿔을 뒤집지 않았습니다. 원뿔이 여전히 올라갔습니까?

110
00:11:57,000 --> 00:11:59,000
이런 질문이군요.

111
00:11:59,000 --> 00:12:11,000
따라서 일련의 사고 유도를 사용할 때 산술 추론에서와 마찬가지로 상식적으로 언어 모델을 유도합니다.

112
00:12:11,000 --> 00:12:15,000
그래서 우리는 사고 과정을 추가합니다.

113
00:12:15,000 --> 00:12:24,000
우리는 단어의 마지막 문자가 무엇인지 명시적으로 언급하고 돌아와서 이를 연결하고 해당 프롬프트를 언어 모델에 제공합니다.

114
00:12:24,000 --> 00:12:32,000
따라서 상징적 추론 평가에는 두 가지 종류의 평가 작업이 있습니다.

115
00:12:32,000 --> 00:12:35,000
하나는 도메인 내 테스트입니다.

116
00:12:35,000 --> 00:12:39,000
두 번째는 도메인 외부, 배포 외부 작업입니다.

117
00:12:39,000 --> 00:12:50,000
도메인 내 작업은 단지 도메인 내 작업의 예는 교육 및 향후 학습과 동일한 단계 수를 갖습니다.

118
00:12:50,000 --> 00:12:56,000
따라서 도메인 내 평가는 높은 예를 갖춘 높은 작업입니다.

119
00:12:56,000 --> 00:13:03,000
모델이 해야 할 일은 테스트 시간 예시에서 동일한 새 기호를 사용하여 동일한 단계를 반복하는 것뿐입니다.

120
00:13:03,000 --> 00:13:09,000
그래서 우리는 수학 공식과 몇 가지 숫자가 주어졌다고 가정해 보겠습니다.

121
00:13:09,000 --> 00:13:13,000
공식에 숫자를 대입하면 방정식이 풀립니다.

122
00:13:13,000 --> 00:13:17,000
그것은 그렇게 간단합니다.

123
00:13:17,000 --> 00:13:21,000
그래서 오른쪽 그림은 손바닥에 대한 결과를 보여줍니다.

124
00:13:21,000 --> 00:13:35,000
여기에서 볼 수 있듯이 5,400억 개의 매개변수가 있는 손바닥이 도메인 내 질문을 거의 100% 정확하게 해결했습니다.

125
00:13:35,000 --> 00:13:43,000
그러나 이 경우에도 도메인 내 테스트를 수행하더라도 이는 장난감 모델을 사용한 장난감 예이며 표준 프롬프트는 여전히 제대로 수행되지 않습니다.

126
00:13:43,000 --> 00:13:49,000
여기에서 성능 선이 x축에 매우 가깝다는 것을 알 수 있습니다.

127
00:13:49,000 --> 00:13:57,000
따라서 분포 외의 경우 평가 사례는 내부 사례보다 더 많은 단계를 갖습니다.

128
00:13:57,000 --> 00:14:07,000
동전 던지기를 예로 들어 도메인 내 테스트는 두 사람이 같은 동전을 던지는 것입니다. 그렇죠?

129
00:14:07,000 --> 00:14:20,000
배포 외 평가를 사용하면 동전을 던지고 가지고 놀며 최종 답을 얻을 수 있는 사람이 3, 4, 5명 더 많아질 것입니다.

130
00:14:20,000 --> 00:14:26,000
직관적으로 배포 외부 작업은 도메인 내 테스트에 비해 더 어렵습니다.

131
00:14:26,000 --> 00:14:38,000
따라서 성능이 약간 감소하는 것을 볼 수 있지만 여기의 표준 프롬프트 문제와 비교하면 여전히 놀랍습니다.

132
00:14:38,000 --> 00:14:42,000
그러나 사고방식에는 몇 가지 한계가 있습니다.

133
00:14:42,000 --> 00:14:51,000
사고의 기차는 인간 추론자의 사고 과정을 모방하지만, 이는 신경망이 실제로 추론하는지 여부에 대한 질문에 대답하지 않습니다.

134
00:14:51,000 --> 00:14:57,000
두 번째 한계는 일련의 생각을 통해 수동으로 예시를 확장하는 데 드는 비용이 최소화된다는 것입니다.

135
00:14:57,000 --> 00:15:07,000
향후에는 LGBT와 소통하는 등의 설정에서 이러한 주석 비용은 미세 조정을 수행할 때 큰 문제를 일으킬 수 있습니다.

136
00:15:07,000 --> 00:15:18,000
그리고 세 번째 단점, 즉 세 번째 한계는 사고열차 추론 능력의 출현이 대형 모델, 대형 모델 규모에서만 나타난다는 점입니다.

137
00:15:18,000 --> 00:15:26,000
1,000억 개가 넘는 매개변수를 가지고 있지만 작은 모델에서는 작동하지 않습니다.

138
00:15:26,000 --> 00:15:32,000
따라서 향후 작업 중 일부는 이를 이와 같은 소형 모델에 적용하는 방법이 될 수 있습니다.

139
00:15:32,000 --> 00:15:40,000
그리고 네 번째 약점은 올바른 추론이 통과된다는 보장이 없다는 것입니다. 그렇죠?

140
00:15:40,000 --> 00:15:54,000
추론이 합리적으로 보이지만 이전 예에서 볼 수 있듯이 올바른 답을 얻을 것이라는 보장은 전혀 없습니다.

141
00:15:54,000 --> 00:16:05,000
따라서 네 번째 제한 사항을 기반으로 우리는 사고 언어 모델 열차의 자체 일관성 버전을 발명했습니다.

142
00:16:05,000 --> 00:16:10,000
동기는 자기 일관성이 인간의 사고 방식과 유사하다는 것입니다.

143
00:16:10,000 --> 00:16:18,000
따라서 여러 가지 다른 사고 방식이 동일한 답으로 이어질 수 있다면 최종 답이 정확하다는 큰 확신을 가질 수도 있습니다.

144
00:16:18,000 --> 00:16:25,000
또한 복잡한 추론 텍스트는 일반적으로 정답에 도달하는 여러 추론 경로를 자동화합니다.

145
00:16:25,000 --> 00:16:30,000
당신이 수학적 개념, 이론 또는 이와 유사한 것을 증명한다고 가정해 봅시다.

146
00:16:30,000 --> 00:16:45,000
아마도 이론이 정확하다면 최종 목적지의 올바른 진술에 도달하기 위해 여러 가지 다른 증명 방법을 사용할 수 있을 것입니다.

147
00:16:45,000 --> 00:16:50,000
무언가 잘못되었다는 것을 증명하려고 하지 않는 한, 그렇죠?

148
00:16:50,000 --> 00:16:59,000
그래서 여기에는 전통적인 프롬프트와 자기 일관성 프롬프트를 통한 일련의 사고 유도 간의 비교가 있습니다.

149
00:16:59,000 --> 00:17:03,000
여기에서 전통적인 프롬프트에는 입력과 출력만 포함되어 있음을 알 수 있습니다.

150
00:17:03,000 --> 00:17:08,000
사고 유도 과정에서 중간 단계를 여러 노드로 나눕니다.

151
00:17:08,000 --> 00:17:14,000
실제로 생각의 흐름을 연결 목록으로 생각할 수 있습니다. 그렇죠?

152
00:17:14,000 --> 00:17:21,000
연결된 목록에는 노드의 시작점이 있고 연결 목록의 꼬리가 있습니다.

153
00:17:21,000 --> 00:17:28,000
자기 일관성 버전의 생각에서는 이것을 병렬 연결 목록으로 생각할 수 있습니다.

154
00:17:28,000 --> 00:17:33,000
연결리스트가 많습니다. 여기에는 많은 답변이 있습니다.

155
00:17:33,000 --> 00:17:45,000
마지막으로 세 개의 병렬 연결 목록이 있고 다수결 투표를 사용하여 투표하고 집계하고 정답을 얻는다고 가정해 보겠습니다.

156
00:17:45,000 --> 00:17:55,000
반드시 정확하지는 않지만 이 경우에는 대부분의 사람들이 동의하는 것에 동의합니다.

157
00:17:55,000 --> 00:18:01,000
우리는 추론 경로가 동의하는 것에 동의합니다.

158
00:18:01,000 --> 00:18:05,000
그래서 우리는 두 개의 정답과 하나의 오답을 갖게 되었습니다.

159
00:18:05,000 --> 00:18:11,000
그리고 마지막으로 집계 후 정답이 출력됩니다.

160
00:18:11,000 --> 00:18:18,000
그래서 여기에 우리가 일련의 사고의 자기 일관성 버전을 구성하는 방법이 있습니다.

161
00:18:18,000 --> 00:18:21,000
첫째, 우리는 일련의 사고를 통해 언어 모델을 촉발합니다.

162
00:18:21,000 --> 00:18:27,000
그런 다음 두 번째 단계에서는 언어 모델 디코더에서 샘플링하여 다양한 추론 경로를 얻습니다.

163
00:18:27,000 --> 00:18:33,000
그리고 마지막 답변이 가장 일관성 있는 답변으로 선택됩니다. 이 경우에는 단지 다수결입니다.

164
00:18:33,000 --> 00:18:42,000
그러나 여기에서 볼 수 있듯이 순전히 순진한 사고 유도 방식을 사용하는 경우 언어 모델에서 그리드 방식으로 디코딩하는 것입니다.

165
00:18:42,000 --> 00:18:55,000
따라서 생각의 흐름에 일부 자기 일관성 구성 요소를 추가하는 경우 언어 모델을 따라 세 가지 다양한 추론 경로를 샘플링할 수 있습니다.

166
00:18:55,000 --> 00:19:00,000
그런 다음 보시다시피 다수결 투표를 사용하여 이를 집계할 수 있습니다.

167
00:19:00,000 --> 00:19:04,000
그 중 두 개는 정답이고, 한 개는 틀린 답입니다.

168
00:19:04,000 --> 00:19:12,000
그리고 우리는 하나의 최종 정답인 18을 집계하기 위해 추론 경로를 소외시킵니다. 이것이 맞습니다.

169
00:19:12,000 --> 00:19:15,000
여기에도 질문의 예가 ​​있습니다.

170
00:19:15,000 --> 00:19:20,000
당신은 잘못된 대답으로 그리드 방식으로 디코딩하고 간단한 경로, 하나의 간단한 경로를 가지고 있습니다.

171
00:19:20,000 --> 00:19:27,000
이것은 자기 일관성 버전의 사고 방식입니다.

172
00:19:27,000 --> 00:19:34,000
대부분의 경우 숨기고 싶지 않기 때문에 모든 샘플 경로를 사용하고 있습니다.

173
00:19:34,000 --> 00:19:39,000
하나의 정답과 하나의 오답이 있고 이를 집계하는 방법을 모른다고 가정해 보겠습니다.

174
00:19:39,000 --> 00:19:47,000
그래서 우리는 세 가지 추론 경로를 사용하고 있습니다. 여기에는 그 중 두 가지만 나열하겠습니다.

175
00:19:47,000 --> 00:19:53,000
이것이 바로 자기 일관성의 메커니즘을 이해하는 것입니다.

176
00:19:53,000 --> 00:19:58,000
따라서 디코더 출력을 두 부분으로 분해해야 합니다.

177
00:19:58,000 --> 00:20:05,000
추론 경로 R1이 포함된 첫 번째 부분과 A1이 포함된 최종 답변입니다.

178
00:20:05,000 --> 00:20:09,000
따라서 R1이 A1으로 연결됩니다.

179
00:20:09,000 --> 00:20:15,000
따라서 다음 질문은 디코더 출력을 얻은 후 답변을 구문 분석하는 방법입니다.

180
00:20:15,000 --> 00:20:21,000
파서는 작업에 따라 다릅니다.

181
00:20:21,000 --> 00:20:28,000
따라서 산술 추론을 위해 모델이 생성된 후 첫 번째 숫자 부분을 최종 답으로 구문 분석합니다.

182
00:20:28,000 --> 00:20:30,000
대답은 어쩌고 저쩌고입니다.

183
00:20:30,000 --> 00:20:36,000
그리고 상식적인 추론을 위해 모델이 생성된 후 전체 문자열을 최종 답변으로 구문 분석합니다.

184
00:20:36,000 --> 00:20:39,000
대답은 무엇입니까? 무엇.

185
00:20:39,000 --> 00:20:46,000
여기서 볼 수 있듯이 질문이 있고 추론 경로가 있으며 답변이 있습니다.

186
00:20:46,000 --> 00:20:54,000
그들은 모두 동일한 구조를 따릅니다. 대답은 무엇입니까? 이 두 가지 예 모두에서.

187
00:20:54,000 --> 00:21:04,000
간단히 말해서, 생성된 대부분의 출력은 일관된 추론 경로 형식을 갖습니다.

188
00:21:04,000 --> 00:21:14,000
그리고 대답은 무엇입니까? 이 형식으로 언어 모델을 프롬프트하는 경우.

189
00:21:14,000 --> 00:21:21,000
따라서 두 가지 집계 접근 방식이 있습니다. 첫 번째 접근 방식은 양식 투표입니다.

190
00:21:21,000 --> 00:21:26,000
우리는 양식 클래스가 무엇이든 취합니다.

191
00:21:26,000 --> 00:21:31,000
또한 각 추론 및 답변 경로의 확률에 가중치를 부여했습니다.

192
00:21:31,000 --> 00:21:35,000
프롬프트와 질문에 따라 달라지는 정규화되지 않은 확률이 있습니다.

193
00:21:35,000 --> 00:21:40,000
그리고 출력 길이에 따른 조건부 확률의 정규화된 버전도 있습니다.

194
00:21:40,000 --> 00:21:44,000
다음은 다양한 집계 접근 방식을 비교한 것입니다.

195
00:21:44,000 --> 00:21:48,000
여기에는 멋진 공식이 있지만, 멋진 수학 공식도 많이 있습니다.

196
00:21:48,000 --> 00:21:55,000
양식 투표는 스쿼트 하이에서 볼 수 있는 모든 모델 중에서 가장 좋은 성능을 달성했습니다.

197
00:21:55,000 --> 00:22:04,000
그래서 저자는 이후 섹션에서 양식 투표를 계속 사용하기로 결정했습니다.

198
00:22:04,000 --> 00:22:08,000
다음은 자기 일관성의 몇 가지 속성과 사람들이 이를 사용해야 하는 이유입니다.

199
00:22:08,000 --> 00:22:13,000
첫 번째는 추가 교육이나 사람이 추가로 주석을 달 필요가 없다는 것입니다.

200
00:22:13,000 --> 00:22:17,000
보조 모델도 없고 기능도 없고 아무것도 없습니다.

201
00:22:17,000 --> 00:22:22,000
또한 기성 알고리즘이기도 합니다.

202
00:22:22,000 --> 00:22:30,000
그리고 오늘부터 소통할 때, LGBT를 사용할 때,

203
00:22:30,000 --> 00:22:36,000
실제로 이것을 시도해 볼 수 있습니다. 일련의 사고 방식의 자기 일관성 버전을 시도해 보세요.

204
00:22:36,000 --> 00:22:48,000
단일 입력을 기반으로 일부 응답을 계속 생성할 수 있습니다.

205
00:22:48,000 --> 00:22:55,000
그리고 다시 시작 또는 재생성을 클릭하면 새로운 추론 경로가 제공됩니다.

206
00:22:55,000 --> 00:23:00,000
그리고 자신의 전문 지식을 바탕으로 수동으로 집계할 수도 있습니다.

207
00:23:00,000 --> 00:23:07,000
또한 샘플링 전략에 강력하고 프롬프트가 불완전하다는 장점도 있습니다.

208
00:23:07,000 --> 00:23:16,000
때로는 생각의 흐름이 성능에 해를 끼치는 반면 일관성 버전은 그렇지 않습니다.

209
00:23:16,000 --> 00:23:25,000
따라서 평가 부분에 대해 이 문서에서는 이전 일련의 사고 문서에서 사용된 것과 동일한 세 가지 벤치마크를 약간 변경하여 사용합니다.

210
00:23:25,000 --> 00:23:32,000
그들은 추론 문제에 AI를 도입하고 언어 모델 테스트 후보 목록에서 코덱을 제거했습니다.

211
00:23:32,000 --> 00:23:38,000
결과적으로 자기 일관성은 네 가지 언어 모델에 비해 세 가지 추론 성능을 모두 향상시켰습니다.

212
00:23:38,000 --> 00:23:46,000
이것은 일련의 사고 유도에 비해 상당히 증가했습니다.

213
00:23:46,000 --> 00:23:56,000
이전에 논의한 것처럼, 이전의 한 연구에서는 순진한 생각의 흐름이 표준 프롬프트에 비해 잠재적으로 성과를 해칠 수 있음을 보여주었습니다.

214
00:23:56,000 --> 00:24:02,000
그러나 자체 일관성은 표준 프롬프트에 비해 성능을 강력하게 향상시킬 수 있습니다.

215
00:24:02,000 --> 00:24:10,000
이 연구에서 저자는 또한 인간 주석자가 프롬프트를 만들 때 사소한 실수를 하는 경우가 있다고 보고했습니다.

216
00:24:10,000 --> 00:24:18,000
자체 일관성은 불완전한 프롬프트에 대한 언어 모델 견고성을 향상시키는 데 도움이 될 수 있습니다.

217
00:24:18,000 --> 00:24:24,000
그래서 또 다른 발견은 추론 경로가 많을수록 좋다는 것입니다.

218
00:24:24,000 --> 00:24:34,000
더 많은 추론 경로를 샘플링하면 문제 해결률 측면에서 더 큰 호기심을 갖게 될 것입니다.

219
00:24:34,000 --> 00:24:36,000
그럼 여기 두 번째 논문이 있습니다.

220
00:24:36,000 --> 00:24:42,000
제가 이야기할 세 번째 논문은 생각을 촉발하는 기차입니다.

221
00:24:42,000 --> 00:24:57,000
연결 목록, 아마도 데이터 구조 일대일 과정, 다음에 배울 내용, 다음 주제를 배운 후에 이 비유를 들어보겠습니다.

222
00:24:57,000 --> 00:25:07,000
대부분의 사람들은 연결리스트를 배우고 나면 트리 구조를 배운다고 대답할 것 같아요.

223
00:25:07,000 --> 00:25:09,000
그러니 당신이 퍼즐을 풀고 있다고 상상해 보세요.

224
00:25:09,000 --> 00:25:12,000
당신은 항상 간단한 방식으로 생각하지 않습니다.

225
00:25:12,000 --> 00:25:23,000
한 단계 더 나아가 두 단계 뒤로 물러나서 문제를 해결하기 위한 최선의 접근 방식이 무엇인지 알아내려고 노력합니다.

226
00:25:23,000 --> 00:25:28,000
당신은 아래에서 위로 생각하는 것이 아닙니다.

227
00:25:28,000 --> 00:25:34,000
그러다가 당신은 이것이 내가 할 방식이 아니라는 것을 알게 되고, 당신은 다시 시작하고, 다시 시작합니다.

228
00:25:34,000 --> 00:25:36,000
아니요, 이 방법이 아닙니다.

229
00:25:36,000 --> 00:25:39,000
따라서 사고가 항상 선형적인 것은 아닙니다.

230
00:25:39,000 --> 00:25:44,000
생각의 기차는 토큰 수준에서 왼쪽에서 오른쪽으로 의사 결정을 내리는 도구입니다.

231
00:25:44,000 --> 00:25:49,000
선형 유형에서는 왼쪽에서 오른쪽으로만 입력을 받을 수 있습니다.

232
00:25:49,000 --> 00:25:53,000
역추적 기능은 허용되지 않습니다. 그렇죠?

233
00:25:53,000 --> 00:26:04,000
따라서 생각의 나무의 목적은 토큰 수준 결정을 넘어 복잡한 문제 해결을 위한 언어 모델을 향상시키는 것입니다.

234
00:26:04,000 --> 00:26:12,000
그리고 그들은 다양한 추론 경로와 전략적 역추적을 만들기 시작한다고 자세히 설명합니다.

235
00:26:12,000 --> 00:26:17,000
여기 이 네 가지 프롬프트 방법을 모두 비교한 내용이 있습니다.

236
00:26:18,000 --> 00:26:28,000
이전 논문에서 논의한 것처럼, 사고열의 자기 일관성 버전은 병렬 연결 목록의 일부라는 비유를 사용합니다.

237
00:26:28,000 --> 00:26:36,000
최종 출력 단계에서 이를 집계하고 대다수 클래스를 선택합니다.

238
00:26:36,000 --> 00:26:38,000
역추적을 허용하지 않습니다.

239
00:26:38,000 --> 00:26:42,000
여기서 중간 단계에 있다고 가정해 보겠습니다.

240
00:26:42,000 --> 00:26:49,000
이 구조에서는 이전 노드로 돌아가서 다시 방문하는 것을 허용하지 않습니다.

241
00:26:49,000 --> 00:26:55,000
아마도 오류는 두 번째 단계에서 발생하지만 다시 돌아갈 수는 없습니다.

242
00:26:55,000 --> 00:26:59,000
그래서 생각을 불러일으키는 과정에서 우리는 이런 비유를 듣게 됩니다.

243
00:26:59,000 --> 00:27:08,000
모든 추론 경로는 트리 수준에서 위에서 아래로 이동할 수 있는 방식으로 분류되어 있습니다.

244
00:27:08,000 --> 00:27:20,000
트리의 최하위 수준에 도달하면 올바른 추론 경로와 출력을 얻게 됩니다. 그렇죠?

245
00:27:20,000 --> 00:27:25,000
따라서 생각의 기차를 구축하기 위해 고려해야 할 몇 가지 사항이 있습니다.

246
00:27:25,000 --> 00:27:31,000
첫 번째는 중간 단계를 사고 과정으로 분해하는 방법입니다.

247
00:27:31,000 --> 00:27:40,000
복잡한 문제를 레이어, 다른 노드로 어떻게 분리합니까? 어떻게 결정합니까?

248
00:27:40,000 --> 00:27:43,000
각 상태에서 잠재적 사고를 생성하는 방법은 무엇입니까?

249
00:27:43,000 --> 00:27:50,000
만약 당신이 여기 있다면 어떻게 이 네 가지 후보를 모두 후계자로 생성할 수 있을까요?

250
00:27:50,000 --> 00:27:53,000
각 상태에서 이러한 잠재적인 생각을 모두 생성하는 방법은 무엇입니까?

251
00:27:53,000 --> 00:27:56,000
각 상태를 경험적으로 평가하는 방법은 무엇입니까?

252
00:27:56,000 --> 00:28:03,000
때때로 우리는 현재 노드가 유망하다고 생각하기 때문에 한 단계 앞으로 나아갈 필요가 있습니다.

253
00:28:03,000 --> 00:28:10,000
하지만 다음 단계에서 우리는 '아니요, 이게 작동하지 않아서 두 단계, 세 단계 뒤로 가야 할 것 같아요'라고 생각할 수도 있습니다.

254
00:28:10,000 --> 00:28:19,000
그렇다면 계속해서 이동할 것인지 이전 상태로 갈 것인지 결정하기 위해 각 상태를 경험적으로 평가하는 방법은 무엇일까요?

255
00:28:19,000 --> 00:28:25,000
그렇다면 우리가 생각의 흐름을 탐색할 때 사용할 수 있는 가장 좋은 검색 알고리즘은 무엇입니까?

256
00:28:25,000 --> 00:28:32,000
그리고 마지막 질문은 사고의 흐름을 평가하는 방법을 평가하는 작업은 무엇입니까?

257
00:28:32,000 --> 00:28:38,000
글쎄, 이 논문의 저자는 접근 방식을 평가하기 위해 세 가지 새로운 작업을 제안했습니다.

258
00:28:38,000 --> 00:28:40,000
첫 번째는 24일 경기다.

259
00:28:40,000 --> 00:28:49,000
보시다시피 우리는 4개의 숫자를 제공하고 24를 얻으려면 산술 연산을 사용해야 합니다.

260
00:28:49,000 --> 00:28:58,000
두 번째 과제는 창의적인 글쓰기로, 우리의 목표는 독창적인 이야기나 시를 생성하는 것입니다.

261
00:28:58,000 --> 00:29:03,000
세 번째 문제, 세 번째 과제는 십자말 풀이입니다.

262
00:29:03,000 --> 00:29:10,000
단서를 바탕으로 한 단어로 격자무늬를 느껴야 합니다.

263
00:29:10,000 --> 00:29:15,000
그럼 이 모든 세부 사항에 대해 하나씩 이야기해 보겠습니다.

264
00:29:15,000 --> 00:29:26,000
따라서 다음 사고 과정에 대한 후보를 생성할 때 실제로 두 가지 접근 방식이 있습니다.

265
00:29:26,000 --> 00:29:29,000
첫 번째 방법은 샘플 접근 방식입니다.

266
00:29:29,000 --> 00:29:31,000
두 번째는 제안이라고합니다.

267
00:29:31,000 --> 00:29:37,000
샘플은 일련의 사고 프롬프트를 통해 IID를 샘플링하는 것입니다.

268
00:29:37,000 --> 00:29:46,000
샘플은 사람들이 창의적인 글쓰기와 같이 더 넓은 사고 공간과 공간이 무수히 많은 작업을 할 때 더 잘 작동합니다.

269
00:29:46,000 --> 00:29:51,000
따라서 IID 샘플링은 사고 공간의 다양성을 높일 수 있습니다.

270
00:29:51,000 --> 00:30:05,000
우리는 더 나은 후계자를 얻고 싶기 때문에 사고 공간의 다양성을 풍부하게 해야 합니다.

271
00:30:05,000 --> 00:30:11,000
제안은 생각의 공간이 제한되어 있을 때 더 잘 작동합니다.

272
00:30:11,000 --> 00:30:16,000
이 경우 각 단계에서 선택할 수 있는 옵션이 몇 가지 밖에 없다고 가정해 보겠습니다.

273
00:30:16,000 --> 00:30:20,000
동일한 맥락에서 다른 생각을 제안하면 중복을 피할 수 있습니다.

274
00:30:20,000 --> 00:30:27,000
24 게임과 마찬가지로 다음 단계를 위해 선택할 수 있는 작업이 제한되어 있습니다.

275
00:30:27,000 --> 00:30:34,000
그리고 생각 단계에서 문제를 어떻게 분해하는지에 대한 또 다른 질문이 있습니다.

276
00:30:34,000 --> 00:30:38,000
한 단계는 너무 크거나 작을 수 없습니다.

277
00:30:38,000 --> 00:30:42,000
너무 크지도, 너무 크지도, 너무 작지도 않은 것이 좋습니다.

278
00:30:42,000 --> 00:30:55,000
따라서 우리가 24인 게임을 풀고 있다면 일련의 방정식이 아마도 중간 사고 단계의 좋은 후보가 될 수 있을 것입니다.

279
00:30:55,000 --> 00:31:02,000
그리고 우리가 경험적으로 상태를 평가하거나 알고 싶을 때 두 가지 접근 방식이 있습니다.

280
00:31:02,000 --> 00:31:06,000
첫 번째는 각 상태를 독립적으로 평가하는 것입니다.

281
00:31:06,000 --> 00:31:16,000
첫 번째 상태는 각 상태에 독립적입니다.

282
00:31:16,000 --> 00:31:26,000
이 접근 방식은 다른 가능한 단계의 더 넓은 맥락을 고려하지 않고 개별 단계의 실행 가능성을 신속하게 평가하는 데 사용됩니다.

283
00:31:26,000 --> 00:31:38,000
24 게임을 풀고 왼쪽 두 숫자가 3과 4이고 현재 결과가 12라고 가정해 보겠습니다.

284
00:31:38,000 --> 00:31:46,000
이는 12가 24의 절반이고 나머지 숫자에 잠재적으로 2를 곱하여 24에 도달할 수 있기 때문일 수 있습니다.

285
00:31:46,000 --> 00:31:48,000
실제로는 정확하지 않지만.

286
00:31:48,000 --> 00:31:55,000
두 번째 상태는 현재 결과가 10이고 왼쪽 두 자리 숫자가 7과 3이라는 것입니다.

287
00:31:55,000 --> 00:32:04,000
10은 출발점으로서 덜 이상적이기 때문에 상태 추정기에 의해 주어진 평가 결과는 가능성이 낮습니다.

288
00:32:04,000 --> 00:32:09,000
그리고 나머지 숫자를 합산하여 24가 되기가 더 어렵습니다.

289
00:32:09,000 --> 00:32:20,000
여러 주에 걸쳐 투표하는 또 다른 투표 접근 방식이 있습니다.

290
00:32:20,000 --> 00:32:24,000
우리가 십자말 풀이 문제를 해결하고 있다고 상상해보십시오.

291
00:32:24,000 --> 00:32:38,000
우리는 경쟁이 치열한 옵션 간에 결정을 내려야 할 때, 특히 한 옵션에 대해 다른 옵션에 대해 직접 평가가 명확하지 않을 때 이 방법을 사용합니다.

292
00:32:38,000 --> 00:32:47,000
그럼 수평 공간에 Apple을 채우고 있고 투표수가 3표라고 가정해 보겠습니다.

293
00:32:47,000 --> 00:32:51,000
두 번째 상태는 같은 공간인 살구를 채우는 것입니다.

294
00:32:51,000 --> 00:33:01,000
적합하기 때문에 두 표만 있지만 덜 일반적이므로 인접한 수직 느낌을 더 어렵게 만듭니다.

295
00:33:01,000 --> 00:33:05,000
우리는 이것을 더 어렵게 만듭니다.

296
00:33:05,000 --> 00:33:12,000
저자는 사고 트리를 탐색하는 두 가지 주요 접근 방식을 제시했습니다.

297
00:33:12,000 --> 00:33:15,000
첫 번째는 BFS이고 두 번째는 DFS입니다.

298
00:33:15,000 --> 00:33:20,000
이들 모두는 표준 BFS, DFS 알고리즘이며 화려하지는 않습니다.

299
00:33:20,000 --> 00:33:34,000
그러나 저자는 또한 A 별 검색과 같은 일부 경험적 검색이 향후 연구에서 잠재적으로 조사될 수 있다고 제안했습니다.

300
00:33:35,000 --> 00:33:48,000
여기서 볼 수 있는 것은 24인 게임에 대한 세 가지 중간 방정식과 사고 과정으로서의 짧은 글쓰기 계획, 창의적인 글쓰기의 사고 단계입니다.

301
00:33:48,000 --> 00:33:52,000
그리고 마무리를 위해 채워야 할 몇 가지 단어가 있습니다.

302
00:33:52,000 --> 00:33:59,000
몇 가지 백업 계획과 우리가 선택할 수 있는 몇 가지 후보가 있습니다.

303
00:33:59,000 --> 00:34:03,000
그럼 평가 부분에 대해 말씀드리겠습니다.

304
00:34:03,000 --> 00:34:07,000
우리는 세 가지 평가 텍스트를 사용하고 있으며 하나씩 살펴보겠습니다.

305
00:34:07,000 --> 00:34:12,000
첫 번째는 24의 게임을 해결하기 위해 시행적 사고를 사용하는 곳입니다.

306
00:34:12,000 --> 00:34:19,000
생각을 각각 중간 방정식인 세 단계로 분해하는 것은 매우 자연스러운 일입니다.

307
00:34:19,000 --> 00:34:28,000
마지막 단계에서는 계산에 한 자리가 사용되므로 두 단계로 분리하는 것이 매우 일반적입니다.

308
00:34:28,000 --> 00:34:37,000
네 자리 숫자가 있고 한 단계에 한 숫자를 사용하므로 네 단계가 있습니다.

309
00:34:37,000 --> 00:34:42,000
이 경우 하나의 독립적인 상태 추정기를 사용합니다.

310
00:34:42,000 --> 00:34:52,000
우리는 24에 도달하는 것과 관련하여 각 사고 후보를 확실함, 아마도, 예시 또는 불가능으로 평가하도록 언어 모델을 유도합니다.

311
00:34:52,000 --> 00:35:01,000
그럼 주요 결과 평가, 평가 결과표는 이렇습니다.

312
00:35:01,000 --> 00:35:13,000
표준 입력 출력은 프롬프트나 시험적 사고 프롬프트 또는 자기 일관성 프롬프트가 아니며 모두 작업 수행이 좋지 않습니다.

313
00:35:13,000 --> 00:35:30,000
대조적으로, 시도적 생각은 b의 폭이 1과 같을 때 이미 45%의 성공률을 달성한 반면, b가 5와 같을 때 트리를 더 넓은 범위로 확장하면 74%의 성공률을 달성합니다.

314
00:35:31,000 --> 00:35:44,000
저자는 또한 각 단계에서 여러 후보자를 방문할 수 있도록 시행사고를 모방하는 공정성을 보장하기 위해 시행사고와 표준 입력 및 출력 프롬프트에서 K 후보의 최고를 비교했습니다.

315
00:35:44,000 --> 00:36:00,000
하지만 보시다시피, 우리가 10개의 베스트 또는 100개의 베스트를 선택한다고 해도 시도에서 얻은 결과에 비해 성능이 상대적으로 낮습니다.

316
00:36:00,000 --> 00:36:05,000
크로스워드에 대한 또 다른 평가는 다음과 같습니다.

317
00:36:05,000 --> 00:36:18,000
설정은 우리가 생각을 최대 10단계로 분해할 수 있고 주 전체에 걸쳐 투표를 유도하는 제안을 사용하고 탐색 알고리즘, 검색 알고리즘으로 DFS를 선택했다는 것입니다.

318
00:36:18,000 --> 00:36:27,000
여기서도 볼 수 있듯이, 시행착오는 이번 게임에서 최고의 성공률을 달성했습니다.

319
00:36:27,000 --> 00:36:31,000
창의적인 글쓰기에서도 똑같은 일이 일어납니다.

320
00:36:35,000 --> 00:36:40,000
그럼 사고촉진 프로그램에 대해 이야기해 봅시다.

321
00:36:40,000 --> 00:36:46,000
사고 촉구 프로그램의 동기는 매우 직관적입니다. 아주 간단합니다.

322
00:36:47,000 --> 00:36:53,000
계산기가 있으면 수학을 수행하기 위해 언어 모델을 사용하는 이유는 무엇입니까?

323
00:36:53,000 --> 00:37:05,000
Python 인터프리터라는 인터프리터가 있으면 언어 모델이 프로그램을 실행하도록 하는 이유는 무엇입니까? 이 작업을 수행하는 동안 해당 인터프리터는 특정 목적으로 설계되지 않았습니다.

324
00:37:05,000 --> 00:37:16,000
우리는 추론 과정의 일부로 고급 도구를 사용하여 능력을 높일 수 있습니다.

325
00:37:16,000 --> 00:37:28,000
따라서 우리는 복잡한 계산을 프로그램 해석기에 위임하고 추론 및 언어 이해로부터 복잡한 계산을 분리합니다.

326
00:37:28,000 --> 00:37:34,000
다음은 언어 모델이 표현식 해결에 적합하지 않은 이유에 대한 몇 가지 예입니다.

327
00:37:34,000 --> 00:37:41,000
첫째, 언어 모델은 특히 숫자가 큰 경우 산술 계산에서 오류를 자주 범합니다.

328
00:37:41,000 --> 00:37:48,000
둘째, 다항식이나 미분 방정식과 같은 복잡한 수학 문제를 해결하는 데 어려움을 겪습니다.

329
00:37:48,000 --> 00:37:58,000
마지막으로 대규모 언어 모델은 특히 반복 횟수가 많은 경우 반복 프로세스를 처리하는 데 비효율적입니다.

330
00:37:58,000 --> 00:38:09,000
사고의 시험, 자기 일관성 등 모두 추론과 계산에 언어 모델을 사용하고 있습니다.

331
00:38:09,000 --> 00:38:13,000
사고 프로그램은 외부 계산을 위해 코드 해석기를 사용합니다.

332
00:38:13,000 --> 00:38:23,000
복잡한 방정식을 다단계 사고 과정으로 나누고 변수에 의미론적 의미를 할당합니다.

333
00:38:24,000 --> 00:38:30,000
그것이 이전의 모든 작업에서 내보내지는 이유입니다.

334
00:38:30,000 --> 00:38:32,000
두 가지 패러다임이 있습니다.

335
00:38:32,000 --> 00:38:37,000
첫 번째는 퓨샷 프롬프트이고 두 번째는 제로샷 프롬프트입니다.

336
00:38:37,000 --> 00:38:45,000
우리가 생각의 시험에서 하고 있는 것처럼 몇 번의 프롬프트에서는 질문과 생각의 몇 가지 예가 있습니다.

337
00:38:45,000 --> 00:38:56,000
그리고 제로샷에서는 거기에 질문을 입력하고 언어 모델이 실행 가능한 프로그램을 출력하도록 합니다.

338
00:39:00,000 --> 00:39:06,000
따라서 우리는 사고 프로그램을 중간 단계로 사용할 수도 있습니다.

339
00:39:06,000 --> 00:39:14,000
확실히 텍스트 추론과 계산 부분이 모두 필요한 몇 가지 문제가 있습니다.

340
00:39:14,000 --> 00:39:18,000
그래서 우리는 사고 프로그램을 분리할 수 있습니다.

341
00:39:18,000 --> 00:39:21,000
중간 단계로 사용할 수 있습니다.

342
00:39:21,000 --> 00:39:28,000
여기에서 우리가 사고 프레임워크의 프로그램에 질문을 입력하면 프로그램이 생성되는 것을 볼 수 있습니다.

343
00:39:28,000 --> 00:39:33,000
프로그램은 외부 통역사에 의해 실행되며 결과를 얻게 됩니다.

344
00:39:33,000 --> 00:39:38,000
결과는 계속해서 생각을 시험해 볼 것입니다.

345
00:39:38,000 --> 00:39:50,000
우리는 통역사로부터 결과를 얻기 위해 생각의 시험을 사용할 수도 있고, 질문이 끝나면 거기서 멈추고 직접 답변을 얻을 수도 있습니다.

346
00:39:50,000 --> 00:39:56,000
다음은 용어 번호를 계산하도록 언어 모델에 요청하는 예입니다.

347
00:39:56,000 --> 00:39:59,000
왼쪽에서는 생각의 시험을 사용하고 있습니다.

348
00:39:59,000 --> 00:40:01,000
분명히 이것은 옳지 않습니다.

349
00:40:01,000 --> 00:40:04,000
임의의 숫자를 출력하면 됩니다.

350
00:40:04,000 --> 00:40:06,000
단지 추측일 뿐입니다.

351
00:40:06,000 --> 00:40:10,000
이 답변을 생성하는 방법 뒤에는 논리가 없습니다.

352
00:40:10,000 --> 00:40:19,000
그러나 생각의 프로그램에서는 매우 훌륭하게 작성된 실행 가능한 프로그램이 생성됩니다.

353
00:40:19,000 --> 00:40:26,000
그리고 최종 답을 얻기 위해 Python 인터프리터로 프로그램을 실행하기만 하면 됩니다.

354
00:40:26,000 --> 00:40:29,000
이것은 꽤 좋은 것입니다.

355
00:40:29,000 --> 00:40:41,000
평가 부분에서는 이전 연구와 유사하게 수행된 5개의 수학 문제 데이터 세트를 사용합니다.

356
00:40:41,000 --> 00:40:53,000
또한 세 가지 금융 데이터 세트를 도입했습니다.

357
00:40:53,000 --> 00:40:58,000
다음은 이 문서에 대한 몇 가지 구현 세부 사항입니다.

358
00:40:58,000 --> 00:41:04,000
그들은 주로 codec002 코덱을 사용했지만 3.0과 람다도 사용했습니다.

359
00:41:04,000 --> 00:41:14,000
그들은 난이도에 따라 모든 데이터 세트에 4~8개의 샷을 사용했습니다.

360
00:41:14,000 --> 00:41:25,000
그리고 우리가 비교하고 있는 기준선은 주로 다수결 집계 모델을 사용하는 자체 일관성 버전에 대한 생각의 시험입니다.

361
00:41:25,000 --> 00:41:29,000
다음은 생각의 재판 결과입니다.

362
00:41:29,000 --> 00:41:38,000
몇 가지 짧은 학습을 통해 자체 일관성 버전의 사고 시도에 비해 수학 데이터 세트에서 8%의 이득을 달성했습니다.

363
00:41:38,000 --> 00:41:42,000
그리고 금융 데이터 세트에서 50%의 이익을 얻었습니다.

364
00:41:42,000 --> 00:41:47,000
제로 숏 설정에서는 수학 데이터 세트에서 12%의 이득을 얻었습니다.

365
00:41:47,000 --> 00:42:01,000
따라서 평균적으로 자기 일관성을 갖춘 사고 프로그램의 성능은 순진한 자기 일관성 사고 실험에 비해 10% 더 나았습니다.

366
00:42:01,000 --> 00:42:05,000
다음은 몇 가지 평가 지표입니다.

367
00:42:05,000 --> 00:42:17,000
그래서 제로샷 설정에서는 보시다시피 제로샷처럼 이전 작업에 비해 본 논문은 최첨단을 이루었고,

368
00:42:17,000 --> 00:42:21,000
생각을 시험해 보면 3번 또는 0번의 샷이 나올 수도 있습니다.

369
00:42:21,000 --> 00:42:27,000
훨씬 더 높고, 이 둘 사이에는 매우 큰 격차가 있습니다.

370
00:42:27,000 --> 00:42:29,000
꽤 큽니다.

371
00:42:29,000 --> 00:42:34,000
그리고 몇 번의 샷 구성에서도 같은 일이 발생합니다.

372
00:42:34,000 --> 00:42:44,000
보시다시피 굵은 글씨는 모두 최신 기술을 나타내며 모든 모델 중 최고의 성능을 나타냅니다.

373
00:42:44,000 --> 00:42:55,000
이제 우리가 이야기할 논문은 대규모 언어 모델에서 복잡한 추론을 가능하게 합니다.

374
00:42:55,000 --> 00:42:58,000
이제 문제 설명부터 시작하겠습니다.

375
00:42:58,000 --> 00:43:14,000
지금 소개할 다음 모델은 모두 생각의 사슬 모델과 여기의 생각의 사슬을 기반으로 하기 때문에 우리는 생각의 사슬이 먼저 이해가 필요한 작업에 대한 어려움이라는 것을 알고 있습니다.

376
00:43:14,000 --> 00:43:20,000
그런 다음 쉬운 문제부터 더 복잡한 문제까지 지식을 일반화합니다.

377
00:43:20,000 --> 00:43:30,000
기본적으로 내 말은 제공된 프롬프트의 예제가 테스트 사례보다 훨씬 쉬울 때 일련의 생각이 제대로 수행되지 않는다는 것입니다.

378
00:43:30,000 --> 00:43:41,000
그리고 일반적인 일반화 작업에는 기호 조작, 구성 일반화, 수치 추론 등이 포함됩니다.

379
00:43:41,000 --> 00:43:51,000
따라서 일반화 작업에서 언어 모델의 성능을 향상시키기 위해 저자는 최소 프롬프트에서 최대 프롬프트까지의 아이디어를 제안했습니다.

380
00:43:51,000 --> 00:43:58,000
그리고 이 아이디어는 매우 직관적이므로 이제 이에 대해 더 자세히 설명하겠습니다.

381
00:43:58,000 --> 00:44:09,000
따라서 가장 자극적인 두 가지 프롬프트에는 두 가지 유형의 프롬프트가 있습니다. 기본적으로 두 단계가 있기 때문에 지금부터 각 단계를 살펴보겠습니다.

382
00:44:09,000 --> 00:44:17,000
그래서 그들은 우리가 1단계에서 이 수학 문제를 해결하려고 한다고 말합니다.

383
00:44:17,000 --> 00:44:26,000
그래서 그것은 새로운 질문이고, 저자들은 여기서 질문이 어떻게 줄어들었는지에 대한 예를 제시했습니다.

384
00:44:26,000 --> 00:44:37,000
여기서 우리는 질문을 볼 수 있습니다. 첫 번째 질문은 슬라이드가 닫힐 때까지 에이미가 몇 번이나 슬라이드할 수 있느냐는 것입니다.

385
00:44:37,000 --> 00:44:44,000
그런 다음 이를 대규모 언어 모델에 입력합니다.

386
00:44:44,000 --> 00:44:53,000
그리고 모델은 먼저 이 질문을 두 개의 하위 질문으로 분해합니다.

387
00:44:53,000 --> 00:45:06,000
그리고 여기에 생각의 단계가 있습니다. 따라서 문이 닫히기 전에 그녀가 몇 번이나 미끄러질 수 있는지를 계산하려면 먼저 각 이동에 걸리는 시간을 계산해야 합니다.

388
00:45:06,000 --> 00:45:12,000
그래서 이것은 기본적으로 첫 번째 하위 질문, 즉 하위 질문 1입니다.

389
00:45:12,000 --> 00:45:19,000
그리고 모델은 먼저 하위 질문 1을 언어 모델에 대한 새로운 입력으로 사용합니다.

390
00:45:19,000 --> 00:45:27,000
그런 다음 언어 모델은 하위 질문을 처리하고 이 하위 질문에 대한 답변을 구체적으로 제공합니다.

391
00:45:27,000 --> 00:45:34,000
대답은 '오르는 데 4분, 미끄러지는 데 1분이 걸리고 4 더하기 1은 5'라는 것입니다.

392
00:45:34,000 --> 00:45:38,000
따라서 Amy는 각 여행에 약 5분 정도 걸립니다. Amy는 5분 정도 걸립니다.

393
00:45:38,000 --> 00:45:56,000
자, 하위 질문 1에 대한 답변을 얻은 후에는 이제 하위 질문 1에 대한 답변을 모두 취하고 하위 질문 2와 결합하여 여기서 모델에 대한 새로운 입력으로 사용할 수 있습니다.

394
00:45:56,000 --> 00:46:17,000
그러면 이제 모델은 기본적으로 답변을 입력으로 처리하고 하위 질문 2에 대한 답변을 얻을 수 있습니다. 이는 또한 최종 질문이자 초기 질문에 대한 최종 답변이기도 합니다.

395
00:46:17,000 --> 00:46:24,000
따라서 각 이동에는 5분이 걸리며, 각 이동에는 5분이 걸립니다. 하위 질문 1에 대한 답변입니다.

396
00:46:24,000 --> 00:46:37,000
그리고 에이미. 따라서 다음 단계는 Amy가 닫히기 전에 15를 5로 나눈 값이 3번이 되는 슬라이드를 만드는 것입니다.

397
00:46:37,000 --> 00:46:44,000
이것은 하위 질문 2에 대한 답변이자 초기 질문에 대한 답변이기도 합니다.

398
00:46:45,000 --> 00:46:54,000
네, 기본적으로 가장 적은 메시지부터 가장 많은 메시지가 작동하는 방식입니다. 그리고 이 예에서는 시연을 위해 모든 프롬프트가 생략되었습니다.

399
00:46:54,000 --> 00:47:01,000
그리고 두 단계 모두, 두 단계 모두에 대한 프롬프트는 연료 부족 프롬프트입니다.

400
00:47:01,000 --> 00:47:11,000
그리고 이 방법은 생각의 연쇄나 자기 일관성과 같은 다른 자극 기법과 결합될 수 있습니다.

401
00:47:11,000 --> 00:47:16,000
좋아요, 이제 질문을 더 평가하겠습니다.

402
00:47:16,000 --> 00:47:25,000
그래서 저자는 문제 설명 부분에서 언급한 일반적인 세 ​​가지 일반화 작업을 사용하여 이 모델을 평가합니다.

403
00:47:25,000 --> 00:47:33,000
첫 번째는 상징적 조작입니다. 좋아하는 작업은 마지막 문자 연결입니다.

404
00:47:33,000 --> 00:47:48,000
그리고 이 작업은 이미 이전 모델과 유사한 모델에서 이전 모델을 소개하는 것과 같으므로 자세히 설명하지 않겠습니다.

405
00:47:48,000 --> 00:48:01,000
그리고 테스트를 구성하기 위해 테스트 목록은 기본적으로 위키 사전에서 단어를 무작위로 선택하고 목록 길이는 4개에서 12개 단어까지 다양합니다.

406
00:48:01,000 --> 00:48:09,000
따라서 테스트 세트, 가장 짧은 테스트 세트는 네 단어와 같습니다.

407
00:48:09,000 --> 00:48:15,000
그리고 가장 긴 테스트 세트 구성은 12개의 영어 단어로 구성됩니다.

408
00:48:15,000 --> 00:48:23,000
따라서 각 테스트, 각 테스트 목록은 500개의 예제로 구성됩니다.

409
00:48:23,000 --> 00:48:35,000
하지만 여기서 123455번째 줄을 볼 수 있듯이 Da Vinci 002만 해당됩니다.

410
00:48:35,000 --> 00:48:42,000
따라서 이에 대한 테스트 세트는 다른 모든 테스트 세트의 경우 500단어가 아닌 100단어입니다.

411
00:48:42,000 --> 00:48:49,000
그리고 베이스라인, 베이스라인 모델 프롬프트 방법은 표준 프롬프트입니다.

412
00:48:49,000 --> 00:49:01,000
그리고 몇 가지 주요 발견에는 Da Vinci 002 텍스트가 작은 목록 크기에서 Da Vinci 002 코드와 유사한 정확도를 보이는 반면 포함됩니다.

413
00:49:01,000 --> 00:49:10,000
큰 목록 크기로 이동하면 정확도가 훨씬 더 빨리 떨어집니다. 그리고 그것은 기본적으로 생각의 사슬과 최소한 대부분 동일합니다.

414
00:49:10,000 --> 00:49:13,000
여기에서 볼 수 있듯이.

415
00:49:13,000 --> 00:49:20,000
그래서 텍스트 텍스트 Da Vinci는 둘 다 좋아했습니다.

416
00:49:20,000 --> 00:49:27,000
아.

417
00:49:27,000 --> 00:49:38,000
작은 목록 크기에서는 텍스트 Da Vinci와 코드 Da Vinci가 모두 91 정도, 89 정도에서 91 정도입니다.

418
00:49:38,000 --> 00:49:46,000
그리고 가장 작은 것은 94, 96과 같습니다. 그러니까 그것들은 90년대 정도, 모두 90년대 정도입니다.

419
00:49:46,000 --> 00:49:58,000
그리고 테스트 세트의 길이가 길어질수록 정확도가 가장 낮아질수록 실제로는 14가 됩니다.

420
00:49:59,000 --> 00:50:04,000
여기에서 두 가지 예의 텍스트를 볼 수 있습니다.

421
00:50:04,000 --> 00:50:18,000
뭐, 가장 짧은 것은 87. 가장 긴 것은 14입니다. 그래서 14 대 38.4를 볼 수 있는 코드 002 모델보다 훨씬 빠르게 감소합니다.

422
00:50:18,000 --> 00:50:27,000
이처럼 끝나는 지점이 다르면 차이가 많이 나지만 시작 지점은 비슷합니다. 그래서 그것은 그들이 감소하는 속도가 훨씬 빠르다는 것을 의미합니다.

423
00:50:27,000 --> 00:50:39,000
그리고 아래로 내려가면 Da Vinci 002 모델의 코드가 마지막 연결과 같은 반복 및 재귀가 포함된 질문에 유리하다는 것을 알 수 있습니다.

424
00:50:39,000 --> 00:50:45,000
좋아요, 다음은 구성적 일반화 일반화 작업입니다.

425
00:50:45,000 --> 00:50:59,000
그리고 임무는 자연어 명령을 동작 순서에 매핑하는 것입니다. 그리고 여기 화면 오른쪽에 작은 예를 보여드리겠습니다.

426
00:51:00,000 --> 00:51:20,000
예를 들어 언어 명령은 반대쪽 오른쪽으로 회전하는 것이고 결과 응답 문자열은 오른쪽으로 2번 회전하는 것과 같지만 실제로는 같은 정리를 위해 더 간결하게 만들기 위한 Python 표기법입니다.

427
00:51:21,000 --> 00:51:34,000
자연어로 더 많은 것을 표현하기 위해 전체를 입력하면 오른쪽으로 두 번 돌리는 대신 오른쪽으로 돌고 이어서 오른쪽으로 도는 것과 같을 것입니다.

428
00:51:34,000 --> 00:51:47,000
자, 여기서 사용된 데이터 세트는 스캔 데이터 세트입니다. 이것은 이런 종류의 질문에 대한 벤치마크 데이터 세트이고 대규모 언어 모델은 채팅 GBT 3의 코드 Da Vinci 002입니다.

429
00:51:48,000 --> 00:52:00,000
그래서 여기에 가장 자극적인 생각 엔진으로 이어지는 방법을 보여주는 또 다른 예가 있습니다. 묻는 것처럼 물어보세요.

430
00:52:00,000 --> 00:52:08,000
어떻게, 두 가지 메시지 방법이 코스 모딩 답변과 어떻게 작동하는지. 좋아요.

431
00:52:08,000 --> 00:52:29,000
그리고 마지막. 아, 결과는 화면에서 볼 수 있듯이 최소한 대부분의 프롬프트 방법에 대한 정확도가 표준 프롬프트 엔진보다 훨씬 높다는 결과를 화면에서 볼 수 있다는 것입니다.

432
00:52:29,000 --> 00:52:42,000
가장 낮은 정확도라도 가장 낮은 정확도는 약 60.7이지만 프롬프트 방법에 대한 가장 높은 정확도는 17보다 훨씬 낮다는 것을 알 수 있습니다.

433
00:52:42,000 --> 00:52:50,000
따라서 적어도 대부분의 개선 사항은 정말 놀랍습니다.

434
00:52:51,000 --> 00:53:09,000
아, 그리고 Da Vinci 002 텍스트에 대한 결과는 기본적으로 해결 속도가 변하지 않기 때문에 100개 명령의 무작위 하위 집합을 기반으로 하므로 전체 세트에 대해 테스트를 사용하든 아니면 그냥 사용하든 상관이 없습니다. 아니면 그냥 100개의 댓글을 사용하세요.

435
00:53:09,000 --> 00:53:22,000
좋습니다. 이제 마지막 평가인 수학 추론을 시작하겠습니다. 이 평가의 임무는 모델에 다양한 수학 문제를 해결하도록 요청하는 것입니다.

436
00:53:22,000 --> 00:53:37,000
그리고 여기서 사용하는 데이터 세트는 GSM AK와 드롭 데이터 세트입니다. 따라서 이 두 데이터 세트는 벤치마크 데이터 세트와도 같습니다. 원한다면, 더 자세히 알아보고 싶다면 논문을 읽어보는 것이 좋습니다.

437
00:53:37,000 --> 00:53:57,000
나는 그것에 대해 너무 자세히 설명하지 않습니다. 그리고 여기에서 사용되는 언어 모델은 코드 Da Vinci 002이기도 합니다. 화면 오른쪽에는 생각 유도 엔진이 얼마나 적게 또는 가장 많이 유도하는지 보여주는 두 가지 예가 있습니다.

438
00:53:57,000 --> 00:54:08,000
그리고 결과를 보면, 아, 여기에서 사용된 프롬프트 방법은 Zoro shop 프롬프트 표준 프롬프트 열차이며 가장 적게 유도하는 것부터 가장 많이 유도하는 것까지 볼 수 있습니다.

439
00:54:09,000 --> 00:54:23,000
따라서 여기서 볼 수 있듯이 결과도 매우 분명합니다. 가장 적은 것부터 가장 많은 것을 요구하는 것이 모든 데이터 세트에서 가장 좋은 양 또는 방법으로 작동합니다.

440
00:54:24,000 --> 00:54:36,000
좋아요, 가장 적은 유도 방법부터 가장 많은 유도 방법의 일부 제한은 대부분 1단계에 대한 것입니다. 그래서 분해 단계.

441
00:54:37,000 --> 00:55:01,000
이 단계에서는 메시지가 일반적으로 여러 도메인에 걸쳐 잘 일반화되지 않습니다. 따라서 이 기술을 다른 분야에 적용하고 싶다면 일반적이고 일반적인 사례를 사용하기보다는 좀 더 구체적인 프롬프트 사례, 프롬프트 예시를 생각해 보고 싶을 것입니다.

442
00:55:01,000 --> 00:55:12,000
둘째, 이 단계 1은 동일한 영역 내에서도 어려울 수 있습니다. 그래서 제 생각에는 케이스 바이 케이스라고 생각합니다. 이 기술을 사용할 때는 좀 더 주의하세요.

443
00:55:13,000 --> 00:55:23,000
좋아요, 이제 우리는 언어 모델의 구성성 격차를 측정하고 줄이는 두 번째 논문을 시작하겠습니다.

444
00:55:24,000 --> 00:55:28,000
실례합니다.

445
00:55:29,000 --> 00:55:52,000
저자에 따르면. 음, 언어 모델은 강력한 질문 응답 성능을 보여주었습니다. 그러나 얼마나 큰 말뭉치를 가지고 있고 언어 모델이 거기에서 검색하여 정답을 추출하기 때문에 그것이 얼마나 정답과 같은지는 여전히 불분명합니다.

446
00:55:53,000 --> 00:56:08,000
거대한 내부 데이터 세트처럼 실제로 추론 기술과 다른 방식으로 추론을 수행하고 거대한 말뭉치에서 답변을 추론할 수 있습니다.

447
00:56:08,000 --> 00:56:19,000
그래서 이를 측정하기 위해 먼저 구성성, 언어의 구성 능력, 다중 홉 추론을 갖춘 대규모 언어 모델을 정량화합니다.

448
00:56:20,000 --> 00:56:34,000
그리고 소위 말하는 용어는 구성성 격차이다. 이를 위해 그들은 자신만의 데이터 세트인 구성 세포 유명인이라는 새로운 데이터 세트를 도입합니다. 그래서 이 데이터 세트는

449
00:56:35,000 --> 00:56:43,000
무료로 명시된 사실을 있을 법하지 않은 방식으로 결합합니다. 그리고 각 사실은 훈련 데이터 세트에서 여러 번 나타날 가능성이 높습니다.

450
00:56:44,000 --> 00:56:58,000
그러나 두 가지 사실을 결합하기 위해 부자연스러운 방법을 사용했을 뿐입니다. 따라서 두 사실의 조합은 충분히 부자연스럽기 때문에 훈련 세트나 인터넷에도 결코 나타나지 않을 것입니다.

451
00:56:58,000 --> 00:57:13,000
CC 데이터 세트의 두 가지 예는 다음과 같습니다. 하나의 예는 레비(Levy)의 탄생지인 모아나(Moana)와 와사(Wasa)의 탄생일의 수도가 무엇인지입니다.

452
00:57:14,000 --> 00:57:17,000
정답은 루사카입니다. 그래서 기본적으로,

453
00:57:18,000 --> 00:57:20,000
그래서 그게 뭐야?

454
00:57:23,000 --> 00:57:37,000
그래서 레비, 모아나, 와사의 출생지가 무엇인지 물어보면 온라인에서 이 질문을 검색하는 것처럼 얻을 수 있고 인터넷에서 정답을 줄 것입니다.

455
00:57:37,000 --> 00:58:00,000
그리고 그 장소의 수도가 무엇인지 검색하면 인터넷에서도 답변을 얻을 수 있습니다. 하지만 이 두 부분을 결합하는 방법은 매우 부자연스럽기 때문에 이 용어를 인터넷에 올려도 인터넷에서 정답을 얻을 가능성이 거의 없으며 이에 대한 내용은 이 프레젠테이션의 후반부에서 보여드리겠습니다.

456
00:58:01,000 --> 00:58:20,000
그리고 아, 예, 여기 회사는 구성성 격차에 대한 방정식입니다. 그리고 이 용어는 기본적으로 모델이 모든 하위 질문에 대해 정답을 생성할 수 있는 동안 얼마나 자주 측정하는지와 같습니다. 글쎄, 그것은 여전히 ​​전반적인 질문에 정확하게 대답할 수 없습니다.

457
00:58:21,000 --> 00:58:24,000
좋습니다. 이제 간략하게 다음과 같이 하겠습니다.

458
00:58:25,000 --> 00:58:39,000
예를 들어, 이 논문의 저자가 자신의 데이터 세트에서 GP GPT 3의 구성 능력을 어떻게 평가하는지 살펴보세요.

459
00:58:39,000 --> 00:58:50,000
화면에서 볼 수 있듯이 파란색 사각형이 있고 녹색 삼각형이 있고 녹색 같은 것들이 있습니다.

460
00:58:50,000 --> 00:59:12,000
따라서 파란색은 구성 질문을 나타내고 녹색 질문은 녹색 표시가 두 개의 하위 질문, 두 개, 두 개, 파란색 질문에 대한 두 개의 하위 질문을 나타냅니다.

461
00:59:12,000 --> 00:59:28,000
따라서 기본적으로 연결고리와 같은 의미의 간격, 파란색 계열과 녹색 계열 사이의 간격은 회사 외부의 구성, 즉 구성성 차이입니다.

462
00:59:29,000 --> 00:59:56,000
따라서 여기에서는 매개변수가 증가하는 것처럼 증가하는 반면, 파란색을 띠는 것과 녹색을 띠는 것 사이의 간격은 증가하는 것과 같아서 실제로 모델 크기를 늘려도 구성성 격차가 줄어들지 않음을 보여줍니다.

463
00:59:56,000 --> 01:00:15,000
따라서 기본적으로 모델이 더 큰 모델 크기로 세상을 더 많이 알고 있다고 해도 해당 지식을 구성하고 처리하는 능력이 향상된다는 의미는 아닙니다.

464
01:00:16,000 --> 01:00:29,000
그래서 이 문제를 해결하기 위해 여기에 문제가 있습니다. 그리고 이 문제를 해결하기 위해 문제를 더욱 정량화하기 위해 이 그래프도 구성합니다.

465
01:00:29,000 --> 01:00:42,000
그래서 기본적으로 그들은 GPT 3이 구성할 사실과 구성할 수 없는 사실을 작성자가 어떻게 결정할 수 있는지 묻습니다.

466
01:00:42,000 --> 01:00:50,000
아, 네, 그래서 제가 GPT 3이라는 말은 Da Vinci 002 모델을 의미합니다. 실제로는 비슷합니다. 네.

467
01:00:50,000 --> 01:01:02,000
여기 이 그래프에서 각 막대는 서로 다른 질문 세트를 나타내며, 각 세트에서 GPT 3개 모델은 질문의 두 부분 모두에 정확하게 답합니다.

468
01:01:02,000 --> 01:01:09,000
그래서 y축은 질문에 대한 대답의 정확성을 나타냅니다. 그렇죠?

469
01:01:09,000 --> 01:01:15,000
그리고 x축에서는 하위 질문의 당혹감이 최대입니다.

470
01:01:15,000 --> 01:01:27,000
따라서 이러한 세트는 각 질문에 대한 모델의 최대 난해함 수준을 기반으로 하는 질문과 같이 가장 어려운 것부터 가장 어려운 것 순으로 배열됩니다.

471
01:01:27,000 --> 01:01:35,000
따라서 기본적으로 혼란 수준이 높을수록 모델의 혼란 수준과 관련이 있습니다.

472
01:01:35,000 --> 01:01:42,000
따라서 이는 기본적으로 모델 자체도 확실하지 않으며 정답이 무엇인지도 확신하지 못한다는 의미입니다.

473
01:01:42,000 --> 01:01:49,000
여기 있는 각 막대는 이러한 질문 유형의 10%에 해당합니다.

474
01:01:49,000 --> 01:02:06,000
그래서 우리가 볼 수 있는 것처럼, 더 오른쪽에 있는 막대는 정답이 무엇인지 확신할 수 없는 모델의 견해를 나타냅니다.

475
01:02:06,000 --> 01:02:14,000
그리고 더 왼쪽에 있는 모델과 비교하여 모델은 유사한 정답이 무엇인지 꽤 확신합니다.

476
01:02:14,000 --> 01:02:20,000
정확도는 두 단계처럼 매우 뚜렷합니다.

477
01:02:20,000 --> 01:02:31,000
따라서 모델이 정답에 대해 더 확신을 가질수록 모델이 질문에 올바르게 답할 가능성이 더 높아진다는 것을 알 수 있습니다.

478
01:02:31,000 --> 01:02:45,000
그래서 이러한 영감을 바탕으로 그들은 다른 수단을 통해 유도된 프롬프트 아이디어를 제안했습니다. 이를 자체 질문 프롬프트라고도 합니다.

479
01:02:45,000 --> 01:02:51,000
따라서 이 프롬프트는 구성성 격차를 효과적이고 효과적으로 좁힐 수 있습니다.

480
01:02:51,000 --> 01:02:57,000
그런 다음 이 프롬프트가 어떻게 매우 빠르게 작동하는지 보여 드리겠습니다.

481
01:02:57,000 --> 01:03:10,000
여기 왼쪽의 그래프는 비교, 실례합니다, 직접 프롬프트 비교, 일련의 생각, Bamboogle의 질문에 대한 자체 질문 간의 구성을 보여줍니다.

482
01:03:10,000 --> 01:03:17,000
따라서 이 Bamboogle은 작성자가 직접 만든 또 다른 데이터 세트입니다.

483
01:03:17,000 --> 01:03:23,000
그래서 이 데이터 세트를 조금 있다가 최신으로 소개하겠습니다.

484
01:03:23,000 --> 01:03:32,000
따라서 여기에서 넓은 배경을 가진 텍스트는 프롬프트이고 녹색 배경을 가진 텍스트는 큰 언어 모델의 출력입니다.

485
01:03:32,000 --> 01:03:36,000
그리고 여기의 기본 텍스트는 질문입니다.

486
01:03:36,000 --> 01:03:42,000
따라서 프롬프트는 실제로 시연을 위해 단축된 예입니다.

487
01:03:42,000 --> 01:03:50,000
저자는 실제로 이 데이터 세트에 대해 4개의 짧은 프롬프트, 4개의 짧은 프롬프트, 4개의 짧은 프롬프트를 사용합니다.

488
01:03:50,000 --> 01:04:00,000
따라서 이 예에서 프롬프트 질문은 누가 더 오래 사는지, 즉 th 또는 hvw입니다.

489
01:04:00,000 --> 01:04:09,000
따라서 저자는 세 가지 유사한 측정 항목 모두에서 질문하고 대답하기 위해 동일한 설정을 사용합니다.

490
01:04:09,000 --> 01:04:15,000
그리고 유일한 변화는 저자가 질문에 답하는 과정을 구성하는 방식입니다.

491
01:04:15,000 --> 01:04:23,000
그리고 여기 모델은 내부 지식을 바탕으로 질문을 생성하고 이에 대한 답변을 제공합니다.

492
01:04:23,000 --> 01:04:31,000
하지만 이것은 모델이 훈련된 데이터 모델로 제한되는 것과 같습니다.

493
01:04:31,000 --> 01:04:36,000
또한 해당 데이터에 대한 새로운 정보를 추론하는 능력도 있습니다.

494
01:04:36,000 --> 01:04:49,000
따라서 질문에서 볼 수 있듯이 이 질문에 답하려면 먼저 이 자체 질문 모델을 사용하여 여기에 필요한 후속 질문을 스스로에게 물어보세요.

495
01:04:49,000 --> 01:04:51,000
대답은 '예'입니다.

496
01:04:51,000 --> 01:05:04,000
따라서 모델에 의해 생성된 초기 질문에 대한 첫 번째 후속 질문은 그가 죽었을 때 몇 살이었는지입니다.

497
01:05:04,000 --> 01:05:15,000
그런 다음 대답을 하면 모델은 후속 질문과 같이 즉각적인 대답을 생성합니다. 그러니까 그가 죽었을 때 그의 나이는 65세였다고 합니다.

498
01:05:15,000 --> 01:05:26,000
그런 다음 모델은 그가 죽었을 때 hv, hvw가 몇 살인지와 같은 후속 질문을 생성합니다.

499
01:05:26,000 --> 01:05:33,000
중간 답변은 이 사람이 죽었을 때 69세였다는 것입니다.

500
01:05:33,000 --> 01:05:45,000
그래서 이제 우리는 두 사람의 나이가 언제, 언제, 언제, 언제 죽었는지 알 수 있습니다.

501
01:05:45,000 --> 01:05:55,000
그리고 우리는 죽어가는 나이를 비교하여 누가 더 오래 살고, 누가 더 오래 사는지 알 수 있습니다.

502
01:05:55,000 --> 01:06:14,000
따라서 이제 모든 증거는 65 대 69와 같이 그녀의 hvw가 더 오래 산다는 최종 답변을 뒷받침하기에 충분합니다.

503
01:06:14,000 --> 01:06:16,000
그래서 마지막 질문은 hvw입니다.

504
01:06:16,000 --> 01:06:36,000
따라서 기본적으로 모델이 한 일은 모델이 충분한 단계에 도달할 때까지 후속 질문을 반복적으로 요청하여 좋아하고, 시뮬레이션하고, 시뮬레이션하고, 이 프로세스를 시뮬레이션하는 것입니다.

505
01:06:36,000 --> 01:06:45,000
최종 답변을 생성하는 데 필요하거나 필요한 모든 정보를 충분히 수집합니다.

506
01:06:46,000 --> 01:06:52,000
그리고 아, 여기서 후속 질문이 필요하다는 문구를 사용하면 됩니다.

507
01:06:52,000 --> 01:07:05,000
따라서 필요한 경우 모델은 마지막 단계까지 다양한 후속 질문을 반복적으로 생성하는 것을 좋아할 것입니다.

508
01:07:05,000 --> 01:07:14,000
그렇지 않다면 기본적으로 최종 답변을 뱉어내는 것과 같습니다.

509
01:07:14,000 --> 01:07:20,000
그래서 이 문구는 실제로도 약간 개선되었고, 결과도 개선되었습니다.

510
01:07:20,000 --> 01:07:31,000
그래서 저자는 왜 저자가 언급하는지에 대해서는 언급하지 않지만 그들도 이유를 모른다고 하지만 그들의 결과는 이것이 꽤 효과적이라는 것을 보여줍니다.

511
01:07:31,000 --> 01:07:34,000
그리고 전체 프로세스는 완전히 자동으로 이루어집니다.

512
01:07:34,000 --> 01:07:39,000
루프 속 인간과 같은 것은 없습니다.

513
01:07:39,000 --> 01:07:49,000
좋아, 방금 전에 언급했듯이 모든 유사한 작업은 모든 지식을 기반으로 하며 내부 데이터베이스를 기반으로 합니다.

514
01:07:49,000 --> 01:08:00,000
따라서 이 모델을 더욱 개선하기 위해 자체 질문 프롬프트 방법과 외부 검색 엔진을 결합합니다.

515
01:08:00,000 --> 01:08:14,000
따라서 이는 대규모 언어 모델이 자체 훈련 데이터 이상의 정보에 대해 영원한 외부 검색 엔진을 활용할 수 있도록 허용함으로써 프로세스를 확장합니다.

516
01:08:14,000 --> 01:08:25,000
따라서 이는 모델이 지식에 공백이 있는 경우, 모델에 최신 정보가 필요한 시기 또는 시기를 의미합니다.

517
01:08:26,000 --> 01:08:32,000
기본적으로 온라인에 접속하여 인터넷에서 최신 데이터 통계나 효과를 검색할 수 있습니다.

518
01:08:32,000 --> 01:08:42,000
그리고 이것은 기본적으로 각 하위 질문을 검색 엔진에 입력하는 과정을 보여주는 간단한 예입니다.

519
01:08:42,000 --> 01:08:48,000
그런 다음 다음 프롬프트에 대한 답변을 순서대로 추가했습니다.

520
01:08:48,000 --> 01:08:54,000
좋아요, 이제 평가와 새로운 대나무 제품 데이터 세트를 간략하게 살펴보겠습니다.

521
01:08:54,000 --> 01:09:06,000
따라서 이 데이터 세트에는 저자가 작성한 두 가지 홉 질문도 포함되어 있으며, 모든 질문은 인기 있는 인터넷 검색 엔진에서 답변하기가 충분히 어렵습니다.

522
01:09:06,000 --> 01:09:13,000
그러나 모든 뒷받침 증거와 마찬가지로 Wikipedia를 별도로 찾을 수도 있습니다.

523
01:09:13,000 --> 01:09:24,000
따라서 구성 아이디어는 실제로 CC 데이터 세트와 매우 유사하지만 다른 질문 세트와 마찬가지로 다릅니다.

524
01:09:24,000 --> 01:09:37,000
좋아요, 그리고 저자들은 기본 모델은 검색 엔진 및 대규모 언어 모델 후처리를 갖춘 검색 엔진과 같이 검색 엔진 자체를 직접적으로 유도하는 일련의 생각입니다.

525
01:09:37,000 --> 01:09:53,000
그리고 저자가 기본적으로 사용하는 것과 같은 언어 모델 사후 처리 기능을 갖춘 검색 엔진이 무엇을 의미합니까? 검색처럼 사용하고 온라인에 가서 답변을 검색하는 데 사용합니다.

526
01:09:53,000 --> 01:10:04,000
그런 다음 답변을 얻은 후 결국 002를 사용하여 검색 엔진에서 얻은 답변과 같은 최종 답변을 추출합니다.

527
01:10:05,000 --> 01:10:09,000
좋아요, 그럼 결과를 살펴보겠습니다.

528
01:10:09,000 --> 01:10:21,000
여기서 표 1은 대나무에 대한 DaVinci 002 정확도를 Wiki 및 Maorae Maorae에 사용합니다.

529
01:10:21,000 --> 01:10:24,000
마오라에, 정말 귀엽네요.

530
01:10:24,000 --> 01:10:53,000
Musque Musque 데이터 세트. 그리고 Bamboo Go의 경우 정확성은 저자가 수동으로 판단합니다. 그리고 다른 데이터 세트에서 측정항목은 제공된 답변이 해당 두 데이터 세트에 대한 답안지의 답변과 정확히 일치하는지 확인하는 것과 비교하는 것이 정확성이라고 판단하는 것입니다.

531
01:10:53,000 --> 01:11:08,000
그리고 부록 표 4에는 다른 측정항목을 사용하여 동일한 데이터 세트에 대한 더 많은 결과가 나와 있습니다. 따라서 여러분이 이와 같은 방법에 관심이 있다면 부록으로 가서 더 깊은 루프를 살펴보는 것이 좋습니다.

532
01:11:08,000 --> 01:11:30,000
그래서 여기서 우리는 자기 자신에게 물어보는 방법이 실제로 위키와 머스크에 대한 일련의 생각보다 더 적은 양으로 향상된다는 것을 볼 수 있습니다. 기본적으로 생각의 사슬은 정확도가 29.8%인데 자기 질문은 30.0에 불과한 것과 같습니다.

533
01:11:30,000 --> 01:11:48,000
그래서 사실 꽤 비슷해요. 그리고 여기 12.6 대 13.8이 있습니다. 하지만 Bamboo Go 데이터 세트에서는 46.4 대 57.6과 같습니다. 그러니까 11% 증가한 거죠. 그래서 꽤 많은 양인 것 같아요.

534
01:11:48,000 --> 01:12:01,000
그리고 자체 질문과 검색은 더 높은 수준의 기술에 도달합니다. 따라서 세 가지 데이터 세트 모두에 대해 더 좋고 기본적으로 더 나은 답변이 있습니다.

535
01:12:02,000 --> 01:12:12,000
네, 사실은 이 업데이트된 버전이 실제로 꽤 잘 작동하는 것 같아요. 그리고 표 2에 있습니다.

536
01:12:13,000 --> 01:12:21,000
DaVinci의 제로 정확도가 2보다 크다는 것을 보여줍니다.

537
01:12:21,000 --> 01:12:30,000
실례지만, 자체 요청은 유사하거나 더 나은 성능을 달성합니다.

538
01:12:30,000 --> 01:12:45,000
정확성에 있어서, 그것은 적어도 대부분보다 30% 이상 더 빠르게 실행됩니다. 이것이 제가 방금 전에 소개한 프롬프트 방법입니다.

539
01:12:46,000 --> 01:13:03,000
따라서 두 개의 Wiki 데이터 세트에서 볼 수 있듯이 최소 대 최대의 정확도는 29이지만 자체 질문의 정확도는 35.5입니다. 그러니까 꽤 많이 늘어난 거죠.

540
01:13:03,000 --> 01:13:20,000
그런데 답변에 좋아요를 표시하기 위해 생성된 토큰의 수가 감소하면서 6개, 100개 정도가 되었습니다.

541
01:13:20,000 --> 01:13:35,000
죄송합니다. 제 두뇌는 최소한으로 생성된 토큰보다 약 250 정도 적게 작동할 수 없습니다. 그리고 이 음악 데이터 세트에서도 정확도는 매우 비슷합니다.

542
01:13:35,000 --> 01:13:53,000
따라서 166개는 모두 약 16개와 같지만 토큰 수는 실제로 자체 질문 모델에서 생성된 토큰 수는 최소 또는 대부분의 방법에서 생성된 토큰 수의 거의 절반입니다.

543
01:13:53,000 --> 01:14:15,000
그래서 효과도 좋습니다. 좋습니다. 이제 이 접근 방식의 한계를 살펴보겠습니다. 이 문서의 저자는 1,750억 개의 매개변수보다 큰 모델을 실험하지 않았으므로 실제로 모델이 그러한 대형 모델에서 어떻게 작동할지 알지 못합니다.

544
01:14:15,000 --> 01:14:38,000
그래서 또 다른 제한 사항이 있습니다. 따라서 모델은 경험적 평가를 통해 더 다르게 행동할 수 있습니다. 그래서 그들은 기본적으로 테스트하는 것을 좋아하지 않았기 때문입니다. 이것이 미래의 한 방향입니다.

545
01:14:38,000 --> 01:14:52,000
그들은 말했어요, 좋아요, 이제 제가 들어갈 거에요, 우리는 반응에 대한 세 번째 논문에 들어갈 수 있어요.

546
01:14:52,000 --> 01:15:13,000
따라서 이는 기본적으로 언어 모델에서 시너지 효과를 발휘하는 추론과 행동을 의미합니다. 좋아요, 대규모 언어 모델은 일련의 추론 추적을 실행하여 언어 추론 질문에 대한 답을 추론할 수 있는 능력을 보여주었습니다.

547
01:15:14,000 --> 01:15:28,000
그럼에도 불구하고 생각의 사슬처럼 그것은 여전히 ​​정적 블랙박스이며, 이는 이 모델이 자체 내부 표현을 사용하고 외부 세계에 기반을 두지 않는다는 것을 의미합니다.

548
01:15:28,000 --> 01:15:56,000
그래서 그것은 환각으로 이어질 것이고 추론 과정에 오류가 전파될 것입니다. 또한 사전 학습 모델인 최근 연구에서는 사전 학습 언어 모델을 사용하여 대화형 환경에서 주로 언어 사전을 통한 작업 예측 또는 소위 프롬프트라고 하는 작업을 통해 작업을 계획하고 수행할 수 있는 방법을 조사했습니다.

549
01:15:56,000 --> 01:16:16,000
그래서 이 두 가지 아이디어를 염두에 두고 저자는 React라는 아이디어를 제안했습니다. 이는 기본적으로 다양한 과제, 언어 추론 및 의사결정에 관한 과제를 해결하는 것을 목표로 하는 언어 모델에 추론과 행동을 결합한 일반적인 패러다임입니다.

550
01:16:17,000 --> 01:16:36,000
그리고 들어가서 그들이 무엇을 했는지, 그리고 그것이 실제로 무엇인지 살펴보겠습니다. 우선, 그냥 추론하는 아이디어입니다. 이것은 우리가 방금 이야기한 일련의 생각과 함께 나왔습니다. 따라서 대규모 언어 모델을 사용하여 추론을 전면에 내세우면 됩니다.

551
01:16:37,000 --> 01:17:02,000
그런 다음 모델의 성능을 향상시킬 수 있으므로 매우 간단합니다. 그런 다음 이제 언어 모델에 질문에 답하도록 요청하면 답을 줄 가능성이 높으며 제공한 답변 이후의 모든 내용은 해당 답변에 대한 정당화일 뿐이므로 환각으로 이어질 수 있습니다. 문제.

552
01:17:03,000 --> 01:17:14,000
따라서 우리가 반대로 생각한다면 추론이 우선시되고, 추론이 추적되거나 진전이 실제로 답변에 필요한 것이 우선시됩니다.

553
01:17:14,000 --> 01:17:23,000
대답에는 무엇이 필요할 것입니다. 그러면 그 대답 자체가 결국 더 나은 대답이 될 것입니다.

554
01:17:23,000 --> 01:17:42,000
그리고 이것 외에도 그것을 생각하는 또 다른 패러다임이 있습니다. 따라서 실제로 모델이 환경에서 어떤 작업을 수행하도록 할 수 있다면(예: 작업 수행) 이를 관찰, 환경의 관찰로 사용하여 데이터를 제공할 수 있습니다.

555
01:17:42,000 --> 01:18:07,000
관찰은 다시 언어 모델로 돌아가서 더 좋아하고 더 좋아하고 반복적인 작업을 수행하고 관찰을 통해 모델이 답을 생성할 수 있도록 합니다. 그래서 여기에는 언어를 돕기 위해 환경에 대한 작업을 사용하는 것과 같은 많은 아이디어가 진행되고 있습니다.

556
01:18:08,000 --> 01:18:17,000
언어 모델을 돕기 위해. 그러나 나는 그것에 대해 너무 자세히 설명하지 않을 것입니다. 관심이 있으신 분은 해당 논문을 다시 참고하시기 바랍니다.

557
01:18:18,000 --> 01:18:38,000
그리고 기본적으로 리액트는 이유만을 합친 것과 행동과 행동만을 합친 것과 같으며 두 가지 아이디어가 함께 있는 것과 같습니다. 그래서 우리는 추론하는 것과 같은 것을 볼 수 있고, 그런 다음 우리는 그런 종류의 행동을 취해야 합니다.

558
01:18:38,000 --> 01:18:55,000
그런 다음 이러한 작업이 환경에서 수행되는 방식을 기반으로 일부 관찰 내용을 언어 모델로 다시 가져올 수 있습니다. 그리고 이것은 사용하는 것이 더 나을 수 있습니다. 여기에서 이유를 구체화하기 위해 다시 사용하십시오.

559
01:18:55,000 --> 01:19:10,000
따라서 실제로 한 번에 끝나는 것이 아니라 전체 프로세스에 걸쳐 여러 번에 걸쳐 생각하는 중간 정도의 중지 방법을 얻게 됩니다. 따라서 실제로 성능을 향상시킬 수 있다면 모델의 전반적인 성능이 향상됩니다.

560
01:19:10,000 --> 01:19:32,000
좋습니다. 이제 질문에 대해 자세히 설명하고 다양한 모델이 이러한 질문에 어떻게 대답하는지 살펴보겠습니다. 그렇다면 문제는 Apple 리모컨을 제외하고 Apple Remote가 원래 상호 작용하도록 설계된 프로그램을 제어할 수 있는 다른 장치가 무엇인지입니다.

561
01:19:33,000 --> 01:19:41,000
먼저 저자는 표준을 벗어난 프롬프트를 통해 예를 제시합니다. 그러니 바로 질문해 보세요.

562
01:19:41,000 --> 01:19:48,000
그리고 분명히 생성된 답변은 올바르지 않습니다. 그리고 두 번째는 생각의 연쇄입니다.

563
01:19:48,000 --> 01:20:05,000
모델은 답변을 생성하는 방법과 같은 몇 가지 추론 추적을 제공하지만 해당 추적의 이유는 기본적으로 잘못되었습니다. 따라서 그들이 제공한 답변은 본질적으로 잘못된 것입니다. 그리고 1절에서는 행동만 봅니다.

564
01:20:05,000 --> 01:20:28,000
따라서 기본적으로 이 접근 방식은 모델에게 이를 검색하고 관찰 결과를 다시 가져오라고 지시하는 것과 같습니다. 그러면 답변이 나옵니다. 그런 다음 기본적으로 최종 답변에 도달할 때까지 전체 단계를 반복합니다. 이전 두 가지보다 정답과 같습니다.

565
01:20:28,000 --> 01:20:33,000
여기에 반응이 들어오는 방법이 있습니다.

566
01:20:33,000 --> 01:20:37,000
이런 식으로. 그래서 우선 생각이 있을 것입니다.

567
01:20:37,000 --> 01:20:42,000
모델은 질문을 바탕으로 생각을 생성합니다.

568
01:20:42,000 --> 01:20:49,000
여기서 생각한 것은 Apple Remote를 검색하여 프로그램을 찾아야 한다는 것입니다. 원래는 상호 작용하도록 설계되었습니다.

569
01:20:49,000 --> 01:20:58,000
자, 생각을 바탕으로 모델이 생성되고 Apple Remote라는 키워드로 검색하는 해당 동작이 생성됩니다.

570
01:20:58,000 --> 01:21:11,000
그리고 이 작업을 수행함으로써 모델은 소위 검색 엔진이라고 불리는 외부 환경과 같은 관찰을 얻습니다.

571
01:21:11,000 --> 01:21:24,000
그리고 그들의 관찰에 따르면, 애플 리모콘은 애플이 2025년 10월에 출시한 리모콘으로, 원래는 프론트 로우 미디어 센터 프로그램을 제어하도록 설계되었습니다.

572
01:21:24,000 --> 01:21:30,000
그래서 우리는 또 다른 생각을 가지고 있습니다.

573
01:21:30,000 --> 01:21:41,000
이제 all을 사용하는 모든 항목이 이미 생성되었으므로 모델은 다음 논리적 단계나 생각을 제시합니다.

574
01:21:41,000 --> 01:21:50,000
이 경우 그들은 Apple Remote가 원래 앞줄 미디어 센터 프로그램을 제어하도록 설계되었기 때문에 생각합니다.

575
01:21:50,000 --> 01:21:57,000
그렇다면 다음 단계, 다음으로 검색해야 할 것은 맨 앞줄입니다.

576
01:21:57,000 --> 01:22:02,000
그런 다음 이를 제어할 수 있는 다른 장치를 찾아보세요.

577
01:22:02,000 --> 01:22:08,000
그리고 그들은 기본적으로 두 번째 검색 작업을 수행하고 이에 대한 두 번째 관찰을 얻습니다.

578
01:22:08,000 --> 01:22:27,000
좋아요, 기본적으로 최종 답에 도달할 때까지 생각 행동 관찰과 같은 것을 반복적으로 반복합니다. 이는 전체 예제에 대한 정답이라고 말할 수 있습니다.

579
01:22:27,000 --> 01:22:38,000
좋아요. 그리고 여기에 내가 방금 겪었던 것과 동일한 아이디어를 기본적으로 설명하는 것 외에는 몇 가지 표기법이 있습니다.

580
01:22:38,000 --> 01:22:45,000
그래서 L은 우리가 생각이라고 부르는 언어 공간을 나타냅니다.

581
01:22:45,000 --> 01:22:51,000
그리고 자본은 행동 공간이고 자본은 에이전트의 행동 공간입니다.

582
01:22:51,000 --> 01:23:04,000
그리고 본 논문에서 in, in, in, 모든 에이전트 행동 공간은 3개로 제한되는데, 이에 대해 잠시 후에 소개하겠습니다.

583
01:23:04,000 --> 01:23:11,000
여기서 한 가지 어려움은 언어 공간이 실제로 무제한이라는 것입니다.

584
01:23:11,000 --> 01:23:23,000
그래서 실제로 이 증강된 행동 공간에서 학습하는 것과 같습니다. 이 증강된 행동 공간을 배우는 것은 실례합니다. 꽤 어렵습니다.

585
01:23:23,000 --> 01:23:28,000
마지막 페이지로 어떻게 돌아가나요?

586
01:23:28,000 --> 01:23:29,000
알았어, 아주 좋아.

587
01:23:29,000 --> 01:23:33,000
그것은 어렵고 강한 언어의 기도가 필요합니다.

588
01:23:33,000 --> 01:23:58,000
따라서 이 문서의 범위에 있는 어려움에 대해 제안된 솔루션은 동결된 대형 언어 모델인 시 540B를 사용하고 또한 컨텍스트 예제에서 몇 개의 샷 프롬프트를 사용하고 컨텍스트 예제에서는 몇 개의 샷을 프롬프트로 사용하는 것입니다.

589
01:23:58,000 --> 01:24:07,000
자, 이제 본 논문에서는 이에 대한 평가 방법을 소개하겠습니다.

590
01:24:07,000 --> 01:24:20,000
따라서 저자는 기본적으로 이 모델을 평가하기 위한 작업에 대한 유사한 설계를 갖고 있으며, 그런 다음 이 네 가지 작업을 네 개로 두 그룹으로 분리합니다.

591
01:24:20,000 --> 01:24:28,000
첫 번째 그룹은 지식 집약적 추론 작업과 여기에서 사용되는 데이터 세트입니다.

592
01:24:28,000 --> 01:24:41,000
아, 그리고 태스크와 태스크는 작성자가 hop up QA를 사용하는 모델 홉 질문 답변과 모델 홉 질문에 대한 사실 검증입니다.

593
01:24:41,000 --> 01:24:51,000
그래서 이것은 모델 홉 질문과 발열에 대한 벤치마크입니다. 이는 사실 확인 작업에 대한 또 다른 사실 기준입니다.

594
01:24:51,000 --> 01:25:08,000
따라서 이 두 작업에 해당하는 행동 공간이 되며, 이 두 작업은 검색, 조회 및 종료로, 현재 세금과 같은 답에 도달하면 완료됩니다.

595
01:25:08,000 --> 01:25:20,000
그래서 저자는 제가 방금 언급한 다음 세 가지 작업에 해당하는 자체 제작 Wikipedia 웹 API를 제안하고 싶습니다.

596
01:25:20,000 --> 01:25:37,000
그리고 여기 그가 사용하는 기준선을 자극하는 첫 번째 반응과 비교하기 위해 사용하는 펌핑 방법에 대한 프롬프트 방법이 있습니다.

597
01:25:37,000 --> 01:25:50,000
디코딩 온도 0.7의 일관된 자체 일관성이 없으며 조치는 신속하게만 수행됩니다.

598
01:25:50,000 --> 01:26:10,000
한 단계 더 나아가서 그들은 외부 데이터베이스의 내부 지식을 결합하여 이 방법의 성능을 더욱 향상시키는 것과 같은 업데이트를 좋아하려고 노력합니다.

599
01:26:10,000 --> 01:26:20,000
그래서 이것을 사용하기 위해 그들은 반응처럼 사용하고 자기 일관성을 가지고 생각의 사슬로 전환합니다.

600
01:26:20,000 --> 01:26:41,000
또는 자기 일관성 전환에 대한 생각의 사슬은 대다수의 답변이 최대이고 질문과 생각의 사슬 자기 일관성 자기 일관성 샘플이 절반 이하로 발생하면 반응으로 다시 전환됩니다.

601
01:26:41,000 --> 01:27:01,000
또한 앞서 언급한 모든 프롬프트 방법에 대해 미세 조정을 수행합니다. 따라서 이것은 이전 작업과 유사한 부트스트래핑 접근 방식이며 기본적으로 반응에 의해 생성된 정답이 있는 3000개의 궤적을 사용합니다.

602
01:27:01,000 --> 01:27:16,000
그리고 더 작은 언어 모델을 미세 조정하고 입력 질문에 대한 궤적 조건을 해독합니다. 그래서 자세한 내용은 부록에 있습니다. 관심 있으신 분들은 상세 내용을 참고해주세요.

603
01:27:16,000 --> 01:27:30,000
좋습니다. 디코딩 온도는 모델 출력의 결정론적 무작위성과 무작위성 사이의 균형을 제어하는 ​​자연어 처리에 사용되는 기본 온도입니다.

604
01:27:30,000 --> 01:27:41,000
그리고 시간의 온도 값은 3단계와 같습니다. 따라서 온도가 1과 같을 때 이는 자연적인 단계이며 결정성이나 무작위성 사이에 선호가 없습니다.

605
01:27:41,000 --> 01:27:58,000
1보다 크면 the, the, the 방법이 더 창의적인 방식으로 답변을 생성하라는 메시지를 표시하는 것과 비슷해집니다. 따라서 모델의 다양성과 창의적인 창의성이 높아질 것입니다.

606
01:27:59,000 --> 01:28:20,000
이제 모델은 기본적으로 더 창의적인 아이디어를 생성할 것입니다. 그러나 그에 대한 절충점은 덜 일관적인 이야기나 정확성을 덜 생성할 수 있고 그 반대의 경우 온도가 1보다 낮으면 덜 참신하다는 것입니다.

607
01:28:20,000 --> 01:28:32,000
그러나 대답은 일관성과 비슷하거나 가독성이 더 좋습니다.

608
01:28:32,000 --> 01:28:40,000
좋습니다. 여기에 몇 가지 결과와 관찰 결과가 있습니다.

609
01:28:41,000 --> 01:28:47,000
먼저 표 1을 살펴본 다음 그림 2를 살펴보고 이어서 그림 2와 그림 3을 살펴보겠습니다.

610
01:28:47,000 --> 01:29:02,000
따라서 표 1에서 우리는 홉업 QN과 발열에 대한 가장 좋은 자극 일치가 각각 생각의 연쇄, 자기 일관성에 반응하고 또한 생각의 연쇄, 자기 일관성이 다시 반응하는 것을 볼 수 있습니다.

611
01:29:02,000 --> 01:29:16,000
알았어, 그렇구나. 그래서 굵은 글씨는 기본적으로 가장 성능이 좋은 것을 보여주는 것과 같습니다. 바로 이 두 가지 방법입니다.

612
01:29:16,000 --> 01:29:26,000
또한 그림 2는 생각의 사슬 수, 자기 일관성 샘플에 대해 사용된 방법이 어떻게 다른지 보여줍니다.

613
01:29:26,000 --> 01:29:41,000
그리고 여기서 우리는 발열 데이터 세트에서 반응으로 다시 전송되는 생각의 자체 일관성 전송이 반응에 비해 가장 높은 정확도를 달성한다는 것을 알 수 있습니다.

614
01:29:41,000 --> 01:29:51,000
따라서 기본적으로 두 가지 전환 프롬프트 방법은 발열 데이터 세트에서 가장 높은 두 가지 정확도를 달성합니다.

615
01:29:52,000 --> 01:30:09,000
그런 다음 생각의 사슬 자체 일관성과 반응은 더 많은 훈련 시도가 있을 때 거의 동등한 정확도에 도달합니다.

616
01:30:09,000 --> 01:30:15,000
그리고 여기에서도 기본적으로 같은 이야기가 나옵니다.

617
01:30:15,000 --> 01:30:24,000
둘 다와 마찬가지로 두 개의 전환 데이터가 트리를 설정하고 두 개의 전환 방법이 가장 높은 성능에 도달합니다.

618
01:30:24,000 --> 01:30:41,000
그러나 실제로 이것은 훈련 횟수가 증가하고 시도 횟수가 증가함에 따라 생각의 연쇄 자체 일관성이 반응 데이터 세트보다 성능이 뛰어납니다.

619
01:30:41,000 --> 01:30:45,000
좋아요, 그러면 우리는 두 가지를 알아낼 것입니다.

620
01:30:45,000 --> 01:30:52,000
이는 사용된 일련의 사고 샘플 수와 관련하여 다양한 방법이 어떻게 수행되는지 보여줍니다.

621
01:30:52,000 --> 01:31:05,000
그래서 여기서 우리는 이것이 반응처럼 비슷한 이야기라는 것을 알 수 있습니다.

622
01:31:06,000 --> 01:31:23,000
따라서 기본적으로 반응하는 미세 조정을 보여주는 쇼케이스와 같은 결과를 보여주는 것은 실제로 미세 조정 모델에 매우 적응력이 있다는 것입니다.

623
01:31:24,000 --> 01:31:47,000
따라서 이전의 미세 조정 사례에서는 반응할 수 없으며 다른 모든 방법보다 성능이 뛰어날 수 없습니다.

624
01:31:47,000 --> 01:31:53,000
그러나 미세 조정 후에는 정확도가 증가합니다.

625
01:31:53,000 --> 01:32:04,000
아, 작고 작은 모델 크기에 대한 정확도가 상당히 높아집니다.

626
01:32:04,000 --> 01:32:08,000
그래서 여기는 15세부터 30세 이상까지입니다.

627
01:32:08,000 --> 01:32:14,000
그래서 꽤 인상적입니다.

628
01:32:14,000 --> 01:32:23,000
다음은 반응 유도와 일련의 사고 유도에 대한 몇 가지 다른 결과와 관찰입니다.

629
01:32:23,000 --> 01:32:37,000
따라서 표 2를 보면 환각은 반응보다 거짓 긍정 비율이 훨씬 더 높기 때문에 일련의 사고에 있어 실제로 심각한 문제라는 것을 알 수 있습니다.

630
01:32:37,000 --> 01:32:47,000
여기에서 성공 모드의 14% 대 66%를 볼 수 있으며 실패 모드와 같은 주요 구성을 구성합니다.

631
01:32:47,000 --> 01:32:53,000
따라서 56% 대 0%와 같습니다.

632
01:32:53,000 --> 01:33:06,000
그래서 실제로 환각 문제를 피하는 데 있어서 알아내는 것과 같이 꽤 잘한 것처럼 반응합니다.

633
01:33:06,000 --> 01:33:10,000
그런데 이런 설정이군요.

634
01:33:10,000 --> 01:33:22,000
그리고 생각하는 단계와 지켜보는 단계를 뒤섞을 때 실제로는 더 현실적이고 신뢰할 수 있는 반응을 하는 데 상당히 도움이 됩니다.

635
01:33:22,000 --> 01:33:30,000
그러나 이런 종류의 설정은 문제를 유연하게 생각하는 것을 어렵게 만듭니다.

636
01:33:30,000 --> 01:33:37,000
그래서 그것은 엉망이 될 수도 있다는 것을 의미합니다. 일련의 사고 방식보다 좀 더 자주 추론하는 것입니다.

637
01:33:37,000 --> 01:33:42,000
이것이 바로 우리가 주목해야 할 또 다른 점입니다.

638
01:33:43,000 --> 01:34:03,000
따라서 연속적으로 정보를 검색하는 것과 같은 반응을 위해서는 검색을 통한 유익한 지식이 매우 중요합니다. 왜냐하면 후속 답변은 모두 이전 답변을 기반으로 하기 때문입니다.

639
01:34:03,000 --> 01:34:17,000
따라서 시작하는 첫 번째 답변이 올바르지 않거나 첫 번째 생각 방향과 행동 방향이 올바르지 않으면 이후의 모든 답변과 생각이 올바르지 않습니다.

640
01:34:17,000 --> 01:34:23,000
그래서 그것의 품질은 매우 중요합니다.

641
01:34:23,000 --> 01:34:43,000
좋아요, 여기에 우리가 의사 결정 작업이라고 부르는 유사한 작업의 다른 두 그룹이 있습니다. 여기서 소개하는 첫 번째 작업은 이른바 세상밖으로 불러낸 텍스트 기반의 게임이다.

642
01:34:43,000 --> 01:34:51,000
이는 이전의 일부 논문에서 사용되거나 소개된 것과 유사한 벤치마크입니다.

643
01:34:51,000 --> 01:35:00,000
그리고 여기서 테스트할 펌핑 방법은 반응 프롬프트, 내부 독백입니다. 그래서 이 작품은 작가들이 소개한 선행작 중 가장 가까운 작품이다.

644
01:35:00,000 --> 01:35:08,000
그리고 그에 대한 기준은 집사인 집사이다. 비슷한 일을 하는 전작이기도 합니다.

645
01:35:08,000 --> 01:35:15,000
좋습니다. 관찰 결과는 다음과 같습니다.

646
01:35:15,000 --> 01:35:18,000
그래서 우리는 볼 수 있습니다.

647
01:35:18,000 --> 01:35:34,000
여기에서 우리는 모든 펌핑 방법을 사용하여 외부 세계 작업을 수행합니다. 최고의 반응 시도는 평균 71%의 성공률을 달성합니다.

648
01:35:34,000 --> 01:35:56,000
여기에서는 기본적으로 모든 방법과 모든 데이터 세트를 평균화하여 죄송하지만 최악의 반응 시도는 48%에 도달합니다.

649
01:35:56,000 --> 01:36:05,000
여기라면 괜찮습니다.

650
01:36:05,000 --> 01:36:22,000
아, 죄송합니다. 71%입니다. 그리고 이것은 45와 37과 같은 나머지 모든 접근 방식보다 훨씬 뛰어납니다.

651
01:36:23,000 --> 01:36:32,000
이는 최상의 6개 결과를 선택하는 다른 방법과 같습니다.

652
01:36:32,000 --> 01:36:40,000
좋아, 그러면 우리는 다른 모든 측정 항목에 비해 반응이 매우 일관되게 수행되는 것을 볼 수 있습니다.

653
01:36:40,000 --> 01:36:48,000
그런 다음 저자를 비교한 다음 반응과 IM 방법을 비교합니다.

654
01:36:48,000 --> 01:36:54,000
기본적으로 이 도구 대 이 도구라는 것을 알 수 있습니다.

655
01:36:54,000 --> 01:37:02,000
이 네 가지 경우에서 반응은 IM 스타일보다 훨씬 뛰어납니다.

656
01:37:02,000 --> 01:37:12,000
90~58, 96, 86 대 60~80, 30 정도를 볼 수 있습니다.

657
01:37:12,000 --> 01:37:28,000
음, 응. 그리고 그러한 궤적과 같은 많은 것은 여전히 ​​상식적 추론이 부족하기 때문에 해당 게임 환경 내에서 아이템이 어떤 위치에 있을지 결정하기 위한 투쟁과 같습니다.

658
01:37:29,000 --> 01:37:44,000
저자가 언급한 이 문제는 이미 React를 통해 해결될 수 있습니다. 이것이 바로 React가 IM 모델보다 더 나은 결과를 원하는 이유입니다.

659
01:37:44,000 --> 01:37:46,000
좋아요.

660
01:37:46,000 --> 01:37:56,000
그런 다음 웹 상점이라는 웹 사이트 탐색인 또 다른 의사 결정 작업을 수행하는 의사 결정을 입력합니다.

661
01:37:56,000 --> 01:38:05,000
이는 110만 개의 실제 제품과 12,000개의 인간 지침이 포함된 온라인 쇼핑 환경입니다.

662
01:38:05,000 --> 01:38:16,000
그리고 저자는 이를 500개의 테스트 지침에 대한 평균 점수와 작업 성공률로 평가하기도 했습니다.

663
01:38:16,000 --> 01:38:19,000
그래서 어떤 사람들은 속삭임을 행동합니다.

664
01:38:19,000 --> 01:38:34,000
따라서 여기에서 사용할 수 있는 몇 가지 작업에는 검색, 제품 선택, 옵션 선택 및 반응 비교와 같은 몇 가지 프롬프트 방법 구입이 있습니다.

665
01:38:35,000 --> 01:38:52,000
10, 10, 12개의 인간 주석이 달린 궤적을 갖춘 기차와 데이터 세트가 있는 모방 및 강화 학습 기차로 훈련할 것입니다.

666
01:38:52,000 --> 01:39:04,000
나는 이 이전 데이터 세트와 10 58 및 7개의 추가 훈련 지침을 좋아할 것입니다.

667
01:39:04,000 --> 01:39:11,000
따라서 실제 결과는 React가 훨씬 더 나은 성능을 달성한다는 것이 매우 분명합니다.

668
01:39:11,000 --> 01:39:25,000
점수에서 이전 최고 성공률보다 약 10% 증가한 것을 볼 수 있습니다.

669
01:39:25,000 --> 01:39:49,000
그리고 기존의 모든 방법은 여전히 ​​인간 전문가의 성능과는 거리가 멀습니다. 인간 전문가의 점수는 81.1이지만 8과 비슷하지만 여기의 모든 모델은 가장 높더라도 가장 높은 모델보다 훨씬 낮기 때문입니다. 인간 전문가가 수행하는 작업.

670
01:39:49,000 --> 01:39:51,000
좋아요.

671
01:39:51,000 --> 01:40:01,000
그런 다음 마침내 자기 피드백을 통한 자기 개선 반복 개선이라는 마지막 논문에 들어갈 수 있습니다.

672
01:40:01,000 --> 01:40:03,000
문제 진술.

673
01:40:03,000 --> 01:40:20,000
음, 규모가 크긴 하지만 대규모 언어 모델은 명확한 텍스트를 생성하는 데 능숙하지만 그렇지 않다는 것을 알고 있습니다. 그러나 대화를 생성하거나 이와 같은 코드를 더 쉽게 읽을 수 있도록 만드는 것과 같은 복잡한 작업에 어려움을 겪는 경우가 많습니다.

674
01:40:20,000 --> 01:40:35,000
음, 인간이 하는 것처럼 먼저 초기 초안을 작성한 다음 며칠 후에 그 초안을 반복적으로 수정하는 것이 좋습니다.

675
01:40:35,000 --> 01:40:53,000
따라서 이 모델은 먼저 더 나은 제품을 생산할 수 있습니다. 따라서 이 작업을 수행하는 것과 마찬가지로 인간이 수행하는 방식과 유사하게 모델은 기본적인 첫 번째 초안을 생성할 수도 있지만 일반적으로 각 버전이 마지막 버전보다 나은 경우 추가 라운드를 추가하여 이 초안을 개선하는 것과 같습니다.

676
01:40:53,000 --> 01:41:09,000
그래서 그것은 지속적인 개선 과정과 같습니다. 그리고 이 과정은 반복적 개선 과정이라고 알려져 있지 않으며, 특별한 특별 교육이나 전문가의 피드백을 활용할 수도 있습니다.

677
01:41:09,000 --> 01:41:22,000
그러나 이 프로세스는 충분한 데이터나 시간을 얻을 수도 있고 전문가의 시간이 힘들고 비용이 많이 들 수도 있습니다.

678
01:41:22,000 --> 01:41:37,000
따라서 이는 많은 감독 없이도 다양한 작업에 걸쳐 결과를 효과적으로 개선하는 방법을 찾는 것의 중요성을 강조합니다.

679
01:41:37,000 --> 01:41:56,000
좋습니다. 이 모델에 대해 간단히 안내해 드리겠습니다. 자체 정제된 모델은 초기 응답을 취하고 수정 사항에 대한 평가를 기반으로 이를 수정하는 반복 피드백 프로세스를 통해 출력을 개선합니다.

680
01:41:56,000 --> 01:42:13,000
그리고 이 방법은 기본적으로 후속 개선 없이 모바일 답변을 생성하는 대신 먼저 입력으로 초기 답변 세트를 얻은 다음 추가로 향상시키기 위해 가장 좋은 답변 세트를 선택하는 것을 포함합니다.

681
01:42:13,000 --> 01:42:27,000
따라서 기본적으로 초기 입력이 있고, 자체 정제된 모델은 출력을 생성하고 이를 동일한 모델에 다시 전달하여 피드백을 받는 것으로 시작됩니다.

682
01:42:27,000 --> 01:42:40,000
그런 다음 피드백은 동일한 모델로 다시 전달되어 여기에서 이전에 생성된 출력을 개선합니다.

683
01:42:40,000 --> 01:42:57,000
따라서 단계, 피드백, 단계 피드백 및 단계 개선은 미리 정의된 중지 조건이 충족될 때까지 반복적으로 수행되는 것과 같습니다.

684
01:42:57,000 --> 01:43:10,000
이는 GVT 3.5와 같은 더 큰 언어 모델로 인스턴스화되는 것과 같으며 이 접근 방식에는 사람의 도움이 필요하지 않습니다.

685
01:43:10,000 --> 01:43:30,000
이 전체 과정에서 주목해야 할 한 가지는 세 가지 단계를 수행해야 한다는 것입니다. 따라서 우리는 세 가지 프롬프트도 훈련해야 합니다. 아, 또한 각 단계마다 세 가지 프롬프트를 통합해야 합니다.

686
01:43:30,000 --> 01:43:43,000
그래서 이것은 좀 더 구체적인 예입니다. 세부적으로 전체 최적화 내용을 살펴보겠습니다.

687
01:43:43,000 --> 01:44:02,000
따라서 기본적으로 이 예에서 인간이 입력하는 초기 질문 또는 초기 작업은 모델에 생성하여 하나부터 끝까지 합계를 계산하는 함수를 생성하도록 요청하는 것입니다.

688
01:44:02,000 --> 01:44:15,000
그리고 여기에 초기가 있습니다. 파란색 사각형은 초기 답변 또는 언어 모델의 초기 출력을 나타냅니다.

689
01:44:15,000 --> 01:44:23,000
그런 다음 이 언어 모델에 이 결과를 새로운 프롬프트로 제공하고 대규모 언어 모델에 피드백을 요청합니다.

690
01:44:23,000 --> 01:44:38,000
따라서 다음은 언어 모델에서 생성된 두 번째 출력으로서 이 코드는 무차별 대입과 출력을 더욱 구체화하기 위한 더 나은 접근 방식을 사용하기 때문에 느리다는 피드백입니다.

691
01:44:38,000 --> 01:44:46,000
이전 출력은 공식과 시간, 더하기 1을 2로 나눈 값을 사용하는 것입니다.

692
01:44:46,000 --> 01:45:12,000
그리고 우리와 모델은 이 출력을 첫 번째 출력과 함께 세 번째 입력으로 사용합니다. 첫 번째 부분의 출력은 모두 새로운 입력으로 사용됩니다. 그런 다음 다시 모델로 다시 보내면 모델이 좋아할 것입니다. 그것을 세 번째 입력으로 받아들이고

693
01:45:12,000 --> 01:45:17,000
그것은 우리의 세련된 결과물을 최종적으로 다듬는 것입니다.

694
01:45:17,000 --> 01:45:39,000
이 경우 sum 함수의 합을 개선한 버전입니다. 이 공식을 계산 프로세스에 직접 활용하여 먼저 성능을 높이고 두 번째로 성능을 낮추는 것입니다.

695
01:45:39,000 --> 01:45:42,000
공간 복잡성.

696
01:45:42,000 --> 01:45:57,000
그리고 여기에 제가 방금 겪었던 것과 동일한 아이디어를 보여주는 기본적으로 알고리즘 방식이 있으므로 이에 대해 자세히 설명하지는 않겠습니다.

697
01:45:58,000 --> 01:46:00,000
네.

698
01:46:00,000 --> 01:46:19,000
그래서 여기에서는 기본적으로 그것들이 두 개라는 것과 같은 것입니다. 단지 두 개의 표기법입니다. 따라서 피드백 위첨자 K는 실행 가능하고 구체적이어야 하는 실행 가능한 요구 사항을 나타냅니다.

699
01:46:19,000 --> 01:46:22,000
그래서 피드백.

700
01:46:22,000 --> 01:46:38,000
위첨자 K는 기본적으로 전체 프로세스에서 K번의 반복을 의미합니다. 따라서 실행 가능하다는 것은 행위를 의미하며, 피드백에는 매우 일반적인 피드백과 달리 출력을 높일 수 있는 구체적인 조치가 포함되어야 합니다.

701
01:46:38,000 --> 01:46:46,000
그리고 구체적이어야 합니다. 따라서 출력에서 ​​변경할 구체적인 문구를 식별하세요.

702
01:46:46,000 --> 01:46:59,000
기본적으로 이 예제에서 의미하는 바는 이전 코드 최적화 예제에 제공된 피드백의 코드에 있는 my 코드입니다.

703
01:46:59,000 --> 01:47:28,000
첫째, 이전 답변이 나쁘다고 생각하는 이유가 충분하지 않다고 설명하는 것과 같습니다. 그리고 계산에 다음 공식을 사용하는 것과 같은 매우 구체적인 방법 접근 방식을 제공함으로써 이 답변이 더욱 향상됩니다.

704
01:47:28,000 --> 01:47:44,000
그리고 정지 조건은, 아, 기본적으로 정지 조건에 대한 두 가지 기준이 있습니다. 따라서 먼저 타임스탬프의 특정 시간 단계에서 중지할 수 있습니다.

705
01:47:44,000 --> 01:47:57,000
여기서는 반복 횟수를 나타냅니다. 둘째, 인간의 피드백으로부터 정지 지표를 추출하는 것도 가능합니다.

706
01:47:59,000 --> 01:48:13,000
좋아요. 네, 그럼 이제 간단히 평가 과정을 살펴보겠습니다. 이 프로세스에 포함된 작업은 작성자가 직접 정의한 두 가지 새로운 작업이 포함된 몇 가지 표준 작업입니다.

707
01:48:13,000 --> 01:48:35,000
첫 번째는 약어 세대입니다. 두 번째는 제약 조건 생성입니다. 따라서 제약 조건 생성이 의미하는 바는 특정 규칙이나 조건에 따라 작업, 텍스트, 스토리 답변 또는 코드를 생성하는 프로세스를 의미한다는 것입니다.

708
01:48:35,000 --> 01:48:53,000
예를 들어, 세계 게임을 하는 것을 좋아하고, 이야기를 쓰는 것을 좋아하지만 각 문장을 특정 문자로만 시작할 수 있거나 텍스트에 특정 단어를 포함해야 하는 경우 .

709
01:48:54,000 --> 01:49:09,000
따라서 각 문장을 특정 문자로 시작하고 텍스트에 특정 단어를 포함하는 것과 같은 것은 모두 제약 조건의 예와 같습니다.

710
01:49:10,000 --> 01:49:22,000
좋습니다. 작성자가 정의한 중지 조건은 반복에 도달하거나 원하는 출력 조건에 도달한 것과 같습니다.

711
01:49:22,000 --> 01:49:46,000
좋아요. 그래서 여기에 몇 가지 비교 비교 방법이 있습니다. 대규모 언어 모델은 모두 동일합니다. 따라서 기본 모델은 모두 동일합니다. 피드백이 있거나 없는 모든 기본 모델을 사용하는 것과 마찬가지로 반복을 찾습니다.

712
01:49:47,000 --> 01:50:02,000
따라서 기본 모델은 GBT 3.5 채팅 GBT 및 GBT 및 코덱이며 저자는 디코딩 온도 0 7과 같은 탐욕스러운 디코딩을 사용합니다.

713
01:50:03,000 --> 01:50:23,000
프롬프트도 이전 작품과 동일하며 새로 만든 것을 추가했습니다. 새로 생성된 항목에 대해 자세히 설명하지는 않겠습니다. 논문 등을 참조할 수 있으며 평가에 사용하는 매트릭스에는 특정 작업이 포함됩니다.

714
01:50:23,000 --> 01:50:44,000
행렬. 따라서 이는 이전 작업의 자동 측정항목과 인간 선호 측정항목입니다. 이런 경우에는 너무 바쁩니다. 이는 선호하는 출력을 선택하기 위해 출력의 하위 집합에 대한 맹목적인 인간 A 및 B 평가입니다.

715
01:50:45,000 --> 01:51:03,000
따라서 기본적으로 그것은 한 무리의 인간이 자신이 선호하는 답변을 선택하도록 허용하지만 버전 A, B와 같은 것이 무엇인지 알리지 않고 좋아하는 것과 같습니다.

716
01:51:03,000 --> 01:51:12,000
좋아, 서문의 GBT는 기본적으로 인간 기본 설정과 동일하지만 대신 GBT가 모든 프로세스를 수행하도록 하세요.

717
01:51:12,000 --> 01:51:30,000
좋습니다. 주요 결과는 다음과 같습니다. 따라서 자체 개선은 모든 모델 크기에 걸쳐 기본 모델에 비해 각 모델의 성능을 일관되게 향상시키고 모든 작업에서 이전 기술 수준을 능가한다는 점은 매우 분명합니다.

718
01:51:30,000 --> 01:51:52,000
따라서 여기서 위쪽 화살표는 모델과 같이 자체 개선을 사용하여 유사한 개선 비율을 의미합니다. 그리고 이 개선은 모두가 성능 개선을 보여주는 위쪽 화살표와 같기 때문에 상당히 일관됩니다.

719
01:51:52,000 --> 01:52:10,000
가장 낮은 것은 마치 가장 낮은 것은 그 자체의 의미와 같습니다. 일관성을 유지하면 동일하게 유지되거나 개선되는 것과 같으므로 전체적으로 좋은 개선과 매우 비슷합니다.

720
01:52:10,000 --> 01:52:25,000
좋아요, 그리고 여기 첫 번째 인지 분석이 있습니다. 여기 저자 시험, 피드백 품질 대 유사 모델 개선 대 반복 등 세 가지 중 어느 것이 가장 중요합니까?

721
01:52:25,000 --> 01:52:32,000
따라서 이 경우 첫 번째 시험은 피드백 품질입니다.

722
01:52:32,000 --> 01:52:46,000
그래서 저자는 좋은 피드백이 일반적인 피드백보다 낫다고 결론을 내립니다. 그렇다면 그것은 좋고, 피드백이 없는 것보다 낫습니다. 여기 그래프가 있습니다. 아, 죄송합니다. 이전 슬라이드로 돌아가겠습니다.

723
01:52:46,000 --> 01:53:15,000
따라서 여기 표에서는 피드백 품질이 실제로 자기 개선에 매우 중요한 역할을 한다는 점을 강조합니다. 보시다시피 여기 자체 개선 피드백인 좋은 피드백은 세 가지 모두 중에서 가장 좋은 결과를 얻습니다. 피드백이 없는 경우와 비교하면 여기에는 0 하나와 같이 두 개도 포함되어 있는데 이는 매우 나쁩니다. .

724
01:53:16,000 --> 01:53:26,000
그리고 여기에는 피드백 품질이 향상되었을 때 개선되는 것과 같은 일반적인 추세가 표시됩니다.

725
01:53:27,000 --> 01:53:48,000
그리고 두 번째 그림이 보여요. 따라서 이 그림 4는 반복 횟수가 증가함에 따라 개선에서 수익이 감소하는 것을 강조하고 왜 0인 이유, 왜 2, 왜 3이 반복 횟수와 같은 것을 나타냅니다.

726
01:53:48,000 --> 01:54:07,000
그리고 예, 보시다시피, 유사한 반복 횟수가 증가함에 따라 변경 사항, 변경 사항의 양도 감소하고 있습니다.

727
01:54:07,000 --> 01:54:13,000
11.3에서 6.4까지, 3개까지만요.

728
01:54:15,000 --> 01:54:36,000
아, 첫 번째 반복에서는 11.3, 두 번째 반복에서는 6.4, 세 번째 반복에서는 3입니다. 따라서 반복 횟수가 증가함에 따라 각 반복의 효율성이 감소하는데, 이를 수익 체감이라고 합니다.

729
01:54:36,000 --> 01:54:52,000
또한 모델 측면 피드백이 포함된 작업의 경우 출력 품질은 반복 중에 많이 달라질 수 있으며, 반복은 한 측면에서는 개선되지만 다른 측면에서는 감소합니다.

730
01:54:55,000 --> 01:55:00,000
따라서 우리는 1 대 1.2 대 0.7을 볼 수 있습니다.

731
01:55:01,000 --> 01:55:17,000
따라서 반복 반복 횟수와 같은 반복은 실제로 작동하지 않으며 최종 답변의 품질을 향상시키는 데 매우 유사한 명백한 효과를 갖습니다.

732
01:55:18,000 --> 01:55:33,000
네. 또한 다양한 품질 측면에 대한 수치 점수를 생성하고 이를 통해 균형 잡힌 평가와 적절한 출력 선택으로 이어집니다.

733
01:55:34,000 --> 01:55:37,000
그리고 또 다른 정량적 분석이 있습니다.

734
01:55:37,000 --> 01:55:47,000
따라서 여기의 저자는 LGBT가 피드백을 통해 답변을 개선하지 않고 4가지 다른 답변을 만들 때 LGBT와 비교하여 자체 개선 성능이 어떤지 시험합니다.

735
01:55:48,000 --> 01:55:54,000
그런 다음 저자는 self-refine의 출력이 LGBT의 이 네 가지 출력보다 더 나은 결과를 얻을 수 있는지 확인했습니다.

736
01:55:55,000 --> 01:56:20,000
따라서 기본적으로 이 그래프는 자체 개선이 유사한 답변의 품질을 향상시키는지, 기본적으로 더 많은 출력을 갖기 때문에 또는 출력 품질이 반복을 통해 더 좋아지는 것과 같기 때문에 품질을 조사하는 것과 같습니다.

737
01:56:21,000 --> 01:56:34,000
따라서 여기서 그들은 기본적으로 자체 개선 모델의 성능을 이것과 비교하는 것을 좋아합니다. 이 출력과 같이 이 경우 4, 1 대 k 평가에서.

738
01:56:34,000 --> 01:56:47,000
따라서 기본적으로 자체 개선 모델이 이를 보여주기 위해 모든 k 출력보다 성능이 뛰어나야 한다는 의미입니다.

739
01:56:48,000 --> 01:56:59,000
그래요, self-refine의 개선은 출력 품질이 좋아지거나 출력이 좋아졌기 때문입니다.

740
01:57:00,000 --> 01:57:09,000
그것은 더 많은 출력을 생성하는 것과 같은 것이 아닙니다.

741
01:57:10,000 --> 01:57:11,000
좋아요.

742
01:57:12,000 --> 01:57:26,000
그래서 결과는, 이것이 출력에 대한 선호, 즉 출력에 대한 선호입니다.

743
01:57:26,000 --> 01:57:55,000
따라서 우리는 더 많은 사람들이 여전히 자신이 좋아하는 모델로 자체 개선을 선택하는 것을 선호하기 때문에 자체 개선 모델이 일반적으로 더 나은 성능을 달성하는 것을 볼 수 있다는 것을 인간 연구자가 수행한 것과 같이 볼 수 있습니다.

744
01:57:56,000 --> 01:58:03,000
이것은 채팅 GPT 또는 이러한 모든 결과와 같은 다중, 다중 결과입니다.

745
01:58:03,000 --> 01:58:16,000
따라서 이 논문에서 제기되거나 언급된 한 가지 질문은 자체 개선이 더 약한 모델에서도 작동하는지 여부입니다.

746
01:58:16,000 --> 01:58:26,000
그래서 이를 조사하기 위해 저자는 더 작은 모델, 덜 강력한 기반 모델을 사용하여 자체 개선을 시작했습니다.

747
01:58:26,000 --> 01:58:41,000
그리고 결과는 모델이 기본적으로 필요한 형식, 필요한 형식으로 피드백을 일관되게 생성할 수 없었기 때문에 이에 잘 맞지 않음을 보여줍니다.

748
01:58:41,000 --> 01:58:51,000
심지어 작성자가 Oracle이나 하드 코딩된 피드백을 사용하여 이 프로세스를 수행하는 것을 좋아하더라도 마찬가지입니다.

749
01:58:51,000 --> 01:58:57,000
따라서 Oracle은 이전 논문에서 소개된 측정 기준입니다.

750
01:58:57,000 --> 01:58:58,000
좋아요.

751
01:58:58,000 --> 01:59:03,000
그래서 종종 개선하라는 지시를 따르는 것처럼 느껴집니다.

752
01:59:03,000 --> 01:59:05,000
그래서 실제로는 잘 안 됩니다.

753
01:59:06,000 --> 01:59:21,000
그리고 생성된 이 모델은 일반적으로 유사 대신 원본과 유사한 출력을 반복하거나 실제로 출력을 개선하는 대신 무작위 추측을 수행합니다.

754
01:59:21,000 --> 01:59:37,000
즉, 자체 개선을 의미하므로 자체 개선의 성능도 실제로 모델이 충분히 강력한지 여부에 따라 달라집니다.

755
01:59:37,000 --> 01:59:43,000
요약을 읽고 오늘 배운 내용을 요약해 보겠습니다.

756
01:59:43,000 --> 01:59:52,000
생각의 사슬, 생각의 나무, 그리고 마지막으로 프로그램의 생각을 촉구하는 생각의 사슬에 대해 이야기했습니다.

757
01:59:52,000 --> 02:00:03,000
요약하자면, 사고 유도 체인을 통해 언어 모델은 복잡한 작업을 해결하기 위한 중간 추론 단계를 명확하게 표현할 수 있습니다.

758
02:00:04,000 --> 02:00:11,000
하나의 큰 문제 하나를 중간 단계로 나누어 하나씩 해결해 나가게 됩니다.

759
02:00:11,000 --> 02:00:19,000
모든 하위 문제를 해결하면 주요 문제가 해결됩니다.

760
02:00:19,000 --> 02:00:29,000
사고 사슬의 자체 일관성 버전은 다중 추론 경로를 생성하고 가장 일관된 솔루션을 선택함으로써 정확성을 향상시켰습니다.

761
02:00:29,000 --> 02:00:35,000
단일 연결 리스트 대신 병렬 연결 리스트를 사용하고 있습니다.

762
02:00:35,000 --> 02:00:54,000
그리고 우리는 다수가 투표한 의견이나 결론이 정확할 수 있다는 희망을 가지고 모든 병렬 연결 목록에서 자금 조달자를 집계했습니다.

763
02:00:54,000 --> 02:00:57,000
그리고 우리는 또한 생각을 촉구하는 나무를 가지고 있습니다.

764
02:00:57,000 --> 02:01:06,000
생각을 자극하는 나무는 여기서 볼 수 있는 트리 구조, 여기에서 볼 수 있는 트리 구조로 추론을 구성하여 문제 해결 능력을 향상시킵니다.

765
02:01:06,000 --> 02:01:19,000
이 트리 구조를 사용하면 토큰 방식으로 왼쪽에서 오른쪽으로 탐색하는 대신 여러 솔루션 경로를 탐색할 수 있습니다.

766
02:01:19,000 --> 02:01:22,000
그리고 마지막으로 생각의 프로그램.

767
02:01:22,000 --> 02:01:29,000
사고의 프로그램은 이전 세 작품과는 뭔가 다르다.

768
02:01:29,000 --> 02:01:40,000
추론을 실행 가능한 단계로 체계적으로 구성하며 단계는 프로그램과 유사합니다.

769
02:01:40,000 --> 02:01:50,000
이러한 논리와 계산의 분리는 정확하고 논리적인 문제 해결을 제공합니다.

770
02:01:50,000 --> 02:02:03,000
그래서 기본적으로 제가 방금 언급한 4개의 논문 중 촉발 이유만을 다루는 논문이 하나 있는데, 이는 가장 촉발이 가장 적습니다.

771
02:02:03,000 --> 02:02:13,000
나머지 세 가지는 모두 행동을 유도하는 이유입니다. 죄송합니다. 이는 자기 질문 유도, 반응 및 자기 개선입니다.

772
02:02:13,000 --> 02:02:21,000
따라서 이 모든 프롬프트 접근 방식은 일종의 행동과 함께 추론 추적을 통합합니다.

773
02:02:21,000 --> 02:02:42,000
예를 들어, 실례합니다. 일부 검색 엔진에서 검색한 다음 생성된 출력이나 검색 엔진에서 생성된 관찰 및 피드백을 언어 모델에 가져오는 것과 같습니다.

774
02:02:42,000 --> 02:03:03,000
기본적으로 반복 단계처럼 이 작업을 수행한 다음 출력을 결합하여 인터넷 검색의 이점을 활용합니다.

775
02:03:03,000 --> 02:03:16,000
따라서 이는 또한 외부 세계의 일부 외부 지식을 통합하여 언어 모델의 성능을 더욱 향상시킵니다.

776
02:03:16,000 --> 02:03:20,000
좋아, 기본적으로 그게 다야. 들어 주셔서 감사합니다.