1
00:00:00,000 --> 00:00:03,200
이제 Tool LLM에 대해 이야기하겠습니다.

2
00:00:03,200 --> 00:00:09,880
본 논문의 주요 목표는 프레임워크를 만드는 것입니다.

3
00:00:09,880 --> 00:00:14,560
여러 API를 사용할 수 있는 LLM 교육

4
00:00:14,560 --> 00:00:18,640
사용자의 텍스트 요청을 이행합니다.

5
00:00:18,640 --> 00:00:22,840
그들이 제공하는 솔루션은 Tool LLM이라고 불리며,

6
00:00:22,840 --> 00:00:24,680
이는 일반적인 프레임워크입니다.

7
00:00:24,680 --> 00:00:25,840
여러 부분이 있습니다.

8
00:00:25,840 --> 00:00:28,720
아주 높은 수준에서 언급하고 싶다면

9
00:00:28,720 --> 00:00:30,640
이 논문의 기여.

10
00:00:30,640 --> 00:00:35,000
먼저 새로운 명령어인 Toolbench가 있습니다.

11
00:00:35,000 --> 00:00:38,800
도구 사용을 위해 특별히 데이터 세트를 조정합니다.

12
00:00:38,800 --> 00:00:42,160
DFS 결정 트리라는 새로운 알고리즘

13
00:00:42,160 --> 00:00:50,200
LLM의 추론 능력을 향상시킬 수 있습니다.

14
00:00:50,200 --> 00:00:54,240
이러한 종류의 도구를 평가하는 새로운 방법은 다음과 같습니다.

15
00:00:54,240 --> 00:00:59,520
Tool Eval이라고 불리는 새로운 미세 조정 LLM 기반 모델

16
00:00:59,520 --> 00:01:04,320
실제로 적절한 API 시퀀스를 권장합니다.

17
00:01:04,320 --> 00:01:10,240
텍스트 요청을 이행합니다.

18
00:01:10,240 --> 00:01:14,040
그럼 전작의 문제는

19
00:01:14,040 --> 00:01:16,560
그리고 이 지역의 현재 상황

20
00:01:16,560 --> 00:01:20,040
그게 지금 우리가 가진 것 중 가장 좋은 거야

21
00:01:20,040 --> 00:01:24,960
비공개 소스인 OpenAI의 전하성입니다.

22
00:01:24,960 --> 00:01:29,400
모든 사용자에게 이상적인 것은 아닙니다.

23
00:01:29,400 --> 00:01:34,440
그리고 오픈소스 세계에서는 전작이

24
00:01:34,440 --> 00:01:41,720
제한된 API 세트와 같은 몇 가지 제한 사항이 있습니다.

25
00:01:41,720 --> 00:01:46,440
아니면 가짜 API를 사용하여 모델을 훈련할 수도 있습니다.

26
00:01:46,440 --> 00:01:49,360
일부 작업에서는 시나리오가 매우 제한적입니다.

27
00:01:49,360 --> 00:01:51,640
단일 도구이거나

28
00:01:51,640 --> 00:01:53,800
사용자가 수동으로

29
00:01:53,800 --> 00:01:56,800
이상적인 API 세트를 지정합니다.

30
00:01:56,800 --> 00:02:01,840
아니면 다른 작품에서는 기획과 추론이

31
00:02:01,840 --> 00:02:04,480
별로 좋지 않습니다.

32
00:02:04,480 --> 00:02:08,920
따라서 이 모든 문제를 완화하기 위한 첫 번째 단계는

33
00:02:08,920 --> 00:02:12,680
좋은 데이터 세트를 만들고 있습니다.

34
00:02:12,680 --> 00:02:16,440
이 문서에서는 이를 Toolbench라고 부릅니다.

35
00:02:16,480 --> 00:02:21,840
Toolbench는 Chargivity를 사용하여 생성된 데이터 세트입니다.

36
00:02:21,840 --> 00:02:23,440
선생님 모델로.

37
00:02:23,440 --> 00:02:28,320
그리고 그것은 세 가지 일반적인 단계로 구성되었습니다.

38
00:02:28,320 --> 00:02:34,800
먼저 Rapid API Hub에서 API를 수집했습니다.

39
00:02:34,800 --> 00:02:40,760
두 번째 단계에서는 전성을 자극하는 방법을 사용했습니다.

40
00:02:40,760 --> 00:02:45,240
다양한 시나리오에 대한 지침을 생성합니다.

41
00:02:45,240 --> 00:02:49,320
그리고 마지막 단계에서 올바른 경로에 주석을 달았습니다.

42
00:02:49,320 --> 00:02:52,400
그리고 올바른 API 시퀀스

43
00:02:52,400 --> 00:02:54,440
그 임무를 완수할 것입니다.

44
00:02:54,440 --> 00:02:57,880
그럼 이에 대해 자세히 알아보겠습니다.

45
00:02:57,880 --> 00:03:02,600
그래서 첫 번째 단계는 API 수집이었습니다.

46
00:03:02,600 --> 00:03:09,480
이 단계에서는 먼저 53,000개 이상의 API로 시작합니다.

47
00:03:09,520 --> 00:03:16,080
49개 카테고리의 10,000개 이상의 도구 중에서 선택하세요.

48
00:03:16,080 --> 00:03:18,200
그러나 그 중 많은 기능이 작동하지 않습니다.

49
00:03:18,200 --> 00:03:25,640
당신이 그것을 부르면 그들은 단지 오류라고 응답합니다.

50
00:03:25,640 --> 00:03:28,520
그리고 그 것들을 모두 제거하면,

51
00:03:28,520 --> 00:03:33,440
결국 16,000개가 넘는 API를 갖게 될 수 있습니다.

52
00:03:33,440 --> 00:03:37,600
3,400개 이상의 도구에서.

53
00:03:39,920 --> 00:03:46,360
두 번째 단계에서는 명령어 생성입니다.

54
00:03:46,360 --> 00:03:50,480
단계에서 핵심 아이디어는 무작위로 샘플링하는 것입니다.

55
00:03:50,480 --> 00:03:55,160
이전 단계에서 수집한 API의 하위 집합입니다.

56
00:03:55,160 --> 00:03:58,640
그리고 우리는 그것을 전하에게 먹이고 묻습니다.

57
00:03:58,640 --> 00:04:06,480
우리를 위한 일련의 작업을 생성합니다.

58
00:04:06,480 --> 00:04:10,240
따라서 이 단계에 대한 실제 프롬프트는

59
00:04:10,240 --> 00:04:12,960
처음에는 일반적인 설명이 포함되어 있습니다.

60
00:04:12,960 --> 00:04:16,080
이 명령어 생성 작업의

61
00:04:16,080 --> 00:04:19,760
둘째, 선택한 API에 대한 문서입니다.

62
00:04:19,760 --> 00:04:24,520
셋째, 몇 가지 시드 예시가 있습니다.

63
00:04:24,520 --> 00:04:26,320
구체적으로 세 가지 시드 예는 다음과 같습니다.

64
00:04:26,320 --> 00:04:30,040
인간 전문가가 작성했습니다.

65
00:04:30,040 --> 00:04:35,040
이 과정에서 다양성을 보장하기 위해,

66
00:04:35,040 --> 00:04:39,400
세 가지 시나리오에 대한 지침을 생성합니다.

67
00:04:39,400 --> 00:04:46,600
첫째, 단일 도구 사용 시나리오, 단 하나의 API입니다.

68
00:04:46,600 --> 00:04:47,880
하나의 도구가 사용됩니다.

69
00:04:47,880 --> 00:04:50,600
한 도구의 API가 사용됩니다.

70
00:04:50,600 --> 00:04:54,200
다중 도구 시나리오에는 두 가지 하위 시나리오가 있습니다.

71
00:04:54,200 --> 00:04:57,120
카테고리 내 및 컬렉션 내.

72
00:04:57,120 --> 00:05:01,440
따라서 빠른 API에서는 반, 가서 보면

73
00:05:01,480 --> 00:05:07,560
카테고리는 좀 더 거친 종류입니다.

74
00:05:07,560 --> 00:05:10,800
API 분류.

75
00:05:10,800 --> 00:05:13,520
그리고 컬렉션이 더욱 세분화되었습니다.

76
00:05:13,520 --> 00:05:17,360
그래서 우리는 다양한 수준에서 다양성을 가질 수 있습니다.

77
00:05:17,360 --> 00:05:21,760
카테고리 수준이나 컬렉션 수준에서

78
00:05:21,760 --> 00:05:25,560
그들은 2~35개의 도구를 샘플링합니다.

79
00:05:25,560 --> 00:05:27,360
수집을 위해 동일한 카테고리에서.

80
00:05:27,360 --> 00:05:31,960
그리고 각 도구에 대해 최대 3개의 API를 샘플링합니다.

81
00:05:31,960 --> 00:05:36,360
그리고 이것들은 수집되어 따로 보관될 것입니다.

82
00:05:36,360 --> 00:05:42,120
보시다시피 총 87,000개 이상의 단일 도구가 있습니다.

83
00:05:42,120 --> 00:05:47,600
API, 동일한 카테고리의 84,000개 이상의 다중 도구 API

84
00:05:47,600 --> 00:05:53,560
동일한 컬렉션의 24,000개 다중 도구 API.

85
00:05:53,560 --> 00:06:00,840
그리고 마지막 단계에서는 솔루션 패널에 주석을 달아야 합니다.

86
00:06:00,840 --> 00:06:05,760
따라서 이 단계에서는 매력을 자극합니다.

87
00:06:05,760 --> 00:06:08,240
유효한 동작 순서를 찾으려면

88
00:06:11,320 --> 00:06:13,280
좀 더 구체적으로 말하면 전략이 있습니다.

89
00:06:13,280 --> 00:06:22,320
상단과 API 이름 및 인수를 알려줍니다.

90
00:06:22,320 --> 00:06:23,800
해당 API에 대한 것입니다.

91
00:06:23,800 --> 00:06:26,200
좀 더 구체적으로 말하자면, 그들은 다음과 같은 함수를 사용합니다.

92
00:06:26,200 --> 00:06:29,000
어트랙션의 특징과 각 API

93
00:06:29,000 --> 00:06:33,840
함수와 두 가지 유형으로 작동합니다.

94
00:06:33,840 --> 00:06:38,320
특별한 종류의 API를 함수로 사용합니다.

95
00:06:38,320 --> 00:06:40,840
하나는 포기하고 하나는 끝내고

96
00:06:40,840 --> 00:06:42,720
최종 삽입으로 마무리되었습니다.

97
00:06:42,720 --> 00:06:48,920
그래서 모델이 기능을 포기하고 완성되면,

98
00:06:48,920 --> 00:06:50,800
즉, 이 경로, 이 순서는

99
00:06:50,800 --> 00:06:53,120
유효하지 않을 것입니다.

100
00:06:53,120 --> 00:07:00,640
그리고 우리는 이 시퀀스 확장을 중단해야 합니다.

101
00:07:00,640 --> 00:07:04,640
그리고 이곳은 그들의 새로운 추론 아이디어가 탄생하는 곳이다.

102
00:07:04,640 --> 00:07:08,880
이는 DFS 기반 의사결정 트리입니다.

103
00:07:08,880 --> 00:07:12,320
실제로 최고의 시퀀스를 찾으려면

104
00:07:12,320 --> 00:07:20,600
실제로 좋은 답변에 도달할 가능성이 가장 높으며,

105
00:07:20,600 --> 00:07:28,680
그들은 간단하지만 매우 효과적인 방법을 사용합니다.

106
00:07:28,680 --> 00:07:32,400
실제로 노드를 확장하기 위해 DFS를 사용합니다.

107
00:07:32,400 --> 00:07:36,000
모델은 포기하여 끝났다고 말합니다.

108
00:07:36,000 --> 00:07:38,400
그들은 역추적을 중단하고

109
00:07:38,400 --> 00:07:43,960
해당 노드에 도달할 때까지 다른 노드를 확장해 보세요.

110
00:07:43,960 --> 00:07:46,560
함수가 최종 답변으로 끝나도록 합니다.

111
00:07:46,560 --> 00:07:52,520
그리고 그 길은 접지 역할을 할 것입니다

112
00:07:52,520 --> 00:07:56,000
이 데이터 세트의 도구입니다.

113
00:07:56,000 --> 00:07:59,360
따라서 데이터 수집은 제쳐두고 우리는 또한

114
00:07:59,360 --> 00:08:07,240
도구 사용 LLM을 평가할 수 있는 방법이 필요합니다.

115
00:08:07,240 --> 00:08:11,880
그리고 수동으로 주석을 달면

116
00:08:11,880 --> 00:08:16,000
고정된 지상 공구 솔루션은 거의 불가능합니다.

117
00:08:16,440 --> 00:08:21,960
세상에는 수천 개의 API가 있습니다.

118
00:08:21,960 --> 00:08:24,040
실제로 달성하는 방법에는 여러 가지가 있습니다.

119
00:08:24,040 --> 00:08:26,960
하나의 지시.

120
00:08:26,960 --> 00:08:31,720
그래서 눈에 보이지 않는 것이 너무나 당연합니다.

121
00:08:31,720 --> 00:08:35,400
그래서 가장 기본적이고 가장 근본적인 것은

122
00:08:35,400 --> 00:08:37,880
우리가 생각할 수 있는 것은 합격률입니다.

123
00:08:37,880 --> 00:08:42,920
LLM에서 제안한 API의 순서

124
00:08:42,920 --> 00:08:46,160
제한된 예산 내에서 실행 가능해야 합니다.

125
00:08:46,160 --> 00:08:49,400
그것이 그들이 도구에서 합격률이라고 부르는 것입니다.

126
00:08:49,400 --> 00:08:52,320
평가 프레임워크인 eval.

127
00:08:52,320 --> 00:08:59,320
그리고 그들은 그것을 인간의 평가와 비교했습니다.

128
00:08:59,320 --> 00:09:06,880
그리고 87%의 동의율을 알아냈습니다.

129
00:09:06,880 --> 00:09:09,520
더 유용한 것은 승률입니다.

130
00:09:09,520 --> 00:09:15,840
이는 우리에게 해당 시퀀스의 유용성을 제공합니다.

131
00:09:15,840 --> 00:09:20,080
승률, 아이디어는 우리가 묻는 것입니다

132
00:09:20,080 --> 00:09:28,960
한 쌍의 솔루션에서 어떤 솔루션 경로를 선택하는지에 대한 창의성

133
00:09:28,960 --> 00:09:32,600
경로가 더 선호될 것입니다. 어느 것이 더 나은 경로입니까?

134
00:09:32,600 --> 00:09:36,720
이 작업을 여러 번 수행하고 평균을 구합니다.

135
00:09:36,720 --> 00:09:42,440
그리고 그것이 이 두 가지 솔루션 경로 사이에서 승자가 될 것입니다.

136
00:09:42,440 --> 00:09:49,920
따라서 이 측정항목을 기반으로 그들은 다시

137
00:09:49,920 --> 00:09:56,160
사람이 직접 평가한 결과 80%가 일치했습니다.

138
00:09:56,160 --> 00:10:03,480
논문의 또 다른 아이디어는 API Retriever입니다.

139
00:10:03,560 --> 00:10:07,400
최상의 API 세트를 찾는 데 사용됩니다.

140
00:10:07,400 --> 00:10:11,120
이는 특정 요청을 해결하는 데 관련이 있습니다.

141
00:10:11,120 --> 00:10:16,000
그리고 이 문제를 해결하는 방법은 매우 간단합니다.

142
00:10:16,000 --> 00:10:20,720
우리는 임베딩 유사성을 취하여 계산합니다.

143
00:10:20,720 --> 00:10:24,320
API의 지침과 문서 사이.

144
00:10:24,320 --> 00:10:28,360
임베딩은 먼지를 사용하여 계산되었습니다.

145
00:10:28,360 --> 00:10:31,000
하지만 그들은 몇 가지 실험을 해왔습니다.

146
00:10:31,000 --> 00:10:34,640
API를 찾는 방법을 보여줬습니다.

147
00:10:34,640 --> 00:10:40,800
이전 방법보다 훨씬 낫습니다.

148
00:10:40,800 --> 00:10:44,080
즉, BM25와 Ada 모델입니다.

149
00:10:48,760 --> 00:10:51,720
우리가 논의한 것처럼, 이 논문의 또 다른 아이디어는,

150
00:10:51,720 --> 00:10:54,240
이것이 바로 DFS 기반 의사결정 트리였습니다.

151
00:10:54,240 --> 00:11:00,560
그리고 그들은 또한 그것을 더 일반적으로 사용되는 방법과 비교했습니다.

152
00:11:00,560 --> 00:11:03,200
즉 리액트.

153
00:11:03,200 --> 00:11:07,720
그러나 일을 공정하게 하기 위해 DFS-DT는

154
00:11:07,720 --> 00:11:12,480
훨씬 더 많은 API 호출이 발생하고 React가 여러 번 종료됩니다.

155
00:11:12,480 --> 00:11:16,480
동일한 수준의 API 호출에 도달할 때까지.

156
00:11:16,480 --> 00:11:21,320
하지만 여전히 그들은 OK, DFS 의사결정 트리를 보았습니다.

157
00:11:21,320 --> 00:11:26,120
React보다 훨씬 뛰어납니다.

158
00:11:26,120 --> 00:11:30,160
그리고 논문의 핵심에는 미세 조정된

159
00:11:30,160 --> 00:11:34,840
우리가 논의한 모든 데이터를 사용하는 라마 모델.

160
00:11:34,840 --> 00:11:37,840
그리고 입력 렌즈도 4,000에서 8,000으로 늘렸습니다.

161
00:11:37,840 --> 00:11:41,480
위치 보간을 사용합니다.

162
00:11:41,480 --> 00:11:45,760
그들은 세 가지 수준에서 진화를 했습니다.

163
00:11:45,760 --> 00:11:49,960
일반화 가능성과 엄지손가락으로 가르칠 수 있는 교육,

164
00:11:49,960 --> 00:11:51,480
동일한 카테고리의 엄지 손가락 도구,

165
00:11:51,480 --> 00:11:54,120
다양한 카테고리의 엄지 손가락 도구.

166
00:11:54,120 --> 00:11:56,280
그리고 실험은 또한

167
00:11:56,280 --> 00:11:59,800
세 가지 시나리오에서 수행되었으며

168
00:11:59,800 --> 00:12:02,800
이는 그들이 수집한 데이터에 해당하며,

169
00:12:02,800 --> 00:12:05,640
단일 도구, 소개 카테고리, 다중 도구,

170
00:12:05,640 --> 00:12:07,720
인트로 컬렉션 멀티툴.

171
00:12:07,720 --> 00:12:11,880
또한 보시다시피 몇 가지 다른 기준선도 사용했습니다.

172
00:12:11,880 --> 00:12:14,520
슬라이드에.

173
00:12:14,520 --> 00:12:20,280
그리고 이것이 비교평가 결과이다.

174
00:12:20,280 --> 00:12:26,120
툴라마(Tool Lama)라고 불리는 미세 조정된 모델 사이,

175
00:12:26,120 --> 00:12:29,240
다양한 추론 방법을 사용하여

176
00:12:29,240 --> 00:12:31,640
다른 모델과 비교.

177
00:12:31,640 --> 00:12:39,160
보시다시피 바쿠나나 알파카 같은 다른 모델들도

178
00:12:39,160 --> 00:12:42,040
지시를 따르는 능력은 그렇지 않습니다.

179
00:12:42,040 --> 00:12:44,760
도구 사용이라는 영역에서 매우 유용합니다.

180
00:12:48,040 --> 00:12:53,080
또한 DFS 의사결정 트리가 React보다 성능이 뛰어나다는 것을 알 수 있습니다.

181
00:12:53,080 --> 00:12:55,920
합격률과 승률 모두에서요.

182
00:12:55,920 --> 00:13:01,720
또한 Lama 도구와 DFS 의사결정 트리도 볼 수 있습니다.

183
00:13:01,720 --> 00:13:04,840
실제로 John Street는 매우 경쟁적이라고 일반화했습니다.

184
00:13:04,840 --> 00:13:05,600
성능.

185
00:13:08,720 --> 00:13:12,880
또한 API 검색기의 장점도 확인했습니다.

186
00:13:12,880 --> 00:13:15,840
어떤 시나리오에서는

187
00:13:15,840 --> 00:13:20,520
이는 데이터 세트의 지상 통과보다 훨씬 좋습니다.

188
00:13:21,520 --> 00:13:29,520
도구 라마의 실현 가능성에 대해 자세히 알아보려면,

189
00:13:29,520 --> 00:13:35,120
그들은 분포 데이터 세트에서 그것을 평가했습니다.

190
00:13:35,120 --> 00:13:37,520
여기서는 API Bench를 사용합니다.

191
00:13:37,520 --> 00:13:42,160
그들은 또한 그라운드 스루 리트리버와

192
00:13:42,160 --> 00:13:46,640
해당 데이터 세트의 Oracle 및 자체 API 검색기.

193
00:13:46,640 --> 00:13:51,240
그들은 또한 쿼리 로그와 Lama 도구를 비교했으며,

194
00:13:51,240 --> 00:13:57,360
이는 특별히 제작된 모델입니다.

195
00:13:57,360 --> 00:13:59,560
이 데이터 세트에 대해 교육을 받았습니다.

196
00:13:59,560 --> 00:14:06,080
보시다시피 두 시나리오 모두에서

197
00:14:06,080 --> 00:14:09,400
RS는 설정에 대한 검색기입니다.

198
00:14:09,400 --> 00:14:12,080
검색된 API가 모델로 전송된다는 의미입니다.

199
00:14:12,080 --> 00:14:13,600
프롬프트의 일부로.

200
00:14:13,600 --> 00:14:15,920
그리고 ZS는 제로샷입니다.

201
00:14:15,920 --> 00:14:21,960
이는 API가 프롬프트에 없음을 의미합니다.

202
00:14:21,960 --> 00:14:30,280
그럼에도 불구하고 우리는 Lama라는 도구가 다음과 같은 모델을 이길 수 있다는 것을 알 수 있습니다.

203
00:14:30,280 --> 00:14:32,280
이 데이터 세트에 대해 교육을 받았습니다.

204
00:14:32,280 --> 00:14:37,640
그리고 다른 시나리오에서는 실제로 매우 유사한 성능을 발휘할 수 있습니다.

205
00:14:37,640 --> 00:14:39,440
쿼리 로그에.

206
00:14:39,440 --> 00:14:42,240
자, 이제 도구 연결성에 대해 이야기해 보겠습니다.

207
00:14:42,240 --> 00:14:46,280
LLM 학습에 대한 또 다른 접근 방식을 취합니다.

208
00:14:46,280 --> 00:14:50,840
음, 미세 조정 LLM은 매우

209
00:14:50,840 --> 00:14:53,520
계산 비용 측면에서 비용이 많이 듭니다.

210
00:14:53,520 --> 00:15:00,520
그리고 미세 조정 모델을 새로운 도구에 적용하는 것은 꽤 어렵습니다.

211
00:15:00,520 --> 00:15:03,840
또한 상황 학습과 같은 다른 기술도 있습니다.

212
00:15:03,840 --> 00:15:05,440
꽤 제한되어 있습니다.

213
00:15:05,440 --> 00:15:07,400
예를 들어, 제한사항 중 하나는

214
00:15:07,400 --> 00:15:12,760
대부분의 자동차 모터에는 컨텍스트 목록이 제한되어 있다는 것입니다.

215
00:15:12,760 --> 00:15:19,760
그리고 많은 경우 학습의 미래는 효과적이지 않습니다.

216
00:15:19,760 --> 00:15:23,600
따라서 이 문서의 핵심 아이디어는 각 도구를 나타낼 수 있다는 것입니다.

217
00:15:23,600 --> 00:15:25,760
토큰으로.

218
00:15:25,760 --> 00:15:28,440
그리고 어휘력을 늘릴 수 있어요

219
00:15:28,440 --> 00:15:32,320
모델의 맨 처음에.

220
00:15:32,320 --> 00:15:35,920
따라서 생성 중에 도구가

221
00:15:35,920 --> 00:15:38,360
예측되면 LLM은 일시적으로

222
00:15:38,360 --> 00:15:41,240
모드를 특수 도구 모드로 전환

223
00:15:41,240 --> 00:15:45,480
적절한 입력 인수를 줄입니다.

224
00:15:45,480 --> 00:15:48,880
도구를 호출하고 다시 주입합니다.

225
00:15:48,880 --> 00:15:53,920
일반적으로 출력에 대한 결과

226
00:15:53,920 --> 00:15:57,640
정상적인 시나리오에서 수행됩니다.

227
00:15:57,640 --> 00:16:01,480
이 그림에서 일반적인 아키텍처를 볼 수 있습니다.

228
00:16:01,480 --> 00:16:03,960
도구 연결성.

229
00:16:04,000 --> 00:16:08,720
임베딩은 모델 헤드에 추가됩니다.

230
00:16:08,720 --> 00:16:10,880
일반적인 단어처럼.

231
00:16:10,880 --> 00:16:13,560
그리고 도구 캔이 예측되면

232
00:16:13,560 --> 00:16:16,120
LLM이 도구 모드로 전환됩니다.

233
00:16:16,120 --> 00:16:23,560
그리고 도구는 적절한 예측 매개변수를 사용하여 실행됩니다.

234
00:16:23,560 --> 00:16:27,480
그러다가 결과가 돌아오는데

235
00:16:27,480 --> 00:16:32,840
사용자의 실제 출력에 주입됩니다.

236
00:16:32,840 --> 00:16:38,000
그래서 다른 방법으로 수학적인 측면에서

237
00:16:38,000 --> 00:16:42,520
다음 토큰을 예측하는 일반적인 방법

238
00:16:42,520 --> 00:16:48,920
일반적인 단어, 즉 어휘의 소프트맥스일 뿐입니다.

239
00:16:48,920 --> 00:16:54,400
하지만 지금 당장은 해당 어휘에 대한 소프트맥스가 있습니다.

240
00:16:54,400 --> 00:16:58,000
게다가 해당 어휘의 연결

241
00:16:58,000 --> 00:17:00,040
그리고 도구의 임베딩 매트릭스.

242
00:17:03,840 --> 00:17:08,040
다시 요약하자면, 모델은 기본적으로 추론 모드에 있습니다.

243
00:17:08,040 --> 00:17:12,240
사용자 프롬프트에 정상적으로 응답을 생성하려고 시도합니다.

244
00:17:12,240 --> 00:17:16,920
그러면 출력은 도구 토큰입니다.

245
00:17:16,920 --> 00:17:20,040
단어 토큰 대신 모델이 도구 모드로 전환됩니다.

246
00:17:20,040 --> 00:17:22,120
그리고 도구 모드에서는 생성을 시도합니다.

247
00:17:22,120 --> 00:17:24,400
도구에 대한 적절한 인수.

248
00:17:24,400 --> 00:17:28,600
그리고 이번 단계에서는 도구 모드에서

249
00:17:28,600 --> 00:17:32,200
우리는 문맥에 포함할 것입니다

250
00:17:32,360 --> 00:17:35,400
특수 구문을 사용하는 도구의 데모

251
00:17:35,400 --> 00:17:37,400
그리고 현재 예측된 상황.

252
00:17:40,120 --> 00:17:44,960
따라서 이 모델의 훈련은 다음과 같습니다.

253
00:17:44,960 --> 00:17:51,160
따라서 LLM 자체, 즉 가중치가 동결될 수 있습니다.

254
00:17:51,160 --> 00:17:56,800
그리고 훈련 데이터는 SS 쌍의 형태일 수 있습니다.

255
00:17:56,800 --> 00:18:04,160
초기. 그리고 예측된 문장 SS에서는

256
00:18:04,160 --> 00:18:11,560
프라임, 우리는 도구에 대한 특별한 토큰을 갖게 될 것입니다.

257
00:18:11,560 --> 00:18:17,120
그리고 논증을 위해 여기 논문에서는 특별한 토큰을 사용합니다.

258
00:18:17,120 --> 00:18:18,560
그들은 그것을 NA라고 부릅니다.

259
00:18:18,560 --> 00:18:21,600
이는 실제 손실 함수에서는 무시됩니다.

260
00:18:21,600 --> 00:18:24,400
그래서 만약 여러분이 그것을 볼 수 있다면, 공식을 본다면,

261
00:18:24,400 --> 00:18:29,200
해당 인덱스의 손실 함수는 0이 되는 것을 알 수 있습니다.

262
00:18:29,200 --> 00:18:32,840
따라서 우리는 여기서 인수 예측에 관심이 없습니다.

263
00:18:32,840 --> 00:18:36,320
우리는 적절한 토큰을 예측하고 싶을 뿐입니다.

264
00:18:36,320 --> 00:18:41,440
이것이 우리가 적절한 임베딩을 훈련할 수 있는 방법입니다.

265
00:18:41,440 --> 00:18:45,880
도구 토큰의 경우.

266
00:18:45,880 --> 00:18:49,440
따라서 이 논문에는 세 가지 실험이 있습니다.

267
00:18:49,440 --> 00:18:54,680
이런 종류의 아키텍처를 평가합니다.

268
00:18:54,680 --> 00:18:58,240
첫 번째는 수치 추론을 위한 산술 도구입니다.

269
00:18:58,240 --> 00:19:02,640
두 번째는 지식기반 데이터베이스 API입니다.

270
00:19:02,640 --> 00:19:03,440
질문 답변.

271
00:19:03,440 --> 00:19:06,560
세 번째는 구체화된 계획을 위한 로봇 액션이다.

272
00:19:06,560 --> 00:19:07,640
세대.

273
00:19:07,640 --> 00:19:11,000
그리고 우리는 그것들을 하나씩 살펴볼 것입니다.

274
00:19:11,000 --> 00:19:12,960
첫 번째는 수치적 추론입니다.

275
00:19:12,960 --> 00:19:17,720
이번 실험에 사용된 데이터

276
00:19:17,720 --> 00:19:23,480
실제로는 JSON 8K의 향상된 버전입니다.

277
00:19:23,480 --> 00:19:27,520
학교 수준의 수학 문제가 일부 포함되어 있습니다.

278
00:19:27,520 --> 00:19:30,600
연산을 위한 기본 산술을 사용합니다.

279
00:19:30,600 --> 00:19:36,600
그러나 그들은 그것을 더욱 어렵게 만들기 위해 거기에 더 많은 숫자를 추가했습니다.

280
00:19:36,600 --> 00:19:44,120
그리고 그들이 사용하고 실제로 향상시킨 다른 데이터

281
00:19:44,520 --> 00:19:49,320
합성 데이터가 포함된 글꼴 QA입니다.

282
00:19:49,320 --> 00:19:55,800
제곱제곱과 같은 더 복잡한 산술 도구의 경우.

283
00:19:55,800 --> 00:20:05,640
따라서 이 데이터 세트는 약간

284
00:20:05,640 --> 00:20:08,800
첫 번째 것보다 아주 작은 것 같아요.

285
00:20:08,800 --> 00:20:13,840
여기에는 68개의 단일 홉 질문과 60개의 다중 홉 질문만 포함되어 있습니다.

286
00:20:14,320 --> 00:20:17,760
여러 모델에서 사용하는 데이터 외에

287
00:20:17,760 --> 00:20:21,600
제로샷 창의성과 비교하자면,

288
00:20:21,600 --> 00:20:27,640
생각의 사슬, LAMA 기반 LLN,

289
00:20:27,640 --> 00:20:30,560
그들은 330억 개의 매개변수 LAMA를 사용합니다.

290
00:20:30,560 --> 00:20:36,440
또한 그들은 React 추론 방법을 사용합니다.

291
00:20:36,440 --> 00:20:43,360
따라서 도구 임베딩이

292
00:20:43,360 --> 00:20:47,160
단일 홉 합성 데이터에 대해서만 훈련됩니다.

293
00:20:47,160 --> 00:20:50,760
하지만 여전히 결과표에서 볼 수 있듯이

294
00:20:50,760 --> 00:20:56,120
그들은 다중 홉 문제에서 꽤 좋은 성능을 발휘했습니다.

295
00:20:56,120 --> 00:21:00,840
그래서 그들은 무언가에 통합될 수 있었습니다

296
00:21:00,840 --> 00:21:04,840
생각의 연쇄처럼.

297
00:21:04,840 --> 00:21:07,600
두 번째 실험은 지식 기반 질문입니다.

298
00:21:07,600 --> 00:21:08,080
응답.

299
00:21:08,080 --> 00:21:11,960
그들이 사용하는 데이터 세트는 Camel입니다.

300
00:21:11,960 --> 00:21:19,600
Wikipedia의 많은 관계형 지식이 포함되어 있습니다.

301
00:21:19,600 --> 00:21:27,680
243개의 관계가 있고 하위 집합이 있습니다.

302
00:21:27,680 --> 00:21:34,120
이 데이터 세트에는 다양한 수의 도구가 포함된 크기 500입니다.

303
00:21:34,120 --> 00:21:42,400
그래서 비교를 위해 모델들은

304
00:21:42,400 --> 00:21:49,840
이 실험을 위해 미세 조정된 것처럼 개발된 것입니다.

305
00:21:49,840 --> 00:21:53,040
툴킷과 GBT의 변형은 두 가지 변형입니다.

306
00:21:53,040 --> 00:21:55,320
하나는 지도 학습 변형입니다.

307
00:21:55,320 --> 00:22:00,680
데이터 세트의 도구당 200개 예시 사용

308
00:22:00,720 --> 00:22:01,720
위에서 언급한 것.

309
00:22:01,720 --> 00:22:06,400
또 다른 변형은 합성 도구입니다.

310
00:22:06,400 --> 00:22:13,160
4D 합성 데이터로 훈련된 GBT 가능

311
00:22:13,160 --> 00:22:17,200
프롬프트 채팅 GBT를 사용합니다.

312
00:22:17,200 --> 00:22:20,840
프롬프트는 질문을 넣는 것뿐입니다.

313
00:22:20,840 --> 00:22:24,280
대답은 다음과 같다고 말하고

314
00:22:24,280 --> 00:22:28,440
채팅 GBT의 답변입니다.

315
00:22:28,480 --> 00:22:35,120
그래서 그들은 기준으로 상황 내 학습을 사용했습니다.

316
00:22:35,120 --> 00:22:38,200
두 가지 변형으로.

317
00:22:38,200 --> 00:22:45,360
하나는 설명을 넣은 뷰 샷입니다.

318
00:22:45,360 --> 00:22:49,840
도구에 대한 설명과 해당 도구의 데모가 프롬프트에 표시됩니다.

319
00:22:49,840 --> 00:22:53,840
하지만 제로샷 환경에서 상황에 맞는 학습은

320
00:22:53,840 --> 00:22:57,040
도구에 대한 설명을 적어 놓았고,

321
00:22:57,120 --> 00:23:04,000
하지만 사용할 수 없는 도구에 대한 8가지 데모를 게시했습니다.

322
00:23:04,000 --> 00:23:09,640
모델이 어떻게 생성될 수 있는지 가르치기 위해

323
00:23:09,640 --> 00:23:13,640
함수의 적절한 호출 형식.

324
00:23:13,640 --> 00:23:19,400
기준선 비교를 위해 사용하는 기본 모델

325
00:23:19,400 --> 00:23:23,680
라마의 매개변수는 130억 개입니다.

326
00:23:24,680 --> 00:23:29,360
결과 차트에서 볼 수 있듯이,

327
00:23:29,360 --> 00:23:35,920
여기서 LLM은 여전히 ​​정확한 사실을 저장하는 데 어려움을 겪고 있습니다.

328
00:23:35,920 --> 00:23:42,480
매개변수에서 일종의 감독을 받아야 합니다.

329
00:23:42,480 --> 00:23:47,120
실제로 지식을 강화하는 방법을 학습

330
00:23:47,120 --> 00:23:48,120
그들이 필요로하는 것.

331
00:23:49,120 --> 00:23:55,080
보시다시피 이 아이디어를 살펴보면

332
00:23:55,080 --> 00:23:57,880
논문의 핵심 아이디어는 꽤 효과적인 방법입니다

333
00:23:57,880 --> 00:24:05,560
방대한 양의 도메인 내 데이터를 이해하고 활용하는 방법에 대해 알아봅니다.

334
00:24:05,560 --> 00:24:09,560
여기서 언급할 또 다른 점은 컨텍스트 길이입니다.

335
00:24:09,560 --> 00:24:15,880
한도는 실제로 성능에 큰 영향을 미칩니다.

336
00:24:15,880 --> 00:24:19,800
관계 수를 늘릴 때 모델의

337
00:24:19,800 --> 00:24:23,240
테스트 세트의 도구.

338
00:24:23,240 --> 00:24:28,360
그래서 그들이 부르는 세 번째 실험에서는

339
00:24:28,360 --> 00:24:32,240
구체화된 계획 생성, 활동 프로그램 사용

340
00:24:32,240 --> 00:24:37,680
가상 홈 플랫폼 위에 있는 지식 기반.

341
00:24:37,680 --> 00:24:40,640
지식기반으로 구성되어 있습니다.

342
00:24:40,640 --> 00:24:43,080
전형적인 집안 활동.

343
00:24:43,080 --> 00:24:46,320
따라서 하나의 작업은 다음과 같습니다.

344
00:24:46,320 --> 00:24:49,520
예를 들어 독서 책이나 책과 같은 목표가 있습니다.

345
00:24:49,520 --> 00:24:52,040
예를 들어 자세한 지침은 다음과 같습니다.

346
00:24:52,040 --> 00:24:55,640
나는 침대에 누워서 책을 펴곤 했어

347
00:24:55,640 --> 00:24:57,520
그리고 읽기 시작하세요.

348
00:24:57,520 --> 00:25:01,360
그리고 환경에 대한 설명도 있습니다.

349
00:25:01,360 --> 00:25:04,880
해당 설명의 한 부분은 에이전트의 초기 상태입니다.

350
00:25:04,880 --> 00:25:10,760
그리고 또 다른 부분은 환경의 개체 목록입니다.

351
00:25:10,760 --> 00:25:13,760
예를 들어, 그들은 내가 사무실 집에 있다고 말합니다.

352
00:25:13,760 --> 00:25:17,600
그리고 제가 조작할 수 있는 물건은 우편물, 냉동고,

353
00:25:17,600 --> 00:25:20,560
텔레비전, 그리고 물건.

354
00:25:20,560 --> 00:25:24,960
그리고 모델은 실행 가능한 계획을 출력할 것으로 예상됩니다.

355
00:25:24,960 --> 00:25:29,400
이는 기본적으로 동사 목적어 명령의 순서가 지정된 목록입니다.

356
00:25:29,400 --> 00:25:30,720
예를 들어 소설을 찾으세요.

357
00:25:30,720 --> 00:25:47,440
좋습니다. 비교를 위해 세 가지 다른 기준을 사용했습니다.

358
00:25:47,440 --> 00:25:51,600
첫째, 그들은 기본적인 LLN만을 사용했습니다.

359
00:25:51,640 --> 00:25:55,680
LLN 모델이며 130억 개의 매개변수가 있습니다.

360
00:25:55,680 --> 00:26:01,640
그리고 그들은 단순히 상황 내 학습을 사용합니다.

361
00:26:01,640 --> 00:26:04,960
그들은 행동 목록, 세 가지 데모 계획,

362
00:26:04,960 --> 00:26:07,360
목표가 있는 새로운 작업, 자세한 설명,

363
00:26:07,360 --> 00:26:10,640
그리고 환경 설명입니다.

364
00:26:10,640 --> 00:26:16,000
세 번째에서는 죄송합니다. 두 번째 변형에서는

365
00:26:16,000 --> 00:26:19,160
게다가 번역도 사용했어요.

366
00:26:19,200 --> 00:26:22,440
이 아이디어는 일부 시나리오에서는

367
00:26:22,440 --> 00:26:27,920
모델은 아마도 몇 가지 도구를 생성할 것입니다.

368
00:26:27,920 --> 00:26:30,480
그것은 실제로 존재하지 않는 객체입니다.

369
00:26:30,480 --> 00:26:33,240
환경에 기반을 두고 있습니다.

370
00:26:33,240 --> 00:26:36,600
이제 번역 모델을 사용할 수 있습니다

371
00:26:36,600 --> 00:26:43,240
LLN의 출력을 번역하기 위해

372
00:26:43,240 --> 00:26:49,680
실제 근거가 있는 사실, 환경 속의 사물에 대한 것입니다.

373
00:26:49,680 --> 00:26:53,160
그들은 이것을 하기 위해 가상의 큰 문장을 사용합니다.

374
00:26:53,160 --> 00:26:57,880
세 번째 단계에서는 이전 단계에 더해

375
00:26:57,880 --> 00:27:00,480
그들은 실제로 접지된 디코딩을 사용했습니다.

376
00:27:00,480 --> 00:27:04,280
디코딩 레벨에서 접지를 통합합니다.

377
00:27:08,000 --> 00:27:10,000
그래서 우리는 실제로 그 번역을 볼 수 있습니다

378
00:27:10,120 --> 00:27:13,880
얕은 접지 문제를 해결하는 데 도움이 됩니다.

379
00:27:13,880 --> 00:27:19,400
그러나 접지 디코딩은 이를 더욱 향상시킵니다.

380
00:27:19,400 --> 00:27:22,560
보시다시피 Toolken GPT 접근 방식

381
00:27:22,560 --> 00:27:27,800
LLN의 성능을 크게 향상시킵니다.

382
00:27:27,800 --> 00:27:32,280
여기 이 표에서 접지 컬럼은

383
00:27:32,280 --> 00:27:36,280
실제로 출력되는 비율을 보여줍니다.

384
00:27:36,280 --> 00:27:39,480
유효하고 환경에 접지되어 있습니다.

385
00:27:39,520 --> 00:27:42,800
실행 파일은 실제 작업입니다.

386
00:27:42,800 --> 00:27:45,840
유효하고 실행될 수 있습니다.

387
00:27:45,840 --> 00:27:52,080
성공은 실제로 끝나는 출력입니다.

388
00:27:52,080 --> 00:27:57,040
정확하고 성공적인 상태입니다.

389
00:27:57,040 --> 00:28:00,720
그리고 성공 R은 성공의 편안한 버전입니다.

390
00:28:00,720 --> 00:28:07,080
반드시 적절한 것으로 끝나거나 끝나는 것은 아닙니다.

391
00:28:07,080 --> 00:28:10,760
상태이지만 과거 어느 시점에는

392
00:28:10,760 --> 00:28:15,720
실제로 성공적인 상태에서 출력을 보았습니다.

393
00:28:18,360 --> 00:28:20,960
따라서 계산 비용 측면에서

394
00:28:20,960 --> 00:28:23,760
Laura의 미세 조정을 볼 수 있습니다.

395
00:28:23,760 --> 00:28:31,680
비용이 훨씬 더 많이 들지만 실제 성능은

396
00:28:31,680 --> 00:28:33,560
조금 더 좋습니다.

397
00:28:33,560 --> 00:28:38,120
그리고 이러한 경쟁 비용 비교를 수행하려면

398
00:28:38,120 --> 00:28:43,640
그들은 LAMA 70억 개의 매개변수를 사용했습니다.

399
00:28:43,640 --> 00:28:46,080
또 다른 평가 연구에서는

400
00:28:46,080 --> 00:28:53,360
그들은 순수한 반응 방법을 a와 비교했음을 보여주었습니다.

401
00:28:53,360 --> 00:28:58,600
그리고 도구 모드도 추가해서 비교했습니다.

402
00:28:58,600 --> 00:29:03,960
그들은 실제로 이 도구 모드를 추가하는 것만으로도

403
00:29:03,960 --> 00:29:07,880
바닐라 반응의 성능을 향상시킵니다.

404
00:29:07,880 --> 00:29:10,480
꽤 크게.

405
00:29:10,480 --> 00:29:16,680
그럼 이 논문의 마지막 내용은

406
00:29:16,680 --> 00:29:22,320
훈련과 관련해 여러 가지 결정이 내려진다는 것입니다.

407
00:29:22,320 --> 00:29:23,000
데이터.

408
00:29:23,000 --> 00:29:26,800
그들은 합성 데이터의 효과가 무엇인지 알고 싶었습니다.

409
00:29:27,240 --> 00:29:31,880
데이터를 감독하고 서로 다른 부분을 선택했습니다.

410
00:29:31,880 --> 00:29:36,040
Camel의 훈련 예시를 보고 그들은 다음을 사용하여

411
00:29:36,040 --> 00:29:40,480
지도 데이터는 실제로 더 나은 성능을 발휘합니다.

412
00:29:40,480 --> 00:29:46,520
마진이 매우 높은 합성 데이터.

413
00:29:46,520 --> 00:29:50,360
자, 이제 COG 에이전트 문서에 대해 이야기하겠습니다.

414
00:29:50,360 --> 00:29:51,880
이 논문의 핵심 기여

415
00:29:51,880 --> 00:29:55,880
공감 이해와 기획을 전문으로 하는 BLM 입니다.

416
00:29:55,920 --> 00:30:01,200
또한 일반적인 교차 양식 능력도 가지고 있습니다.

417
00:30:01,200 --> 00:30:04,360
이 논문에는 다른 기여도 있습니다.

418
00:30:04,360 --> 00:30:08,360
더 큰 규모처럼 더 큰 규모를 출시했습니다.

419
00:30:08,360 --> 00:30:13,400
그래프 이론 인터페이스 및 OCR에 대한 주석이 달린 데이터 세트,

420
00:30:13,400 --> 00:30:17,200
그리고 그들은 또한 새로운 별도의 모델을 만들었습니다

421
00:30:17,200 --> 00:30:22,920
고해상도 UI 인터페이스에서 기능을 추출합니다.

422
00:30:22,920 --> 00:30:25,600
COG 에이전트의 아키텍처는 다음과 같습니다.

423
00:30:25,600 --> 00:30:29,120
우리가 이전 논문에서 COG BLM을 가지고 있는 핵심은,

424
00:30:29,120 --> 00:30:32,560
170억 개의 매개변수가 있습니다.

425
00:30:32,560 --> 00:30:37,360
저해상도 이미지 인코더도 함께 제공됩니다.

426
00:30:37,360 --> 00:30:45,520
매우 거친 픽셀을 인코딩할 수 있는

427
00:30:45,520 --> 00:30:51,720
그리고 그 위에는 다층 어댑터가 있습니다

428
00:30:51,720 --> 00:30:56,520
저해상도 인코더의 출력을 변환할 수 있는

429
00:30:56,520 --> 00:31:00,040
BLM의 기능 공간에.

430
00:31:00,040 --> 00:31:03,200
그리고 이 논문의 주요 공헌 중 하나는

431
00:31:03,200 --> 00:31:07,440
볼 수 있는 고해상도 이미지 인코더가 삽입되어 있습니다.

432
00:31:07,440 --> 00:31:10,880
각 레이어에서 Cross-Attention 메커니즘을 사용

433
00:31:10,880 --> 00:31:14,440
BLM 디코더에.

434
00:31:14,440 --> 00:31:20,120
따라서 이 모델을 사전 훈련하기 위해 그들은

435
00:31:20,160 --> 00:31:23,560
세 가지 다른 측면에 중점을 둡니다.

436
00:31:23,560 --> 00:31:27,040
첫째, 다양한 크기의 텍스트를 인식하는 능력이다.

437
00:31:27,040 --> 00:31:30,120
또는 고해상도 이미지의 글꼴 표시.

438
00:31:30,120 --> 00:31:32,120
두 번째는 텍스트의 접지 능력이다.

439
00:31:32,120 --> 00:31:33,520
이미지 속 개체에 대해

440
00:31:33,520 --> 00:31:36,840
그리고 세 번째는 특별한 이해능력이다.

441
00:31:36,840 --> 00:31:39,160
웹페이지와 같은 GUI 미스터리의 경우.

442
00:31:39,160 --> 00:31:41,960
그리고 우리는 그것들을 하나씩 살펴볼 것입니다.

443
00:31:41,960 --> 00:31:43,760
첫 번째는 텍스처 구성이고,

444
00:31:43,760 --> 00:31:47,680
그들이 사용하는 데이터는 합성 렌더링입니다.

445
00:31:47,680 --> 00:31:53,560
언어 사전 훈련 데이터 세트의 텍스트입니다.

446
00:31:53,560 --> 00:32:00,200
기본적으로 Layon2B 데이터 세트의 텍스트를 샘플링합니다.

447
00:32:00,200 --> 00:32:03,920
다양한 글꼴 크기와 색상을 사용했습니다.

448
00:32:03,920 --> 00:32:06,840
문 의도, 다른 배경

449
00:32:06,840 --> 00:32:11,680
다양한 유형의 텍스트가 풍부한 이미지를 렌더링합니다.

450
00:32:11,680 --> 00:32:14,000
그리고 그들이 사용하는 두 번째 데이터는

451
00:32:14,000 --> 00:32:16,960
OCR 광학 문자 인식입니다.

452
00:32:16,960 --> 00:32:20,560
자연스러운 이미지의

453
00:32:20,560 --> 00:32:25,600
Kaio와 Layon2B에서 이미지를 추출했습니다.

454
00:32:25,600 --> 00:32:29,760
코스와 함께 추출된 텍스트로

455
00:32:29,760 --> 00:32:31,840
주변의 경계 상자 중

456
00:32:31,840 --> 00:32:34,440
그리고 세번째는 학원서류에요

457
00:32:34,440 --> 00:32:38,720
기본적으로 이미지 텍스트 쌍의 데이터 세트인 아카이브에서.

458
00:32:39,600 --> 00:32:46,200
데이터 또는 초점의 두 번째 범주

459
00:32:46,200 --> 00:32:48,160
사전 훈련의 시각적 접지는

460
00:32:48,160 --> 00:32:54,360
그들은 Layon115million의 이미지 캡션 쌍을 사용했습니다.

461
00:32:54,360 --> 00:32:57,760
실제로 경계 상자가 있는 데이터 세트

462
00:32:57,760 --> 00:33:00,760
캡션에 있는 항목 중

463
00:33:00,760 --> 00:33:05,400
마지막은 GUI 이미지 카테고리입니다.

464
00:33:06,160 --> 00:33:08,480
사전 훈련 카테고리입니다.

465
00:33:08,480 --> 00:33:11,880
다시 말하지만, 여기에는 두 가지 서로 다른 데이터 하위 집합이 있습니다.

466
00:33:11,880 --> 00:33:14,880
하나는 GUI 참조 표현식 생성이고,

467
00:33:14,880 --> 00:33:17,320
두 번째는 GUI 참조 표현식입니다.

468
00:33:17,320 --> 00:33:18,560
이해력.

469
00:33:18,560 --> 00:33:20,560
해당 세대 모델은 기본적으로

470
00:33:20,560 --> 00:33:25,920
DOM 요소에 대한 HTML 코드 생성을 담당합니다.

471
00:33:25,920 --> 00:33:29,360
스크린샷의 특정 영역을 기반으로 합니다.

472
00:33:29,360 --> 00:33:34,440
그리고 이해 과제에서는 데이터 과제 모델이

473
00:33:34,440 --> 00:33:42,120
DOM 요소가 주어진 경계 상자를 생성합니다.

474
00:33:42,120 --> 00:33:49,520
그들은 실제로 400,000개의 웹페이지로 구성된 데이터 세트를 만들었습니다.

475
00:33:49,520 --> 00:33:52,680
이 구조를 사용합니다.

476
00:33:52,680 --> 00:33:57,960
그리고 그들은 60,000번의 반복을 위해 CogAgent를 사전 훈련했습니다.

477
00:33:57,960 --> 00:34:00,440
게다가, 그들은 그것을 더욱 세밀하게 조정했습니다.

478
00:34:00,440 --> 00:34:04,040
여러 가지 다양한 작업에 대해.

479
00:34:04,600 --> 00:34:08,000
첫 번째는 스크린샷을 많이 수집했다는 점입니다.

480
00:34:08,000 --> 00:34:12,680
주석이 달린 화면 요소가 있는 휴대폰 및 컴퓨터

481
00:34:12,680 --> 00:34:15,520
잠재적인 업무와 운영 방법.

482
00:34:15,520 --> 00:34:18,800
그리고 그들은 또한 두 개의 유명한 데이터 세트인 Mind2Web을 사용했습니다.

483
00:34:18,800 --> 00:34:23,240
그리고 세계 속의 안드로이드는 웹에 더 집중하고 있습니다

484
00:34:23,240 --> 00:34:27,320
그리고 각각 안드로이드.

485
00:34:27,320 --> 00:34:31,240
그리고 그들은 또한 기타 기타 VQA 데이터 세트도 사용했습니다.

486
00:34:31,240 --> 00:34:33,240
그들의 모델에서 찾아보세요.

487
00:34:33,240 --> 00:34:37,080
실험에는 세 가지 범주가 있습니다.

488
00:34:37,080 --> 00:34:38,240
실험의.

489
00:34:38,240 --> 00:34:42,080
첫 번째 실험은 기본 시각적 요소에 관한 것입니다.

490
00:34:42,080 --> 00:34:43,320
이해.

491
00:34:43,320 --> 00:34:46,680
그들은 CogAgent가 올바른지 확인하고 싶었습니다.

492
00:34:46,680 --> 00:34:50,960
기본적인 이해나 전반적인 이해가 가능하며,

493
00:34:50,960 --> 00:34:53,800
VQA 영역의 시각적 이해.

494
00:34:53,800 --> 00:34:56,000
그들은 몇 가지 일반적인 VQA 데이터 세트를 사용했습니다.

495
00:34:56,000 --> 00:34:58,520
VQAV2 및 OKVQA와 같은.

496
00:34:58,560 --> 00:35:05,680
또한 그들은 텍스트가 풍부한 VQA 데이터 세트를 많이 사용했습니다.

497
00:35:05,680 --> 00:35:08,960
모델을 미세 조정하고 테스트하기도 합니다.

498
00:35:08,960 --> 00:35:14,320
보시다시피 CogAgent는 최첨단 기술에 도달했습니다.

499
00:35:14,320 --> 00:35:19,040
또는 거의 모든 분야에서 최첨단 기술에 매우 가깝습니다.

500
00:35:19,040 --> 00:35:22,000
그들은 또한 자사 모델의 제로샷 테스트를 실시했습니다.

501
00:35:22,000 --> 00:35:24,920
두 가지 도전적인 분포를 벗어난 데이터에 대해

502
00:35:24,920 --> 00:35:27,720
그래서 그들은 모델을 훈련하거나 미세 조정하지 않았습니다.

503
00:35:27,720 --> 00:35:29,600
이 데이터 데이터 세트에 대해.

504
00:35:29,600 --> 00:35:36,480
그럼에도 불구하고 그들은 일반화가 가능하다는 것을 알았습니다.

505
00:35:36,480 --> 00:35:38,800
CogAgent의 기능은 놀랍습니다.

506
00:35:41,400 --> 00:35:45,120
두 번째 실험에서는 GUI 에이전트가 있습니다.

507
00:35:45,120 --> 00:35:47,760
컴퓨터 인터페이스 또는 실제로 웹 인터페이스에서.

508
00:35:47,760 --> 00:35:51,080
여기서 주로 사용한 데이터 세트는 Mine-to-Web 데이터입니다.

509
00:35:51,080 --> 00:35:57,040
세트는 2,000개가 넘는 데이터 세트입니다.

510
00:35:57,400 --> 00:36:04,000
31개 도메인에 걸쳐 137개 웹사이트의 작업.

511
00:36:04,000 --> 00:36:08,000
그리고 데이터 세트의 각 항목은 다음과 같이 구성됩니다.

512
00:36:08,000 --> 00:36:11,160
높은 수준의 작업 설명, 일련의 작업,

513
00:36:11,160 --> 00:36:14,120
그리고 실제 형식의 웹페이지 스냅샷입니다.

514
00:36:14,120 --> 00:36:16,720
그리고 이러한 사항을 고려할 때 모델은

515
00:36:16,720 --> 00:36:20,240
후속 또는 다음 행동을 예측합니다.

516
00:36:21,240 --> 00:36:27,120
그리고 그들은 마이닝 세트에서 모델을 미세 조정했습니다.

517
00:36:27,120 --> 00:36:33,240
세 가지 서로 다른 도메인 외부 하위 집합에 대해 평가되었습니다.

518
00:36:33,240 --> 00:36:36,520
웹사이트 간, 도메인 간, 작업 간.

519
00:36:36,520 --> 00:36:39,000
보시다시피 CogAgent는

520
00:36:39,000 --> 00:36:46,000
단순한 유명 모델을 이길 수 있습니다.

521
00:36:46,000 --> 00:36:49,800
따라서 이러한 시나리오에는 LOMA2 또는 GBT4가 있습니다.

522
00:36:53,320 --> 00:36:56,720
마지막 실험은 스마트 광산 인터페이스에 관한 것입니다.

523
00:36:56,720 --> 00:36:58,840
그들은 실제로 Android를 사용합니다.

524
00:36:58,840 --> 00:37:02,800
데이터 세트로서 Android는 야생에 있습니다.

525
00:37:02,800 --> 00:37:08,920
700,000개 이상의 작업 에피소드를 보유하고 있으며,

526
00:37:08,920 --> 00:37:12,800
3,000개 이상의 작업 지침을 다룹니다.

527
00:37:12,800 --> 00:37:17,280
4가지 Android 버전과 8가지 기기 스타일에 대해

528
00:37:17,280 --> 00:37:20,040
크기가 다릅니다.

529
00:37:20,040 --> 00:37:24,000
그럼 다시 이전과 비슷하게,

530
00:37:24,000 --> 00:37:25,760
이 데이터 세트의 각 에피소드는 다음과 같이 구성됩니다.

531
00:37:25,760 --> 00:37:28,040
자연어로 된 목표 설명,

532
00:37:28,040 --> 00:37:29,600
일련의 작업이 뒤따릅니다.

533
00:37:29,600 --> 00:37:31,880
그리고 해당 스크린샷.

534
00:37:31,880 --> 00:37:35,560
그리고 임무는 다음 행동을 예측하는 것입니다.

535
00:37:35,560 --> 00:37:40,160
주로 주어진 목표를 기반으로 주어진 데이터에 대해.

536
00:37:40,160 --> 00:37:44,280
다시 한번 우리는 CogAgent가 예술적인 수준에 도달할 수 있다는 것을 알 수 있습니다.

537
00:37:44,280 --> 00:37:51,760
대부분의 섹션에서 세트 순서를 이겼습니다.

538
00:37:51,760 --> 00:37:55,560
이 데이터 세트의.

539
00:37:55,560 --> 00:38:00,440
그들은 많은 절제 연구를 수행했습니다.

540
00:38:00,440 --> 00:38:02,920
그래서 첫 번째는 그들이 원했던 것입니다

541
00:38:02,920 --> 00:38:07,440
실제로 성능을 경험적으로 검증하기 위해

542
00:38:07,440 --> 00:38:10,400
교차주의 메커니즘의 이득

543
00:38:10,400 --> 00:38:13,920
고해상도 이미지를 인코딩하기 위한 것입니다.

544
00:38:13,920 --> 00:38:16,480
그리고 우리는 계산적으로 말하자면,

545
00:38:16,480 --> 00:38:22,800
원래 모델을 공급하면

546
00:38:22,800 --> 00:38:25,640
매우 높은 해상도의 이미지로 교차주의 없이

547
00:38:25,640 --> 00:38:31,240
비용은 매우, 매우 높아질 것입니다.

548
00:38:31,240 --> 00:38:39,160
그들은 또한 다양한 종류의 설정과 비교했습니다.

549
00:38:39,160 --> 00:38:43,600
고해상도 모듈을 사용하는 것과 고해상도 모듈을 사용하지 않는 것

550
00:38:43,600 --> 00:38:45,280
입력 크기가 다릅니다.

551
00:38:45,280 --> 00:38:49,560
보시다시피, 크로스 모듈 아이디어는 실제로

552
00:38:49,560 --> 00:38:53,560
훨씬 더 낮은 비용으로 훨씬 더 나은 성과를 낼 수 있습니다.

553
00:38:57,080 --> 00:38:59,120
그리고 또 다른 절제 연구에서는

554
00:38:59,120 --> 00:39:04,080
사전 훈련된 데이터의 효과를 확인하고 싶었습니다.

555
00:39:04,080 --> 00:39:07,800
그들은 순차적으로 먼저 이미지 캡션 데이터를 사용했고,

556
00:39:07,800 --> 00:39:11,160
그런 다음 OCR 데이터를 추가하고 GUI를 추가했습니다.

557
00:39:11,160 --> 00:39:12,000
접지 데이터.

558
00:39:12,000 --> 00:39:17,520
그리고 우리가 볼 수 있듯이, 특히 정신-습식 열에서,

559
00:39:17,520 --> 00:39:20,440
베벨 접지 데이터는 상당한 영향을 미칩니다

560
00:39:20,440 --> 00:39:21,440
이 데이터 세트에 대해.

561
00:39:21,440 --> 00:39:25,680
따라서 도메인별 구성의 중요성을 보여줍니다.

562
00:39:25,680 --> 00:39:27,800
사전 훈련된 데이터.

563
00:39:27,800 --> 00:39:31,640
그런 다음 GUI 에이전트를 교육하고 싶습니다.

564
00:39:31,640 --> 00:39:34,480
요약하자면, 당신은 도구를 보았습니다.

565
00:39:34,480 --> 00:39:39,560
전자는 도구를 사용하여 LLM을 찾는 일반적인 아이디어입니다.

566
00:39:39,560 --> 00:39:43,440
ART는 문제 분해를 위한 프레임워크입니다.

567
00:39:43,440 --> 00:39:47,400
AgentBench는 에이전트 벤치마크로서의 LLM입니다.

568
00:39:47,400 --> 00:39:53,600
우리는 LLM 도구 도구를 보고 방법에 대한 아이디어를 얻었습니다.

569
00:39:53,600 --> 00:39:56,960
향상된 기능을 갖춘 여러 API를 사용하도록 LLM을 수정할 수 있습니다.

570
00:39:57,000 --> 00:39:58,120
추리.

571
00:39:58,120 --> 00:40:01,880
분명히 이 도구는 GPT 문서를 작성할 수 있습니다.

572
00:40:01,880 --> 00:40:05,360
LLM을 엄청나게 늘리는 방법에 대한 아이디어를 제공했습니다.

573
00:40:05,360 --> 00:40:06,240
도구의.

574
00:40:06,240 --> 00:40:09,800
그리고 마지막으로 우리는 우리에게 아이디어를 준 톱니바퀴 에이전트를 보았습니다.

575
00:40:09,800 --> 00:40:16,000
더 높은 GUI를 이해할 수 있는 LLM을 만드는 방법

576
00:40:16,000 --> 00:40:20,280
인터페이스와 그에 대한 이유와 계획.